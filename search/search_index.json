{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AWS Security Workshops Welcome to the AWS security workshops portal! Here you will find a collection of workshops aimed at helping you gain an understanding of the service ecosystem and introduce you to a variety of best practices that can be applied to securing your environments and workloads running in AWS. Security and Compliance is a shared responsibility between AWS and the customer. As an AWS customer, you benefit from a data center and network architecture built to satisfy the requirements of the most security-sensitive organizations. AWS is responsible for protecting the infrastructure which runs all of the services offered and this responsibility is known as the Security of the Cloud . Customers responsibility, known as the Security in the Cloud , is determined by which services the customer chooses to use. The workshops contained in this portal are focused on the Security in the Cloud and they will guide you through prepared scenarios that represent common use cases and operational tasks you'll face in building on AWS. They will also highlight the design principals from the AWS Well-Architected Framework Security Pillar , which can help you improve your security posture. Implement a strong identity foundation Enable traceability Apply security at all layers Automate security best practices Protect data in transit and at rest Keep people away from data Prepare for security events","title":"Home"},{"location":"#aws-security-workshops","text":"Welcome to the AWS security workshops portal! Here you will find a collection of workshops aimed at helping you gain an understanding of the service ecosystem and introduce you to a variety of best practices that can be applied to securing your environments and workloads running in AWS. Security and Compliance is a shared responsibility between AWS and the customer. As an AWS customer, you benefit from a data center and network architecture built to satisfy the requirements of the most security-sensitive organizations. AWS is responsible for protecting the infrastructure which runs all of the services offered and this responsibility is known as the Security of the Cloud . Customers responsibility, known as the Security in the Cloud , is determined by which services the customer chooses to use. The workshops contained in this portal are focused on the Security in the Cloud and they will guide you through prepared scenarios that represent common use cases and operational tasks you'll face in building on AWS. They will also highlight the design principals from the AWS Well-Architected Framework Security Pillar , which can help you improve your security posture. Implement a strong identity foundation Enable traceability Apply security at all layers Automate security best practices Protect data in transit and at rest Keep people away from data Prepare for security events","title":"AWS Security Workshops"},{"location":"contribute/","text":"Contributing Guidelines Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution. Reporting Bugs/Feature Requests We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment Contributing via Pull Requests Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request . Finding contributions to work on Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start. Code of Conduct This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments. Security issue notifications If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue. Licensing See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Contributing"},{"location":"contribute/#contributing-guidelines","text":"Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution.","title":"Contributing Guidelines"},{"location":"contribute/#reporting-bugsfeature-requests","text":"We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment","title":"Reporting Bugs/Feature Requests"},{"location":"contribute/#contributing-via-pull-requests","text":"Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request .","title":"Contributing via Pull Requests"},{"location":"contribute/#finding-contributions-to-work-on","text":"Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.","title":"Finding contributions to work on"},{"location":"contribute/#code-of-conduct","text":"This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.","title":"Code of Conduct"},{"location":"contribute/#security-issue-notifications","text":"If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue.","title":"Security issue notifications"},{"location":"contribute/#licensing","text":"See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Licensing"},{"location":"getting-started/","text":"Getting Started Create an AWS account In order to complete these workshops, you'll need a valid, usable AWS Account . Use a personal account or create a new AWS account to ensure you have the necessary access and that you do not accidentally modify corporate resources. Do not use an AWS account from the company you work for. Create an admin user If you don't already have an AWS IAM user with admin permissions, please use the following instructions to create one: Browse to the AWS IAM console. Click Users on the left navigation and then click Add User . Enter a User Name , check the checkbox for AWS Management Console access , enter a Custom Password , and click Next:Permissions . Click Attach existing policies directly , click the checkbox next to the AdministratorAccess , and click Next:review . Click Create User Click Dashboard on the left navigation and use the IAM users sign-in link to login as the admin user you just created. Add credits (optional) If you are doing this workshop as part of an AWS sponsored event, you will receive credits to cover the costs. Below are the instructions for entering the credits: Browse to the AWS Account Settings console. Enter the Promo Code you received (these will be handed out at the beginning of the workshop). Enter the Security Check and click Redeem . Create a Cloud9 instance (optional) If the workshop you are doing requires you to run commands or scripts you will need to launch a an AWS Cloud9 instance which will provide you with a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. The workshop instructions will specify if this needed. Below are the instructions for launching an instance: Browse to the AWS Cloud9 console. Click Create environment on the right side. Enter a Name (security-workshop-ide) and click Next step . Leave all the defaults and click Next step . Click Create environment . The environment will open automatically after it has been provisioned. Browse back to the AWS Cloud9 console and you can click Open IDE on the environment you created to access it at anytime. You are now setup for the workshops!","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/#create-an-aws-account","text":"In order to complete these workshops, you'll need a valid, usable AWS Account . Use a personal account or create a new AWS account to ensure you have the necessary access and that you do not accidentally modify corporate resources. Do not use an AWS account from the company you work for.","title":"Create an AWS account"},{"location":"getting-started/#create-an-admin-user","text":"If you don't already have an AWS IAM user with admin permissions, please use the following instructions to create one: Browse to the AWS IAM console. Click Users on the left navigation and then click Add User . Enter a User Name , check the checkbox for AWS Management Console access , enter a Custom Password , and click Next:Permissions . Click Attach existing policies directly , click the checkbox next to the AdministratorAccess , and click Next:review . Click Create User Click Dashboard on the left navigation and use the IAM users sign-in link to login as the admin user you just created.","title":"Create an admin user"},{"location":"getting-started/#add-credits-optional","text":"If you are doing this workshop as part of an AWS sponsored event, you will receive credits to cover the costs. Below are the instructions for entering the credits: Browse to the AWS Account Settings console. Enter the Promo Code you received (these will be handed out at the beginning of the workshop). Enter the Security Check and click Redeem .","title":"Add credits (optional)"},{"location":"getting-started/#create-a-cloud9-instance-optional","text":"If the workshop you are doing requires you to run commands or scripts you will need to launch a an AWS Cloud9 instance which will provide you with a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. The workshop instructions will specify if this needed. Below are the instructions for launching an instance: Browse to the AWS Cloud9 console. Click Create environment on the right side. Enter a Name (security-workshop-ide) and click Next step . Leave all the defaults and click Next step . Click Create environment . The environment will open automatically after it has been provisioned. Browse back to the AWS Cloud9 console and you can click Open IDE on the environment you created to access it at anytime. You are now setup for the workshops!","title":"Create a Cloud9 instance (optional)"},{"location":"license/","text":"License MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"builder-sessions/","text":"re:Invent Builder Sessions Title Description Permission Boundaries: How to Truly Delegate Permissions on AWS Permission boundaries is probably one of the most important new IAM feature that has launched in awhile. This feature addresses a longstanding customer issue, namely, how do I delegate administration to my users. If you have developers that need to be able to create roles for Lambda functions, system administrators that need to be able to create IAM roles and users, or any similar scenario, then you need permission boundaries.","title":"Directory"},{"location":"builder-sessions/#reinvent-builder-sessions","text":"Title Description Permission Boundaries: How to Truly Delegate Permissions on AWS Permission boundaries is probably one of the most important new IAM feature that has launched in awhile. This feature addresses a longstanding customer issue, namely, how do I delegate administration to my users. If you have developers that need to be able to create roles for Lambda functions, system administrators that need to be able to create IAM roles and users, or any similar scenario, then you need permission boundaries.","title":"re:Invent Builder Sessions"},{"location":"builder-sessions/permission-boundaries-build/","text":"Permission Boundaries: How to Truly Delegate Permissions on AWS (Build Phase) Permission boundaries is probably one of the most important new IAM features that has launched in a while. This feature addresses a longstanding customer issue, namely, how do I delegate administration to my users. If you have system administrators that need to be able to create IAM roles and users, developers that need to be able to create roles for Lambda functions, or any similar scenario, then you need permission boundaries. Console Login Browse to the URL provided to you and login. After you login click the AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for the Management console . Click on that and you will be taken to the AWS console. Scenario As the administrator for an AWS account hosting multiple production applications, you've been tasked with creating a new administrator role to delegate some of your responsibilities. This new role will be responsible for doing all the administration on the resources for the Ares Mission . The diagram above showcases the two applications currently being hosted in the AWS account and their associated resources. Currently there is only one application related to the Ares Mission but there is a plan to migrate three more applications for this mission by the end of the year. The new role should account for current and future Ares Mission applications to reduce your overhead and friction with the web administrators. The web administrators for the Ares Mission should have permissions to create and administer resources related to that mission. This means they should be able to: Create, modify, and delete IAM policies and roles. Any role created must have restricted permissions to ensure a web administrator cannot elevate their privileges or the privileges of the application. Create, modify, and delete Ares Mission Lambda functions. The web administrators should not be able to impact any resources in the account that are not part of the Ares Mission application including users, groups, roles, S3 buckets, EC2 instances, etc. In this case, they should not be able to modify resources of the Rover Mission. All resources are located in the us-west-2 region. Task 1 - Create a permission boundary for Lambda Functions ACTION : Create a new IAM policy that will act as the permission boundary for the web admins. Name the policy identity-ex-permissionboundary-ares-lambda Hint : Friendly Names and Paths . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateLogGroup , Effect : Allow , Action : logs:CreateLogGroup , Resource : arn:aws:logs:us-west-2:ACCOUNT_ID:* }, { Sid : CreateLogStreamandEvents , Effect : Allow , Action : [ logs:CreateLogStream , logs:PutLogEvents ], Resource : arn:aws:logs:us-west-2:ACCOUNT_ID:log-group:/aws/lambda/identity-ex-????:* }, { Sid : AllowedS3GetObject , Effect : Allow , Action : [ s3:List* ], Resource : arn:aws:s3:::identity-ex-???? } ] } Task 2 - Create a permission policy for the Web Admin ACTION : Create the permission policy that will be attached to the webadmin AWS IAM user. Name the new policy identity-ex-webadmin-permissionpolicy . Hint : Friendly Names and Paths . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateCustomerManagedPolicies , Effect : Allow , Action : [ iam:CreatePolicy , iam:DeletePolicy , iam:CreatePolicyVersion , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : arn:aws:iam::ACCOUNT_ID:policy/identity-ex-???? }, { Sid : RoleandPolicyActionswithnoPermissionBoundarySupport , Effect : Allow , Action : [ iam:UpdateRole , iam:DeleteRole ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? ] }, { Sid : CreateRoles , Effect : Allow , Action : [ iam:CreateRole , iam:AttachRolePolicy , iam:DetachRolePolicy ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? ], Condition : { StringEquals : { iam:PermissionsBoundary : arn:aws:iam::ACCOUNT_ID:policy/identity-ex-permissionboundary-ares-lambda } } }, { Sid : LambdaFullAccesswithResourceRestrictions , Effect : Allow , Action : lambda:* , Resource : arn:aws:lambda:us-west-2:ACCOUNT_ID:function:identity-ex-???? }, { Sid : PassRoletoLambda , Effect : Allow , Action : iam:PassRole , Resource : arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? , Condition : { StringLikeIfExists : { iam:PassedToService : lambda.amazonaws.com } } }, { Sid : AdditionalPermissionsforLambda , Effect : Allow , Action : [ kms:ListAliases , logs:Describe* , logs:ListTagsLogGroup , logs:FilterLogEvents , logs:GetLogEvents ], Resource : * }, { Sid : DenyPermissionBoundaryandPolicyDeleteModify , Effect : Deny , Action : [ iam:CreatePolicyVersion , iam:DeletePolicy , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : [ arn:aws:iam::ACCOUNT_ID:policy/identity-ex-permissionboundary-ares-lambda , arn:aws:iam::ACCOUNT_ID:policy/identity-ex-webadmin-permissionpolicy ] }, { Sid : DenyRolePermissionBoundaryDelete , Effect : Deny , Action : iam:DeleteRolePermissionsBoundary , Resource : * } ] } Task 3 - Create the Web Admin user ACTION : Create an IAM User and name it webadmin . The user will need console access so give it a password. Attach the identity-ex-webadmin-permissionpolicy , IAMReadOnlyAccess AWSLambdaReadOnlyAccess policies to the IAM user. When you are done the webadmin user should have three policies attached: identity-ex-webadmin-permissionpolicy, IAMReadOnlyAccess AWSLambdaReadOnlyAccess. Task 4 - Gather info needed for the Verify phase ACTION : Now that you have setup the IAM user for the web admins, it's time to pass this information on to the next team who will work through the VERIFY tasks. You need to gather some details about your IAM user and then hand this info to the next team. Copy the IAM users sign-in link , the IAM user name (if you used a name other then webadmin ) and the password you used. You will also need the resource restriction that you used in your policies and the name you used for the permission policy and permission boundary (if you used names other than the ones recommended above) Here are all of the details you need to pass to another team: IAM users sign-in link: IAM user name: IAM user password: Resource restriction identifier: Permission boundary name: (recommended name: identity-ex-permissionboundary-ares-lambda ) Permission policy: (recommended name: identity-ex-webadmin-permissionpolicy ) Enter this information into the VERIFY phase form and exchange forms with another team so you both can work through the tasks. You can now move on to the Verify phase!","title":"Build Phase"},{"location":"builder-sessions/permission-boundaries-build/#permission-boundaries-how-to-truly-delegate-permissions-on-aws-build-phase","text":"Permission boundaries is probably one of the most important new IAM features that has launched in a while. This feature addresses a longstanding customer issue, namely, how do I delegate administration to my users. If you have system administrators that need to be able to create IAM roles and users, developers that need to be able to create roles for Lambda functions, or any similar scenario, then you need permission boundaries.","title":"Permission Boundaries: How to Truly Delegate Permissions on AWS (Build Phase)"},{"location":"builder-sessions/permission-boundaries-build/#console-login","text":"Browse to the URL provided to you and login. After you login click the AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for the Management console . Click on that and you will be taken to the AWS console.","title":"Console Login"},{"location":"builder-sessions/permission-boundaries-build/#scenario","text":"As the administrator for an AWS account hosting multiple production applications, you've been tasked with creating a new administrator role to delegate some of your responsibilities. This new role will be responsible for doing all the administration on the resources for the Ares Mission . The diagram above showcases the two applications currently being hosted in the AWS account and their associated resources. Currently there is only one application related to the Ares Mission but there is a plan to migrate three more applications for this mission by the end of the year. The new role should account for current and future Ares Mission applications to reduce your overhead and friction with the web administrators. The web administrators for the Ares Mission should have permissions to create and administer resources related to that mission. This means they should be able to: Create, modify, and delete IAM policies and roles. Any role created must have restricted permissions to ensure a web administrator cannot elevate their privileges or the privileges of the application. Create, modify, and delete Ares Mission Lambda functions. The web administrators should not be able to impact any resources in the account that are not part of the Ares Mission application including users, groups, roles, S3 buckets, EC2 instances, etc. In this case, they should not be able to modify resources of the Rover Mission. All resources are located in the us-west-2 region.","title":"Scenario"},{"location":"builder-sessions/permission-boundaries-build/#task-1-create-a-permission-boundary-for-lambda-functions","text":"ACTION : Create a new IAM policy that will act as the permission boundary for the web admins. Name the policy identity-ex-permissionboundary-ares-lambda Hint : Friendly Names and Paths . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateLogGroup , Effect : Allow , Action : logs:CreateLogGroup , Resource : arn:aws:logs:us-west-2:ACCOUNT_ID:* }, { Sid : CreateLogStreamandEvents , Effect : Allow , Action : [ logs:CreateLogStream , logs:PutLogEvents ], Resource : arn:aws:logs:us-west-2:ACCOUNT_ID:log-group:/aws/lambda/identity-ex-????:* }, { Sid : AllowedS3GetObject , Effect : Allow , Action : [ s3:List* ], Resource : arn:aws:s3:::identity-ex-???? } ] }","title":"Task 1 - Create a permission boundary for Lambda Functions"},{"location":"builder-sessions/permission-boundaries-build/#task-2-create-a-permission-policy-for-the-web-admin","text":"ACTION : Create the permission policy that will be attached to the webadmin AWS IAM user. Name the new policy identity-ex-webadmin-permissionpolicy . Hint : Friendly Names and Paths . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateCustomerManagedPolicies , Effect : Allow , Action : [ iam:CreatePolicy , iam:DeletePolicy , iam:CreatePolicyVersion , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : arn:aws:iam::ACCOUNT_ID:policy/identity-ex-???? }, { Sid : RoleandPolicyActionswithnoPermissionBoundarySupport , Effect : Allow , Action : [ iam:UpdateRole , iam:DeleteRole ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? ] }, { Sid : CreateRoles , Effect : Allow , Action : [ iam:CreateRole , iam:AttachRolePolicy , iam:DetachRolePolicy ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? ], Condition : { StringEquals : { iam:PermissionsBoundary : arn:aws:iam::ACCOUNT_ID:policy/identity-ex-permissionboundary-ares-lambda } } }, { Sid : LambdaFullAccesswithResourceRestrictions , Effect : Allow , Action : lambda:* , Resource : arn:aws:lambda:us-west-2:ACCOUNT_ID:function:identity-ex-???? }, { Sid : PassRoletoLambda , Effect : Allow , Action : iam:PassRole , Resource : arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? , Condition : { StringLikeIfExists : { iam:PassedToService : lambda.amazonaws.com } } }, { Sid : AdditionalPermissionsforLambda , Effect : Allow , Action : [ kms:ListAliases , logs:Describe* , logs:ListTagsLogGroup , logs:FilterLogEvents , logs:GetLogEvents ], Resource : * }, { Sid : DenyPermissionBoundaryandPolicyDeleteModify , Effect : Deny , Action : [ iam:CreatePolicyVersion , iam:DeletePolicy , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : [ arn:aws:iam::ACCOUNT_ID:policy/identity-ex-permissionboundary-ares-lambda , arn:aws:iam::ACCOUNT_ID:policy/identity-ex-webadmin-permissionpolicy ] }, { Sid : DenyRolePermissionBoundaryDelete , Effect : Deny , Action : iam:DeleteRolePermissionsBoundary , Resource : * } ] }","title":"Task 2 - Create a permission policy for the Web Admin"},{"location":"builder-sessions/permission-boundaries-build/#task-3-create-the-web-admin-user","text":"ACTION : Create an IAM User and name it webadmin . The user will need console access so give it a password. Attach the identity-ex-webadmin-permissionpolicy , IAMReadOnlyAccess AWSLambdaReadOnlyAccess policies to the IAM user. When you are done the webadmin user should have three policies attached: identity-ex-webadmin-permissionpolicy, IAMReadOnlyAccess AWSLambdaReadOnlyAccess.","title":"Task 3 - Create the Web Admin user"},{"location":"builder-sessions/permission-boundaries-build/#task-4-gather-info-needed-for-the-verify-phase","text":"ACTION : Now that you have setup the IAM user for the web admins, it's time to pass this information on to the next team who will work through the VERIFY tasks. You need to gather some details about your IAM user and then hand this info to the next team. Copy the IAM users sign-in link , the IAM user name (if you used a name other then webadmin ) and the password you used. You will also need the resource restriction that you used in your policies and the name you used for the permission policy and permission boundary (if you used names other than the ones recommended above) Here are all of the details you need to pass to another team: IAM users sign-in link: IAM user name: IAM user password: Resource restriction identifier: Permission boundary name: (recommended name: identity-ex-permissionboundary-ares-lambda ) Permission policy: (recommended name: identity-ex-webadmin-permissionpolicy ) Enter this information into the VERIFY phase form and exchange forms with another team so you both can work through the tasks. You can now move on to the Verify phase!","title":"Task 4 - Gather info needed for the Verify phase"},{"location":"builder-sessions/permission-boundaries-verify/","text":"Permission Boundaries: How to Truly Delegate Permissions on AWS (Verify Phase) We are now in the Verify phase. It is time to put on the hat of the web administrator and test the access to ensure the permissions are setup correctly. You'll be logging in to the AWS account you were delegated access to and perform a number of verification tasks. Console Login You should have received from another team the following information. You will need this information to access the AWS console IAM users sign-in link IAM user name IAM user password Resource restriction identifier Permission boundary name Requirements The only requirement is to verify you can complete the following tasks. The web admins should only have access to the following resources: IAM policies and roles created by the web admins Lambda functions created by the web admins The web admins should not be able to impact any resources in the account that they do not own including users, groups, roles, S3 buckets, EC2 instances, etc. The following steps should be taken to validate that the delegation was done properly. Verify that you are able to create an IAM policy, create an IAM role with that policy attached and then create a Lambda function and pass that role to it. Task 1 - Create a customer managed IAM policy The first step is to create a customer managed IAM policy. This will define the permissions of the role that you will pass to a Lambda function. Since the function will be working with S3 and since the point of this is to show how permission boundaries work, use the following policy which grants basic Lambda logging permissions and S3 full access. Keep in mind the resource restrictions put in place which will require you to use a certain name for the policy. What is the resource restriction identifier that was given to you? { Version : 2012-10-17 , Statement : [ { Effect : Allow , Action : [ logs:CreateLogGroup , logs:CreateLogStream , logs:PutLogEvents , s3:* ], Resource : * } ] } Task 2 - Create an IAM role Next you will create an IAM Role. Choose Lambda as the service for this role. Attach the policy you just created and the permission boundary (which will most likely be named: identity-ex-permissionboundary-ares-lambda ) Keep in mind the resource restrictions put in place which will require you to use a certain name for the role. What is the resource restriction identifier that was given to you? Task 3 - Create a Lambda function Finally you will create a Node.js 8.10 Lambda function using the code below and attach the IAM role you just created to it. You will need to replace \"ELB_ACCESS_LOGS_BUCKET_NAME\" with bucket from your account that begins with \"identity-ex-ares*\" . Keep in mind the resource restrictions put in place which will require you to use a certain name for the role. What is the resource restriction identifier that was given to you? const AWS = require ( aws-sdk ); const s3 = new AWS . S3 (); exports . handler = async ( event ) = { console.log( Loading function ) ; const allKeys = [] ; await getKeys({ Bucket : ELB_ACCESS_LOGS_BUCKET_NAME } , allKeys ); return allKeys ; } ; async function getKeys ( params , keys ) { const response = await s3.listObjectsV2(params).promise() ; response.Contents.forEach(obj = keys.push(obj.Key)) ; if (response.IsTruncated) { const newParams = Object.assign({ } , params ); newParams . ContinuationToken = response . NextContinuationToken ; await getKeys ( newParams , keys ); } } Test the Lambda function and make sure it is generating logs in CloudWatch logs and that it is able to list the ELB logs in the ELB access logs bucket the object in S3. In order to test you will need to create a test event. The parameters of the test do not matter. Summary Congratulations, you've completed the Permission Boundaries Builder session! Hopefully by going through this session you have a better idea of what permission boundaries are, where they can be used, and are starting to think about where you can apply them in your environments.","title":"Verify Phase"},{"location":"builder-sessions/permission-boundaries-verify/#permission-boundaries-how-to-truly-delegate-permissions-on-aws-verify-phase","text":"We are now in the Verify phase. It is time to put on the hat of the web administrator and test the access to ensure the permissions are setup correctly. You'll be logging in to the AWS account you were delegated access to and perform a number of verification tasks.","title":"Permission Boundaries: How to Truly Delegate Permissions on AWS (Verify Phase)"},{"location":"builder-sessions/permission-boundaries-verify/#console-login","text":"You should have received from another team the following information. You will need this information to access the AWS console IAM users sign-in link IAM user name IAM user password Resource restriction identifier Permission boundary name","title":"Console Login"},{"location":"builder-sessions/permission-boundaries-verify/#requirements","text":"The only requirement is to verify you can complete the following tasks. The web admins should only have access to the following resources: IAM policies and roles created by the web admins Lambda functions created by the web admins The web admins should not be able to impact any resources in the account that they do not own including users, groups, roles, S3 buckets, EC2 instances, etc. The following steps should be taken to validate that the delegation was done properly. Verify that you are able to create an IAM policy, create an IAM role with that policy attached and then create a Lambda function and pass that role to it.","title":"Requirements"},{"location":"builder-sessions/permission-boundaries-verify/#task-1-create-a-customer-managed-iam-policy","text":"The first step is to create a customer managed IAM policy. This will define the permissions of the role that you will pass to a Lambda function. Since the function will be working with S3 and since the point of this is to show how permission boundaries work, use the following policy which grants basic Lambda logging permissions and S3 full access. Keep in mind the resource restrictions put in place which will require you to use a certain name for the policy. What is the resource restriction identifier that was given to you? { Version : 2012-10-17 , Statement : [ { Effect : Allow , Action : [ logs:CreateLogGroup , logs:CreateLogStream , logs:PutLogEvents , s3:* ], Resource : * } ] }","title":"Task 1 - Create a customer managed IAM policy"},{"location":"builder-sessions/permission-boundaries-verify/#task-2-create-an-iam-role","text":"Next you will create an IAM Role. Choose Lambda as the service for this role. Attach the policy you just created and the permission boundary (which will most likely be named: identity-ex-permissionboundary-ares-lambda ) Keep in mind the resource restrictions put in place which will require you to use a certain name for the role. What is the resource restriction identifier that was given to you?","title":"Task 2 - Create an IAM role"},{"location":"builder-sessions/permission-boundaries-verify/#task-3-create-a-lambda-function","text":"Finally you will create a Node.js 8.10 Lambda function using the code below and attach the IAM role you just created to it. You will need to replace \"ELB_ACCESS_LOGS_BUCKET_NAME\" with bucket from your account that begins with \"identity-ex-ares*\" . Keep in mind the resource restrictions put in place which will require you to use a certain name for the role. What is the resource restriction identifier that was given to you? const AWS = require ( aws-sdk ); const s3 = new AWS . S3 (); exports . handler = async ( event ) = { console.log( Loading function ) ; const allKeys = [] ; await getKeys({ Bucket : ELB_ACCESS_LOGS_BUCKET_NAME } , allKeys ); return allKeys ; } ; async function getKeys ( params , keys ) { const response = await s3.listObjectsV2(params).promise() ; response.Contents.forEach(obj = keys.push(obj.Key)) ; if (response.IsTruncated) { const newParams = Object.assign({ } , params ); newParams . ContinuationToken = response . NextContinuationToken ; await getKeys ( newParams , keys ); } } Test the Lambda function and make sure it is generating logs in CloudWatch logs and that it is able to list the ELB logs in the ELB access logs bucket the object in S3. In order to test you will need to create a test event. The parameters of the test do not matter.","title":"Task 3 - Create a Lambda function"},{"location":"builder-sessions/permission-boundaries-verify/#summary","text":"Congratulations, you've completed the Permission Boundaries Builder session! Hopefully by going through this session you have a better idea of what permission boundaries are, where they can be used, and are starting to think about where you can apply them in your environments.","title":"Summary"},{"location":"level-300/","text":"Level 300 Workshops Title Description Find All the Threats: AWS Threat Detection and Remediation This hands-on workshop where you learn about a number of AWS services involved with threat detection and remediation as we walk through some real-world threat scenarios. Learn about the threat detection capabilities of Amazon GuardDuty, Amazon Macie, AWS Config, and the available remediation options. For each hands-on scenario, we review methods to remediate the threat using the following services: AWS CloudFormation, Amazon S3, AWS CloudTrail, Amazon VPC flow logs, Amazon CloudWatch Events, Amazon SNS, Amazon Macie, DNS logs, AWS Lambda, AWS Config, Amazon Inspector and, of course, Amazon GuardDuty.","title":"Directory"},{"location":"level-300/#level-300-workshops","text":"Title Description Find All the Threats: AWS Threat Detection and Remediation This hands-on workshop where you learn about a number of AWS services involved with threat detection and remediation as we walk through some real-world threat scenarios. Learn about the threat detection capabilities of Amazon GuardDuty, Amazon Macie, AWS Config, and the available remediation options. For each hands-on scenario, we review methods to remediate the threat using the following services: AWS CloudFormation, Amazon S3, AWS CloudTrail, Amazon VPC flow logs, Amazon CloudWatch Events, Amazon SNS, Amazon Macie, DNS logs, AWS Lambda, AWS Config, Amazon Inspector and, of course, Amazon GuardDuty.","title":"Level 300 Workshops"},{"location":"level-300/threat-detection-remediation/","text":"Find All the Threats: AWS Threat Detection and Remediation This workshop is designed to help you get familiar with AWS Security services and learn how to use them to identify and remediate threats in your environment. You'll be working with services such as Amazon GuardDuty, Amazon Macie, Amazon Inspector, Amazon CloudWatch, AWS Lambda, AWS Systems Manager, AWS Config, and AWS CloudTrail. You will learn how to use these services to set up a notification and remediation pipeline, investigate threats during and after an attack, and add additional protections in place to improve the security posture of your environment. Prerequisites You should have some level of familiarity with AWS services such as EC2, VPC and S3. Exposure to AWS Lambda and CloudFormation are a bonus. Some experience working with the AWS console is helpful as well. Scenario Your company is new to the cloud and has recently performed a lift-and-shift of your infrastructure for piloting purposes. You are a systems administrator and have been tasked with security monitoring within your AWS environment. As part of that maintenance you are also responsible for responding to any security event in your environment. Architecture overview For this Workshop you will have a single instance setup in the us-west-2 region. As this was a \u201clift-and-shift\u201d migration for piloting, you have yet to build redundancy into your application, so you have a single public-facing web server. The web server has access to the Internet Gateway through an Elastic Network Interface. Customers access your web server through a DNS entry pointing to the Elastic Network Interface. You store static content in an S3 bucket and use the VPC S3 Endpoint Gateway for access from the web server. Before you migrated the application you saw a webinar about AWS security best practices. Because of that webinar, you knew to enable a number of Security services provided by AWS. Region Please use the us-west-2 (Oregon) region for this workshop. Modules Environment Build and Configuration Attack Simulation Detection and Remediation Review and Discussion Total time: 2 hours","title":"Overview"},{"location":"level-300/threat-detection-remediation/#find-all-the-threats-aws-threat-detection-and-remediation","text":"This workshop is designed to help you get familiar with AWS Security services and learn how to use them to identify and remediate threats in your environment. You'll be working with services such as Amazon GuardDuty, Amazon Macie, Amazon Inspector, Amazon CloudWatch, AWS Lambda, AWS Systems Manager, AWS Config, and AWS CloudTrail. You will learn how to use these services to set up a notification and remediation pipeline, investigate threats during and after an attack, and add additional protections in place to improve the security posture of your environment.","title":"Find All the Threats: AWS Threat Detection and Remediation"},{"location":"level-300/threat-detection-remediation/#prerequisites","text":"You should have some level of familiarity with AWS services such as EC2, VPC and S3. Exposure to AWS Lambda and CloudFormation are a bonus. Some experience working with the AWS console is helpful as well.","title":"Prerequisites"},{"location":"level-300/threat-detection-remediation/#scenario","text":"Your company is new to the cloud and has recently performed a lift-and-shift of your infrastructure for piloting purposes. You are a systems administrator and have been tasked with security monitoring within your AWS environment. As part of that maintenance you are also responsible for responding to any security event in your environment.","title":"Scenario"},{"location":"level-300/threat-detection-remediation/#architecture-overview","text":"For this Workshop you will have a single instance setup in the us-west-2 region. As this was a \u201clift-and-shift\u201d migration for piloting, you have yet to build redundancy into your application, so you have a single public-facing web server. The web server has access to the Internet Gateway through an Elastic Network Interface. Customers access your web server through a DNS entry pointing to the Elastic Network Interface. You store static content in an S3 bucket and use the VPC S3 Endpoint Gateway for access from the web server. Before you migrated the application you saw a webinar about AWS security best practices. Because of that webinar, you knew to enable a number of Security services provided by AWS.","title":"Architecture overview"},{"location":"level-300/threat-detection-remediation/#region","text":"Please use the us-west-2 (Oregon) region for this workshop.","title":"Region"},{"location":"level-300/threat-detection-remediation/#modules","text":"Environment Build and Configuration Attack Simulation Detection and Remediation Review and Discussion Total time: 2 hours","title":"Modules"},{"location":"level-300/threat-detection-remediation/01-environment-setup/","text":"Module 1: Environment build and configuration In the first module you will be configuring detective and responsive controls for your environment. You'll be running the first of two CloudFormation templates which will automate the creation of some of these controls and then you will manually configure the rest. Deploy the AWS CloudFormation template To initiate the scenario and configure your environment you will need to run the module 1 CloudFormation template: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. On the Specify Details section enter the necessary parameters as shown below. Parameter Value Stack name ThreatDetectionWksp-Env-Setup Email Address A valid email address Once you have entered your parameters click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status as shown below. You will get an email from SNS asking you to confirm the Subscription. Confirm the subscription so you can receive email alerts from AWS services during the Workshop. Setup Amazon CloudWatch event rules and automatic response The CloudFormation template you just ran created three CloudWatch Event Rules](https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html) for alerting and response purposes. The steps below will walk you through creating the final rule. After this you'll have rules in place to receive email notifications and trigger AWS Lambda functions to respond to threats. Below are steps to create this rule through the console but you can also find out more about doing it programmatically by reviewing the Amazon GuardDuty Documentation . Open the CloudWatch console (us-west-2) In the navigation pane on the left, under Events , click Rules What are the current Rules in place setup to do? Click Create Rule Under Event Pattern click Build event pattern to match events by service and select Custom event pattern in the drop down. Paste in the custom event pattern below: { source : [ aws.guardduty ], detail : { type : [ UnauthorizedAccess:EC2/MaliciousIPCaller.Custom ] } } For Targets , click Add Target , select Lambda Function , and then select threat-detection-wksp-remediation-nacl . Click Configure details . On the Configure rule details screen fill out the Name and Description (suggestions below). Name: threat-detection-wksp-guardduty-finding-ec2-maliciousip Description: GuardDuty Finding: UnauthorizedAccess:EC2/MaliciousIPCaller.Custom Click Create rule . Optional: Consider examining the Lambda function to see what it does. Open the Lambda console . Click on the function named threat-detection-wksp-remediation-nacl What will the function do when invoked? What will the threat-detection-wksp-remediation-inspector functions do? Enable Amazon GuardDuty The next step is to enable Amazon GuardDuty, which will continuously monitor your environment for malicious or unauthorized behavior. Go to the Amazon GuardDuty console (us-west-2). Click the Get Started button. On the next screen click the Enable GuardDuty button. GuardDuty is now enabled and continuously monitoring your CloudTrail logs, VPC flow logs, and DNS Query logs for threats in your environment. Enable Amazon Macie Since you plan on storing sensitive data in S3, let\u2019s quickly enable Amazon Macie. Macie is a security service that will continuously monitor data access activity for anomalies and generate alerts when it detects risk of unauthorized access or inadvertent data leaks. Go to the Amazon Macie console (us-west-2). Click Get Started . Macie will create a service-linked role when you enable it. If you would like to see the permissions that the role will have you can click the View service role permissions . Click Enable Macie . Setup Amazon Macie for data discovery classification Macie is also used for automatically discovering and classifying sensitive data. Now that Macie is enabled, setup an integration to classify data in your S3 bucket. In the Amazon Macie console click on Integrations on the left navigation. Find your AWS account ID (there should be only one) and click Select Click Add then on the next screen click the check box next to the S3 bucket that ends with \u201c-data\u201d . Click Add Leave the options here at the default, click Review . On the next screen click Start Classification . Finally click Done . Macie is now enabled and has begun to discover, classify and protect your data. Enable AWS Security Hub Now that all of your detective controls have been configured you need to enable AWS Security Hub](https://aws.amazon.com/securityhub/), which will provide you with a comprehensive view of the security and compliance of your AWS environment. Go to the AWS Security Hub console. Click the Get started button. On the next screen click the Enable SecurityHub button. AWS Security Hub is now enabled and will begin collecting and aggregating findings from the security services we have enabled so far. Architecture overview Your environment is now configured and ready for operations. Below is a diagram to depict the detective controls you now have in place. After you have successfully setup your environment, you can proceed to the next module.","title":"Module 1: Environment Build"},{"location":"level-300/threat-detection-remediation/01-environment-setup/#module-1-environment-build-and-configuration","text":"In the first module you will be configuring detective and responsive controls for your environment. You'll be running the first of two CloudFormation templates which will automate the creation of some of these controls and then you will manually configure the rest.","title":"Module 1: Environment build and configuration"},{"location":"level-300/threat-detection-remediation/01-environment-setup/#deploy-the-aws-cloudformation-template","text":"To initiate the scenario and configure your environment you will need to run the module 1 CloudFormation template: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. On the Specify Details section enter the necessary parameters as shown below. Parameter Value Stack name ThreatDetectionWksp-Env-Setup Email Address A valid email address Once you have entered your parameters click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status as shown below. You will get an email from SNS asking you to confirm the Subscription. Confirm the subscription so you can receive email alerts from AWS services during the Workshop.","title":"Deploy the AWS CloudFormation template"},{"location":"level-300/threat-detection-remediation/01-environment-setup/#setup-amazon-cloudwatch-event-rules-and-automatic-response","text":"The CloudFormation template you just ran created three CloudWatch Event Rules](https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html) for alerting and response purposes. The steps below will walk you through creating the final rule. After this you'll have rules in place to receive email notifications and trigger AWS Lambda functions to respond to threats. Below are steps to create this rule through the console but you can also find out more about doing it programmatically by reviewing the Amazon GuardDuty Documentation . Open the CloudWatch console (us-west-2) In the navigation pane on the left, under Events , click Rules What are the current Rules in place setup to do? Click Create Rule Under Event Pattern click Build event pattern to match events by service and select Custom event pattern in the drop down. Paste in the custom event pattern below: { source : [ aws.guardduty ], detail : { type : [ UnauthorizedAccess:EC2/MaliciousIPCaller.Custom ] } } For Targets , click Add Target , select Lambda Function , and then select threat-detection-wksp-remediation-nacl . Click Configure details . On the Configure rule details screen fill out the Name and Description (suggestions below). Name: threat-detection-wksp-guardduty-finding-ec2-maliciousip Description: GuardDuty Finding: UnauthorizedAccess:EC2/MaliciousIPCaller.Custom Click Create rule . Optional: Consider examining the Lambda function to see what it does. Open the Lambda console . Click on the function named threat-detection-wksp-remediation-nacl What will the function do when invoked? What will the threat-detection-wksp-remediation-inspector functions do?","title":"Setup Amazon CloudWatch event rules and automatic response"},{"location":"level-300/threat-detection-remediation/01-environment-setup/#enable-amazon-guardduty","text":"The next step is to enable Amazon GuardDuty, which will continuously monitor your environment for malicious or unauthorized behavior. Go to the Amazon GuardDuty console (us-west-2). Click the Get Started button. On the next screen click the Enable GuardDuty button. GuardDuty is now enabled and continuously monitoring your CloudTrail logs, VPC flow logs, and DNS Query logs for threats in your environment.","title":"Enable Amazon GuardDuty"},{"location":"level-300/threat-detection-remediation/01-environment-setup/#enable-amazon-macie","text":"Since you plan on storing sensitive data in S3, let\u2019s quickly enable Amazon Macie. Macie is a security service that will continuously monitor data access activity for anomalies and generate alerts when it detects risk of unauthorized access or inadvertent data leaks. Go to the Amazon Macie console (us-west-2). Click Get Started . Macie will create a service-linked role when you enable it. If you would like to see the permissions that the role will have you can click the View service role permissions . Click Enable Macie .","title":"Enable Amazon Macie"},{"location":"level-300/threat-detection-remediation/01-environment-setup/#setup-amazon-macie-for-data-discovery-classification","text":"Macie is also used for automatically discovering and classifying sensitive data. Now that Macie is enabled, setup an integration to classify data in your S3 bucket. In the Amazon Macie console click on Integrations on the left navigation. Find your AWS account ID (there should be only one) and click Select Click Add then on the next screen click the check box next to the S3 bucket that ends with \u201c-data\u201d . Click Add Leave the options here at the default, click Review . On the next screen click Start Classification . Finally click Done . Macie is now enabled and has begun to discover, classify and protect your data.","title":"Setup Amazon Macie for data discovery &amp; classification"},{"location":"level-300/threat-detection-remediation/01-environment-setup/#enable-aws-security-hub","text":"Now that all of your detective controls have been configured you need to enable AWS Security Hub](https://aws.amazon.com/securityhub/), which will provide you with a comprehensive view of the security and compliance of your AWS environment. Go to the AWS Security Hub console. Click the Get started button. On the next screen click the Enable SecurityHub button. AWS Security Hub is now enabled and will begin collecting and aggregating findings from the security services we have enabled so far.","title":"Enable AWS Security Hub"},{"location":"level-300/threat-detection-remediation/01-environment-setup/#architecture-overview","text":"Your environment is now configured and ready for operations. Below is a diagram to depict the detective controls you now have in place. After you have successfully setup your environment, you can proceed to the next module.","title":"Architecture overview"},{"location":"level-300/threat-detection-remediation/02-attack-simulation/","text":"Module 2: Attack Simulation Now that you have detective and responsive controls setup, you'll be running another CloudFormation template which will simulate the actual attack you will be investigating. Agenda Run the second CloudFormation template \u2013 5 min Threat detection and response presentation \u2013 25 min Deploy the CloudFormation template To initiate the attack simulation you will need to run the module 2 CloudFormation template: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. The name of the stack will be automatically populated but you are free to change it, after which click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and click Create This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status as shown below. Threat detection and response presentation Below is a diagram of the setup after the module 2 CloudFormation stack is created. If you are going through this workshop in a classroom setting then wait till the presentation is over before starting module 3 (the presentation will allow enough time to pass for the attack scenario to complete.) If you are going through this workshop outside of a classroom setting you can proceed to Module 3. Please note it will take at least 20 minutes after the 2nd CloudFormation template has completed before you will start seeing findings.","title":"Module 2: Attack Simulation"},{"location":"level-300/threat-detection-remediation/02-attack-simulation/#module-2-attack-simulation","text":"Now that you have detective and responsive controls setup, you'll be running another CloudFormation template which will simulate the actual attack you will be investigating. Agenda Run the second CloudFormation template \u2013 5 min Threat detection and response presentation \u2013 25 min","title":"Module 2: Attack Simulation"},{"location":"level-300/threat-detection-remediation/02-attack-simulation/#deploy-the-cloudformation-template","text":"To initiate the attack simulation you will need to run the module 2 CloudFormation template: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. The name of the stack will be automatically populated but you are free to change it, after which click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and click Create This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status as shown below.","title":"Deploy the CloudFormation template"},{"location":"level-300/threat-detection-remediation/02-attack-simulation/#threat-detection-and-response-presentation","text":"Below is a diagram of the setup after the module 2 CloudFormation stack is created. If you are going through this workshop in a classroom setting then wait till the presentation is over before starting module 3 (the presentation will allow enough time to pass for the attack scenario to complete.) If you are going through this workshop outside of a classroom setting you can proceed to Module 3. Please note it will take at least 20 minutes after the 2nd CloudFormation template has completed before you will start seeing findings.","title":"Threat detection and response presentation"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/","text":"Module 3: Detection and Remediation Unfortunately, due to a misconfiguration in your environment, a hacker has been able to gain access to your webserver. Now, with the intruder in your environment you\u2019re getting alerts from the security tools you\u2019ve put in place indicating nefarious activity. These alerts include communication with known malicious IP addresses, account reconnaissance, changes to S3 policies, and disabling security configurations. You must identify exactly what activity the intruder has performed and how they did it so you can block the intruder\u2019s access, remediate the vulnerabilities, and restore the configuration to its proper state. Agenda Detect, respond remediate \u2013 30 min Find out what's happening! You\u2019ve received the first alerts from GuardDuty. Now what? Since the alert came from GuardDuty, we will check there first. Check GuardDuty findings Go to the Amazon GuardDuty console. In the navigation pane, click on Findings . You should see all the findings below: Don't panic if all of these findings fail to show up at first. The findings generated will take at least 20 minutes to show up in the GuardDuty console. 3. The high severity UnauthorizedAccess:EC2/SSHBruteForce finding is a result of the activity going on in the background to simulate the attack and can be ignored. You can archive the finding if you choose with the steps below: Click on the check box next to the \" UnauthorizedAccess:EC2/SSHBruteForce \" Finding . Click on Actions . * Select Archive . If you're interested in seeing all of your findings (current and archived) you can click on the filter icon to the left of Add filter criteria to toggle them in the console. After archiving you should have four findings that are associated with this workshop. 4. Now let's examine the low severity UnauthorizedAccess:EC2/SSHBruteForce finding since this was one of the first findings to show up. Click on the Finding . Review the Resource affected and other sections in the window that popped open on the right. Copy down the GuardDuty Finding ID and the Instance ID . Was the brute force attack successful? Check Inspector assessment and CloudWatch logs Following security design best practices you already setup your instances to send certain logs to CloudWatch. You\u2019ve also setup a CloudWatch event rule that runs an AWS Inspector scan when GuardDuty detects a particular attack. Let\u2019s look at the Inspector findings to see if the SSH configuration adheres to best practices to determine what the risk is for the brute force attack. We will then examine the CloudWatch logs. Go to Amazon Inspector in the Amazon Console. Click Findings on the left navigation. If you do not see any findings after awhile, there may have been an issue with your Inspector agent. Click on Assessment Templates , check the template that starts with threat-detection-wksp , and click Run . Please allow 15 minutes for the scan to complete. You can also look in Assessment runs and check the status . Feel free to continue through this module and check the results later on. Filter down the findings by typing in Password . Review the findings. Which Inspector rule packages were used for this scan? Based on the findings you see that password authentication is configured on the instance with no password complexity restrictions which means the instance is more susceptible to a SSH brute force attack. Now that we know that let\u2019s look at the CloudWatch logs and create a metric to see if there are any successful SSH logins (to finally answer the question of whether the SSH brute force attack was successful.) Go to CloudWatch logs . Click on the log group /threat-detection-wksp/var/log/secure If you have multiple log streams, filter using the Instance ID you copied earlier and click on the stream. Within the Filter Events text-box put the following Filter Pattern: bash [Mon, day, timestamp, ip, id, msg1= Invalid, msg2 = user, ...] Do you see any failed (invalid user) attempts to log into the instance? 9. Now replace the Filter with one for successful attempts: [Mon, day, timestamp, ip, id, msg1= Accepted, msg2 = password, ...] Do you see any successful attempts to log into the instance? Which linux user was compromised? Check the remaining GuardDuty findings Now that you have verified that the brute force attack was successful and your instance was compromised, go back to the Amazon GuardDuty console and view the other findings. Does it look like you are early in identifying the attack (just intrusion), or has the intruder started performing malicious actions? View the following GuardDuty findings and take a note of the resources involved: Recon:IAMUser/MaliciousIPCaller.Custom UnauthorizedAccess:IAMUser/MaliciousIPCaller.Custom UnauthorizedAccess:EC2/MaliciousIPCaller.Custom You can see by these findings that the compromised instance is communicating with an IP address on your custom threat list and that API calls are being made from a host on your custom threat list. The API calls are being made using AWS IAM temporary security credentials coming from an IAM Role for EC2. How could you determine this fact yourself? Check if sensitive data was involved At this point you know how the attacker was able to get into your systems and a general idea of what they did. If you review the permissions associated with the IAM Role attached to the compromised instance you will notice that it has a very permissive policy as it relates to your S3 data bucket. Verify what sort of sensitive data is in your bucket and take a closer at your Macie Alerts. Go to the Amazon Macie console. Look through the latest alerts. Do you see any critical alerts? Next lets verify what sort of sensitive data exists in that bucket. Click Dashboard on the left navigation. You should see the following data classifications: You can slide the risk slider to filter data classifications based on risk levels. Above the risk slider, click the S3 Public Objects and Buckets icon. Click the magnifying glass to the left of the bucket name listed. Check if any of the data in the bucket is considered a high risk Look for the Object PII priority field and Object risk level field Verify if any of the data is unencrypted Look for the Object encryption field. (Does a portion of the blue bar indicate that encryption is set to none?) At this point you have identified that there is a bucket with high risk data that has open public read permissions and that certain objects in that bucket are not encrypted. When you first configured the environment you enabled default encryption for the bucket so this could be an indicator that someone has disabled it. Since you are already in the Macie service, create a new Basic Alert that will alert you in the future if default encryption is disabled on any of your buckets. Click on Settings in the left navigation and then Basic Alerts . Click on Add New Create an alert with the following parameters: Alert title : Encryption Removed Description : Evidence of encryption being removed from a bucket Category : Data Compliance Query : eventNameErrorCode.key:DeleteBucketEncryption Macie allows you to create queries using the Apache Lucene Query Parser Syntax . The query created for this alert uses the Macie field name eventNameErrorCode.key which corresponds to the CloudTrail field name eventName . Index : CloudTrail Data Severity : Critical You can leave the other options at the default settings 10. Click Save 11. In the list of alerts find the alert you just created and click on the magnifying glass to the right of the screen to run the alert. 12. Review the alert details. Next you need to track down if someone recently disabled default encryption and who did it. Go to the AWS CloudTrail console Click Event History on the left navigation. Set the Filter to Event name and for the event name enter DeleteBucketEncryption . Set the Time Range to today. Expand the latest event and click on View Event to see the details of the API call. Which AWS IAM Role disabled default encryption on the S3 Bucket? Is this the same AWS IAM Role seen in your GuardDuty findings? Stop and evaluate So at this point you have identified a successful intrusion into your network and specific actions taken against your account. Let\u2019s recap what those are: A SSH brute force attack against an internet accessible EC2 instance was successful. The EC2 instance communicated with a known malicious IP address (possibly indicating that malware was installed.) The IAM credentials for the instance were stolen, published to S3, and used to perform reconnaissance against the account. An S3 bucket was made public and encryption was removed - most likely for data exfiltration. Now that you've identified the attacker\u2019s actions you need to stop them from performing any additional activities, restore your systems to their previous configurations, and protect your resources so this can\u2019t happen again. Respond and remediate Before we get ahead of ourselves, we must stop any further actions from taking place. This requires removing the foothold in our environment, revoking any active credentials or removing those credentials' capabilities, and blocking further actions by the attacker. Verify your automated remediation Based upon your existing work, you\u2019ve implemented the first step by using the CloudWatch Event rule to trigger the Lambda function to update the NACL for the subnet that the instance is located in. Let\u2019s look at what changed. Go to the AWS Config console. You may initially see the following message (if you don't see the message just go on to the next step): Click the Click Here button to proceed with using Config without Config Rules Click Resources in the left navigation. We can search here to find configuration changes to the NACL. Select the radio button for Tag and enter Name for the Tag key and threat-detection-wksp-compromised for the Tag value (this is allowing us to search for the NACL with that name): Click on the Network ACL ID in the Config timeline column. On the next screen you should see two Change events in the timeline. Click on Change for each one to see what occurred. Evaluate the NACL changes. What does the new NACL rule do? Modify the security group Now that the active session from the attacker has been stopped by the update to the NACL, you need to modify the Security Group associated with the instance to prevent the attacker or anyone else from coming from a different IP. Go to the Amazon EC2 Console. Find the running instances with the name threat-detection-wksp: Compromised Instance . Under the Description tab, click on the Security Group for the compromised instance. View the rules under the Inbound tab. Click Edit and delete the inbound SSH rule. You've decided that all administration on EC2 Instances will be done through AWS Systems Manager so you no longer need this port open. In your initial setup you already installed the SSM Agent on your EC2 Instance. 6. Click Save Revoke the IAM role active sessions and rotate credentials Now that the attacker can\u2019t SSH into the compromised instance, you need to revoke all active sessions for the IAM role associated with that instance. First verify what the current credentials are for the EC2 instance. Go to AWS Systems Manager console and click Managed Instances (found under the Shared Resources section on the left navigation). You should see an instance named threat-detection-wksp: Compromised Instance with a Ping status of Online . 2. To see the keys currently active on the instance, click on Run Command on the left navigation and then click Run a Command . 4. For Command document select AWS-RunShellScript You may need to scroll through the list or just enter the document name in the search bar. 5. Leave the Document version at the default. 6. Under Command Parameters type the following in Commands : curl http://169.254.169.254/latest/meta-data/iam/security-credentials/threat-detection-wksp-compromised-ec2 7. Under Targets select Manually selecting instances and check the checkbox next to threat-detection-wksp: Compromised Instance . 8. Under Output options uncheck the checkbox labeled Enable writing to an S3 bucket . 9. Leave all of the other options at their default, scroll to the end and click Run . 8. Scroll down to the Targets and outputs section and click the Instance ID (which should correspond to the instance ID of the compromised instance) 10. Expand Step 1 - Output and make note of the AccessKeyID , SecretAccessKey , and Token . (the command will take a minute or so to run) Now revoke the IAM Role session: Browse to the AWS IAM console. Click Roles and the threat-detection-wksp-compromised-ec2 role (this is the role attached to the compromised instance). Click on the Revoke sessions tab. Click on Revoke active sessions . Click the acknowledgement check box and then click Revoke active sessions . What is the mechanism that is put in place by this step to actually prevent the use of the temp credentials issued by this role? Restart instance to rotate credentials Now all active sessions for the compromised instance role have been invalidated. This means the attacker can no longer use those credentials, but it also means that your application that use this role can't as well. In order to ensure the availability of your application you need to refresh the credentials on the instance. To change the IAM credentials on the instance, you must Stop and Start the instance. A simple reboot will not change the keys. Since you are using AWS Systems Manager for doing administration on your EC2 Instances you can use it to query the metadata to validate that the credentials were rotated. In the EC2 console Stop the Instance named threat-detection-wksp: Compromised Instance . Wait for the Instance State to say Stopped and then Start the instance. Lastly, you can need to query the metadata again to validate that the credentials were changed. Repeat the first 10 Systems Manager steps to retrieve the credentials again. Notice the keys are different. If you want, try again after rebooting the instance. The keys will stay the same. This is a good use case for auto-scaling groups and golden-image AMI\u2019s, but that is out of scope for this workshop. Also out of scope is clearing the suspected malware. Limit S3 access With the EC2 instance access scoped down and the IAM credentials revoked, we need to stop external access to the S3 bucket. Before we restore the previous configuration, we can quickly make the bucket only accessible from inside the VPC. Then we can re-enable encryption. First, check the configuration of the S3 endpoint in your environment by going to Amazon VPC and clicking on Endpoints on the left navigation. Copy the Endpoint ID (if there are multiple endpoints, look for the one with the VPC ID that ends in threat-detection-wksp ) Click the Policy tab and review the policy statement. Notice that all access is allowed. Click the Route Tables tab to get the Route Table ID associated with this endpoint. You can then go to the VPC to see which subnets are associated with this route table and therefore the endpoint. Notice that routing to S3 is through the VPC endpoint Go to the Amazon S3 console. Click the bucket that starts with threat-detection-wksp- and ends in -data . Click on the Permissions tab. Click Bucket Policy Update the Bucket Policy with the following policy: { \"Version\": \"2012-10-17\", \"Id\": \"Policy1415115909152\", \"Statement\": [ { \"Sid\": \"Access-to-specific-VPCE-only\", \"Principal\": \"*\", \"Action\": \"s3:GetObject\", \"Effect\": \"Deny\", \"Resource\": [\"arn:aws:s3::: BUCKETNAME \", \"arn:aws:s3::: BUCKETNAME /*\"], \"Condition\": { \"StringNotEquals\": { \"aws:sourceVpce\": \" VPCENDPOINTID \" } } } ] } Be sure to replace with the name of the bucket and with endpoint ID you copied down earlier. Click Save . Now regardless of the bucket\u2019s Access Control List, if the request for get object isn\u2019t coming from the VPC endpoint it will be denied. This also provides more security and better pricing for legitimate traffic. Is there still a problem with the bucket permissions given the Access Control List that is still in place? To quickly restore the previous configuration for this bucket, we start by going to the AWS Config console. Under Resources click on S3 Bucket . Click on your Bucket (bucket name starts with threat-detection-wksp- and ends in -data ). Click on Change under the previous configuration in the slider at the top of the screen Make note of the changes to Permissions Click on Manage Resource in the top right. This will take you to the S3 console. Click on the Permissions tab. Remove Public Access based on Config change you just looked at. Click on the Properties Tab. Re-enable S3 Default AES-256 encryption. With the configuration reestablished and some additional protections in place, you can focus on alerts and automated remediations in the event of another attack. After you have remediated the incident and further hardened your environment, you can proceed to the next module. If you are going through this workshop in a classroom setting then the instructor should start the module 4 presentation soon.","title":"Module 3: Detect & Respond"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/#module-3-detection-and-remediation","text":"Unfortunately, due to a misconfiguration in your environment, a hacker has been able to gain access to your webserver. Now, with the intruder in your environment you\u2019re getting alerts from the security tools you\u2019ve put in place indicating nefarious activity. These alerts include communication with known malicious IP addresses, account reconnaissance, changes to S3 policies, and disabling security configurations. You must identify exactly what activity the intruder has performed and how they did it so you can block the intruder\u2019s access, remediate the vulnerabilities, and restore the configuration to its proper state.","title":"Module 3: Detection and Remediation"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/#agenda","text":"Detect, respond remediate \u2013 30 min","title":"Agenda"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/#find-out-whats-happening","text":"You\u2019ve received the first alerts from GuardDuty. Now what? Since the alert came from GuardDuty, we will check there first.","title":"Find out what's happening!"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/#check-guardduty-findings","text":"Go to the Amazon GuardDuty console. In the navigation pane, click on Findings . You should see all the findings below: Don't panic if all of these findings fail to show up at first. The findings generated will take at least 20 minutes to show up in the GuardDuty console. 3. The high severity UnauthorizedAccess:EC2/SSHBruteForce finding is a result of the activity going on in the background to simulate the attack and can be ignored. You can archive the finding if you choose with the steps below: Click on the check box next to the \" UnauthorizedAccess:EC2/SSHBruteForce \" Finding . Click on Actions . * Select Archive . If you're interested in seeing all of your findings (current and archived) you can click on the filter icon to the left of Add filter criteria to toggle them in the console. After archiving you should have four findings that are associated with this workshop. 4. Now let's examine the low severity UnauthorizedAccess:EC2/SSHBruteForce finding since this was one of the first findings to show up. Click on the Finding . Review the Resource affected and other sections in the window that popped open on the right. Copy down the GuardDuty Finding ID and the Instance ID . Was the brute force attack successful?","title":"Check GuardDuty findings"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/#check-inspector-assessment-and-cloudwatch-logs","text":"Following security design best practices you already setup your instances to send certain logs to CloudWatch. You\u2019ve also setup a CloudWatch event rule that runs an AWS Inspector scan when GuardDuty detects a particular attack. Let\u2019s look at the Inspector findings to see if the SSH configuration adheres to best practices to determine what the risk is for the brute force attack. We will then examine the CloudWatch logs. Go to Amazon Inspector in the Amazon Console. Click Findings on the left navigation. If you do not see any findings after awhile, there may have been an issue with your Inspector agent. Click on Assessment Templates , check the template that starts with threat-detection-wksp , and click Run . Please allow 15 minutes for the scan to complete. You can also look in Assessment runs and check the status . Feel free to continue through this module and check the results later on. Filter down the findings by typing in Password . Review the findings. Which Inspector rule packages were used for this scan? Based on the findings you see that password authentication is configured on the instance with no password complexity restrictions which means the instance is more susceptible to a SSH brute force attack. Now that we know that let\u2019s look at the CloudWatch logs and create a metric to see if there are any successful SSH logins (to finally answer the question of whether the SSH brute force attack was successful.) Go to CloudWatch logs . Click on the log group /threat-detection-wksp/var/log/secure If you have multiple log streams, filter using the Instance ID you copied earlier and click on the stream. Within the Filter Events text-box put the following Filter Pattern: bash [Mon, day, timestamp, ip, id, msg1= Invalid, msg2 = user, ...] Do you see any failed (invalid user) attempts to log into the instance? 9. Now replace the Filter with one for successful attempts: [Mon, day, timestamp, ip, id, msg1= Accepted, msg2 = password, ...] Do you see any successful attempts to log into the instance? Which linux user was compromised?","title":"Check Inspector assessment and CloudWatch logs"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/#check-the-remaining-guardduty-findings","text":"Now that you have verified that the brute force attack was successful and your instance was compromised, go back to the Amazon GuardDuty console and view the other findings. Does it look like you are early in identifying the attack (just intrusion), or has the intruder started performing malicious actions? View the following GuardDuty findings and take a note of the resources involved: Recon:IAMUser/MaliciousIPCaller.Custom UnauthorizedAccess:IAMUser/MaliciousIPCaller.Custom UnauthorizedAccess:EC2/MaliciousIPCaller.Custom You can see by these findings that the compromised instance is communicating with an IP address on your custom threat list and that API calls are being made from a host on your custom threat list. The API calls are being made using AWS IAM temporary security credentials coming from an IAM Role for EC2. How could you determine this fact yourself?","title":"Check the remaining GuardDuty findings"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/#check-if-sensitive-data-was-involved","text":"At this point you know how the attacker was able to get into your systems and a general idea of what they did. If you review the permissions associated with the IAM Role attached to the compromised instance you will notice that it has a very permissive policy as it relates to your S3 data bucket. Verify what sort of sensitive data is in your bucket and take a closer at your Macie Alerts. Go to the Amazon Macie console. Look through the latest alerts. Do you see any critical alerts? Next lets verify what sort of sensitive data exists in that bucket. Click Dashboard on the left navigation. You should see the following data classifications: You can slide the risk slider to filter data classifications based on risk levels. Above the risk slider, click the S3 Public Objects and Buckets icon. Click the magnifying glass to the left of the bucket name listed. Check if any of the data in the bucket is considered a high risk Look for the Object PII priority field and Object risk level field Verify if any of the data is unencrypted Look for the Object encryption field. (Does a portion of the blue bar indicate that encryption is set to none?) At this point you have identified that there is a bucket with high risk data that has open public read permissions and that certain objects in that bucket are not encrypted. When you first configured the environment you enabled default encryption for the bucket so this could be an indicator that someone has disabled it. Since you are already in the Macie service, create a new Basic Alert that will alert you in the future if default encryption is disabled on any of your buckets. Click on Settings in the left navigation and then Basic Alerts . Click on Add New Create an alert with the following parameters: Alert title : Encryption Removed Description : Evidence of encryption being removed from a bucket Category : Data Compliance Query : eventNameErrorCode.key:DeleteBucketEncryption Macie allows you to create queries using the Apache Lucene Query Parser Syntax . The query created for this alert uses the Macie field name eventNameErrorCode.key which corresponds to the CloudTrail field name eventName . Index : CloudTrail Data Severity : Critical You can leave the other options at the default settings 10. Click Save 11. In the list of alerts find the alert you just created and click on the magnifying glass to the right of the screen to run the alert. 12. Review the alert details. Next you need to track down if someone recently disabled default encryption and who did it. Go to the AWS CloudTrail console Click Event History on the left navigation. Set the Filter to Event name and for the event name enter DeleteBucketEncryption . Set the Time Range to today. Expand the latest event and click on View Event to see the details of the API call. Which AWS IAM Role disabled default encryption on the S3 Bucket? Is this the same AWS IAM Role seen in your GuardDuty findings?","title":"Check if sensitive data was involved"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/#stop-and-evaluate","text":"So at this point you have identified a successful intrusion into your network and specific actions taken against your account. Let\u2019s recap what those are: A SSH brute force attack against an internet accessible EC2 instance was successful. The EC2 instance communicated with a known malicious IP address (possibly indicating that malware was installed.) The IAM credentials for the instance were stolen, published to S3, and used to perform reconnaissance against the account. An S3 bucket was made public and encryption was removed - most likely for data exfiltration. Now that you've identified the attacker\u2019s actions you need to stop them from performing any additional activities, restore your systems to their previous configurations, and protect your resources so this can\u2019t happen again.","title":"Stop and evaluate"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/#respond-and-remediate","text":"Before we get ahead of ourselves, we must stop any further actions from taking place. This requires removing the foothold in our environment, revoking any active credentials or removing those credentials' capabilities, and blocking further actions by the attacker.","title":"Respond and remediate"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/#verify-your-automated-remediation","text":"Based upon your existing work, you\u2019ve implemented the first step by using the CloudWatch Event rule to trigger the Lambda function to update the NACL for the subnet that the instance is located in. Let\u2019s look at what changed. Go to the AWS Config console. You may initially see the following message (if you don't see the message just go on to the next step): Click the Click Here button to proceed with using Config without Config Rules Click Resources in the left navigation. We can search here to find configuration changes to the NACL. Select the radio button for Tag and enter Name for the Tag key and threat-detection-wksp-compromised for the Tag value (this is allowing us to search for the NACL with that name): Click on the Network ACL ID in the Config timeline column. On the next screen you should see two Change events in the timeline. Click on Change for each one to see what occurred. Evaluate the NACL changes. What does the new NACL rule do?","title":"Verify your automated remediation"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/#modify-the-security-group","text":"Now that the active session from the attacker has been stopped by the update to the NACL, you need to modify the Security Group associated with the instance to prevent the attacker or anyone else from coming from a different IP. Go to the Amazon EC2 Console. Find the running instances with the name threat-detection-wksp: Compromised Instance . Under the Description tab, click on the Security Group for the compromised instance. View the rules under the Inbound tab. Click Edit and delete the inbound SSH rule. You've decided that all administration on EC2 Instances will be done through AWS Systems Manager so you no longer need this port open. In your initial setup you already installed the SSM Agent on your EC2 Instance. 6. Click Save","title":"Modify the security group"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/#revoke-the-iam-role-active-sessions-and-rotate-credentials","text":"Now that the attacker can\u2019t SSH into the compromised instance, you need to revoke all active sessions for the IAM role associated with that instance. First verify what the current credentials are for the EC2 instance. Go to AWS Systems Manager console and click Managed Instances (found under the Shared Resources section on the left navigation). You should see an instance named threat-detection-wksp: Compromised Instance with a Ping status of Online . 2. To see the keys currently active on the instance, click on Run Command on the left navigation and then click Run a Command . 4. For Command document select AWS-RunShellScript You may need to scroll through the list or just enter the document name in the search bar. 5. Leave the Document version at the default. 6. Under Command Parameters type the following in Commands : curl http://169.254.169.254/latest/meta-data/iam/security-credentials/threat-detection-wksp-compromised-ec2 7. Under Targets select Manually selecting instances and check the checkbox next to threat-detection-wksp: Compromised Instance . 8. Under Output options uncheck the checkbox labeled Enable writing to an S3 bucket . 9. Leave all of the other options at their default, scroll to the end and click Run . 8. Scroll down to the Targets and outputs section and click the Instance ID (which should correspond to the instance ID of the compromised instance) 10. Expand Step 1 - Output and make note of the AccessKeyID , SecretAccessKey , and Token . (the command will take a minute or so to run) Now revoke the IAM Role session: Browse to the AWS IAM console. Click Roles and the threat-detection-wksp-compromised-ec2 role (this is the role attached to the compromised instance). Click on the Revoke sessions tab. Click on Revoke active sessions . Click the acknowledgement check box and then click Revoke active sessions . What is the mechanism that is put in place by this step to actually prevent the use of the temp credentials issued by this role?","title":"Revoke the IAM role active sessions and rotate credentials"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/#restart-instance-to-rotate-credentials","text":"Now all active sessions for the compromised instance role have been invalidated. This means the attacker can no longer use those credentials, but it also means that your application that use this role can't as well. In order to ensure the availability of your application you need to refresh the credentials on the instance. To change the IAM credentials on the instance, you must Stop and Start the instance. A simple reboot will not change the keys. Since you are using AWS Systems Manager for doing administration on your EC2 Instances you can use it to query the metadata to validate that the credentials were rotated. In the EC2 console Stop the Instance named threat-detection-wksp: Compromised Instance . Wait for the Instance State to say Stopped and then Start the instance. Lastly, you can need to query the metadata again to validate that the credentials were changed. Repeat the first 10 Systems Manager steps to retrieve the credentials again. Notice the keys are different. If you want, try again after rebooting the instance. The keys will stay the same. This is a good use case for auto-scaling groups and golden-image AMI\u2019s, but that is out of scope for this workshop. Also out of scope is clearing the suspected malware.","title":"Restart instance to rotate credentials"},{"location":"level-300/threat-detection-remediation/03-detection-and-remediation/#limit-s3-access","text":"With the EC2 instance access scoped down and the IAM credentials revoked, we need to stop external access to the S3 bucket. Before we restore the previous configuration, we can quickly make the bucket only accessible from inside the VPC. Then we can re-enable encryption. First, check the configuration of the S3 endpoint in your environment by going to Amazon VPC and clicking on Endpoints on the left navigation. Copy the Endpoint ID (if there are multiple endpoints, look for the one with the VPC ID that ends in threat-detection-wksp ) Click the Policy tab and review the policy statement. Notice that all access is allowed. Click the Route Tables tab to get the Route Table ID associated with this endpoint. You can then go to the VPC to see which subnets are associated with this route table and therefore the endpoint. Notice that routing to S3 is through the VPC endpoint Go to the Amazon S3 console. Click the bucket that starts with threat-detection-wksp- and ends in -data . Click on the Permissions tab. Click Bucket Policy Update the Bucket Policy with the following policy: { \"Version\": \"2012-10-17\", \"Id\": \"Policy1415115909152\", \"Statement\": [ { \"Sid\": \"Access-to-specific-VPCE-only\", \"Principal\": \"*\", \"Action\": \"s3:GetObject\", \"Effect\": \"Deny\", \"Resource\": [\"arn:aws:s3::: BUCKETNAME \", \"arn:aws:s3::: BUCKETNAME /*\"], \"Condition\": { \"StringNotEquals\": { \"aws:sourceVpce\": \" VPCENDPOINTID \" } } } ] } Be sure to replace with the name of the bucket and with endpoint ID you copied down earlier. Click Save . Now regardless of the bucket\u2019s Access Control List, if the request for get object isn\u2019t coming from the VPC endpoint it will be denied. This also provides more security and better pricing for legitimate traffic. Is there still a problem with the bucket permissions given the Access Control List that is still in place? To quickly restore the previous configuration for this bucket, we start by going to the AWS Config console. Under Resources click on S3 Bucket . Click on your Bucket (bucket name starts with threat-detection-wksp- and ends in -data ). Click on Change under the previous configuration in the slider at the top of the screen Make note of the changes to Permissions Click on Manage Resource in the top right. This will take you to the S3 console. Click on the Permissions tab. Remove Public Access based on Config change you just looked at. Click on the Properties Tab. Re-enable S3 Default AES-256 encryption. With the configuration reestablished and some additional protections in place, you can focus on alerts and automated remediations in the event of another attack. After you have remediated the incident and further hardened your environment, you can proceed to the next module. If you are going through this workshop in a classroom setting then the instructor should start the module 4 presentation soon.","title":"Limit S3 access"},{"location":"level-300/threat-detection-remediation/04-review-and-discussion/","text":"Module 4: Review and Discussion In the last module we will have a short discussion of the lab (and discuss exactly what occurred.) We will also go over a number of questions and then provide instructions on how to clean up the lab environment (to prevent future charges in your AWS account.) Agenda Review Discussion \u2013 10 min Questions \u2013 10 min Cleanup \u2013 5 min Architecture Overview Diagram of the overall lab setup: What is Really Going On? In Module 1 of the lab you setup the initial components of your infrastructure including GuardDuty, Macie and a simple notification and remediation pipeline. Some of the steps required manual configuration but you also ran a CloudFormation template which setup some of the components. In Module 2 you launched a second CloudFormation template that initiated the attack simulated by this lab. The CloudFormation template created two EC2 instances. One instance (named Malicious Host ) had an EIP attached to it that was added to your GuardDuty custom threat list. Although the Malicious Host is in the same VPC as the other instance, for the sake of the scenario (and to prevent the need to submit a penetration testing request) we acted as if it is on the Internet and represented the attack's computer. The other instance (named Compromised Instance ) was your web server and it was taken over by the Malicious Host . In Module 3 you investigated the attack, remediated the damage, and setup some automated remediations for future attacks. Here is what occurred in the attack: There are two instances created by the Module 2 CloudFormation template. They are in the same VPC but different subnets. The Malicious Host represents the attacker which we pretend is on the Internet. The Elastic IP on the Malicious Host is in a custom threat list in GuardDuty. The other instance named Compromised Instance represents the web server that was lifted and shifted into AWS. Although company policy is that only key-based authentication should be enabled for SSH, at some point password authentication for SSH was enabled on the Compromised Instance . This misconfiguration is identified in the Inspector scan that is triggered from the GuardDuty finding. The Malicious Host performed a brute force SSH password attack against the Compromised Instance . The brute force attack is designed to be successful. GuardDuty Finding : UnauthorizedAccess:EC2/SSHBruteForce The SSH brute force attack was successful and the attacker was able to log in to the Compromised Instance . Successful login is confirmed in CloudWatch Logs (/threat-detection-wksp/var/log/secure). The EC2 Instance that is created in the Module 2 CloudFormation template disabled default encryption on the Data bucket. In addition the CloudFormation template made the Data bucket public. This is used for the Macie part of the investigation in Module 3. We pretend that the attacker made the bucket public and removed the default encryption from the bucket. Macie Alert : S3 Bucket IAM policy grants global read rights The Compromised Instance also has a cron job that continuously pings the Malicious Host to generate a GuardDuty finding based off the custom threat list. GuardDuty Finding : UnauthorizedAccess:EC2/MaliciousIPCaller.Custom The API Calls that generated the API findings come from the Malicious Host . The calls use the temp creds from the IAM role for EC2 running on the Malicious Host . The GuardDuty findings are generated because the EIP attached to the Malicious Host is in a custom threat list. GuardDuty Finding : Recon:IAMUser/MaliciousIPCaller.Custom GuardDuty Finding : UnauthorizedAccess:IAMUser/MaliciousIPCaller.Custom A number of CloudWatch Events Rules are evoked by the GuardDuty findings and then these trigger various services. CloudWatch Event Rule : The generic GuardDuty finding invokes a CloudWatch Event rule which triggers SNS to send an email. CloudWatch Event Rule : The generic Macie alert invokes a CloudWatch Event rule which triggers SNS to send an email. CloudWatch Event Rule : The SSH brute force attack finding invokes a CloudWatch Event rule which triggers a Lambda function to block the attacker IP address of the attacker via a NACL as well as a Lambda function that runs an Inspector scan on the EC2 instance. CloudWatch Event Rule : The Unauthorized Access Custom MaliciousIP finding invokes a CloudWatch Event rule which triggers a Lambda function to block the IP address of the attacker via a NACL. Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the lab a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forgot about it, and then accrue charges. You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete the Inspector objects created for the workshop. Go to the Amazon Inspector console. Click on Assessment targets in the navigation pane on the left. Delete all that start with threat-detection-wksp . Delete the IAM Role for the compromised EC2 instance and the Service-Linked Role for Inspector (if you didn't already have this Role created). Go to AWS IAM console. Click on Roles Search for the role named threat-detection-wksp-compromised-ec2 . Click the check box next to it and click Delete . Repeat the steps above for the role named AWSServiceRoleForAmazonInspector . Delete all three S3 buckets created by the Module 1 CloudFormation template (the buckets that start with threat-detection-wksp and end with -data , -threatlist and -logs ) Go to Amazon S3 console. Click on the appropiate bucket. Click Delete Bucket . Copy and paste the name of the bucket (this is an extra verification that you actually want to delete the bucket). Repeat the steps above for all three buckets. Delete Module 1 and 2 CloudFormation stacks ( ThreatDetectionWksp-Env-Setup and ThreatDetectionWksp-Attacks ). Go to the AWS CloudFormation console. Select the appropiate stack. Select Action . Click Delete Stack . Repeat the steps above for each stack. You do not need to wait for the first stack to delete before you delete the second one. Delete the GuardDuty custom threat list and disable GuardDuty (if you didn't already have it configured before the workshop) Go to the Amazon GuardDuty console. Click on Lists on the left navigation. Click the X next to the threat list that starts with Custom-Threat-List . Click Settings in the navigation pane on the left navigation. Click the check box next to Disable . Click Save settings and then click Disable in the pop-up box. Delete the manual CloudWatch Event Rule you created and the CloudWatch Logs that were generated. Go to the AWS CloudWatch console. Click on Rules in the navigation pane on the left. Click the radio button next threat-detection-wksp-guardduty-finding-maliciousip . Select Action and click Delete . Click on Logs in the navigation pane on the left. Click the radio button next to /aws/lambda/threat-detection-wksp-inspector-role-creation . Select Action and click Delete log group and then click Yes, Delete in the pop-up box. Repeat for: /aws/lambda/threat-detection-wksp-remediation-inspector /aws/lambda/threat-detection-wksp-remediation-nacl /threat-detection-wksp/var/log/secure Delete the SNS subscription that was created when you subscribed to SNS Topic. Go to the AWS SNS console. Click on Subscriptions on the left navigation. Select the check box next to the subscription that shows your e-mail as the Endpoint and has threat-detection-wksp in the Subscription ARN . Select Action and then click Delete subscriptions Disable Macie (if you didn't already have Macie enabled before the workshop). Go the Amazon Macie console. In the upper right-hand corner select the down arrow to the left of the Region and select Macie General Settings . Check the two boxes and click Disable Amazon Macie Disabling Macie will actually log you out of the AWS Console so you will need to log back to do any other tasks. Finished! Congratulations on completing this workshop! This is the workshop's permanent home, so feel free to revisit as often as you'd like.","title":"Module 4: Discussion"},{"location":"level-300/threat-detection-remediation/04-review-and-discussion/#module-4-review-and-discussion","text":"In the last module we will have a short discussion of the lab (and discuss exactly what occurred.) We will also go over a number of questions and then provide instructions on how to clean up the lab environment (to prevent future charges in your AWS account.)","title":"Module 4: Review and Discussion"},{"location":"level-300/threat-detection-remediation/04-review-and-discussion/#agenda","text":"Review Discussion \u2013 10 min Questions \u2013 10 min Cleanup \u2013 5 min","title":"Agenda"},{"location":"level-300/threat-detection-remediation/04-review-and-discussion/#architecture-overview","text":"Diagram of the overall lab setup:","title":"Architecture Overview"},{"location":"level-300/threat-detection-remediation/04-review-and-discussion/#what-is-really-going-on","text":"In Module 1 of the lab you setup the initial components of your infrastructure including GuardDuty, Macie and a simple notification and remediation pipeline. Some of the steps required manual configuration but you also ran a CloudFormation template which setup some of the components. In Module 2 you launched a second CloudFormation template that initiated the attack simulated by this lab. The CloudFormation template created two EC2 instances. One instance (named Malicious Host ) had an EIP attached to it that was added to your GuardDuty custom threat list. Although the Malicious Host is in the same VPC as the other instance, for the sake of the scenario (and to prevent the need to submit a penetration testing request) we acted as if it is on the Internet and represented the attack's computer. The other instance (named Compromised Instance ) was your web server and it was taken over by the Malicious Host . In Module 3 you investigated the attack, remediated the damage, and setup some automated remediations for future attacks.","title":"What is Really Going On?"},{"location":"level-300/threat-detection-remediation/04-review-and-discussion/#here-is-what-occurred-in-the-attack","text":"There are two instances created by the Module 2 CloudFormation template. They are in the same VPC but different subnets. The Malicious Host represents the attacker which we pretend is on the Internet. The Elastic IP on the Malicious Host is in a custom threat list in GuardDuty. The other instance named Compromised Instance represents the web server that was lifted and shifted into AWS. Although company policy is that only key-based authentication should be enabled for SSH, at some point password authentication for SSH was enabled on the Compromised Instance . This misconfiguration is identified in the Inspector scan that is triggered from the GuardDuty finding. The Malicious Host performed a brute force SSH password attack against the Compromised Instance . The brute force attack is designed to be successful. GuardDuty Finding : UnauthorizedAccess:EC2/SSHBruteForce The SSH brute force attack was successful and the attacker was able to log in to the Compromised Instance . Successful login is confirmed in CloudWatch Logs (/threat-detection-wksp/var/log/secure). The EC2 Instance that is created in the Module 2 CloudFormation template disabled default encryption on the Data bucket. In addition the CloudFormation template made the Data bucket public. This is used for the Macie part of the investigation in Module 3. We pretend that the attacker made the bucket public and removed the default encryption from the bucket. Macie Alert : S3 Bucket IAM policy grants global read rights The Compromised Instance also has a cron job that continuously pings the Malicious Host to generate a GuardDuty finding based off the custom threat list. GuardDuty Finding : UnauthorizedAccess:EC2/MaliciousIPCaller.Custom The API Calls that generated the API findings come from the Malicious Host . The calls use the temp creds from the IAM role for EC2 running on the Malicious Host . The GuardDuty findings are generated because the EIP attached to the Malicious Host is in a custom threat list. GuardDuty Finding : Recon:IAMUser/MaliciousIPCaller.Custom GuardDuty Finding : UnauthorizedAccess:IAMUser/MaliciousIPCaller.Custom A number of CloudWatch Events Rules are evoked by the GuardDuty findings and then these trigger various services. CloudWatch Event Rule : The generic GuardDuty finding invokes a CloudWatch Event rule which triggers SNS to send an email. CloudWatch Event Rule : The generic Macie alert invokes a CloudWatch Event rule which triggers SNS to send an email. CloudWatch Event Rule : The SSH brute force attack finding invokes a CloudWatch Event rule which triggers a Lambda function to block the attacker IP address of the attacker via a NACL as well as a Lambda function that runs an Inspector scan on the EC2 instance. CloudWatch Event Rule : The Unauthorized Access Custom MaliciousIP finding invokes a CloudWatch Event rule which triggers a Lambda function to block the IP address of the attacker via a NACL.","title":"Here is what occurred in the attack:"},{"location":"level-300/threat-detection-remediation/04-review-and-discussion/#cleanup","text":"In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the lab a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forgot about it, and then accrue charges. You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete the Inspector objects created for the workshop. Go to the Amazon Inspector console. Click on Assessment targets in the navigation pane on the left. Delete all that start with threat-detection-wksp . Delete the IAM Role for the compromised EC2 instance and the Service-Linked Role for Inspector (if you didn't already have this Role created). Go to AWS IAM console. Click on Roles Search for the role named threat-detection-wksp-compromised-ec2 . Click the check box next to it and click Delete . Repeat the steps above for the role named AWSServiceRoleForAmazonInspector . Delete all three S3 buckets created by the Module 1 CloudFormation template (the buckets that start with threat-detection-wksp and end with -data , -threatlist and -logs ) Go to Amazon S3 console. Click on the appropiate bucket. Click Delete Bucket . Copy and paste the name of the bucket (this is an extra verification that you actually want to delete the bucket). Repeat the steps above for all three buckets. Delete Module 1 and 2 CloudFormation stacks ( ThreatDetectionWksp-Env-Setup and ThreatDetectionWksp-Attacks ). Go to the AWS CloudFormation console. Select the appropiate stack. Select Action . Click Delete Stack . Repeat the steps above for each stack. You do not need to wait for the first stack to delete before you delete the second one. Delete the GuardDuty custom threat list and disable GuardDuty (if you didn't already have it configured before the workshop) Go to the Amazon GuardDuty console. Click on Lists on the left navigation. Click the X next to the threat list that starts with Custom-Threat-List . Click Settings in the navigation pane on the left navigation. Click the check box next to Disable . Click Save settings and then click Disable in the pop-up box. Delete the manual CloudWatch Event Rule you created and the CloudWatch Logs that were generated. Go to the AWS CloudWatch console. Click on Rules in the navigation pane on the left. Click the radio button next threat-detection-wksp-guardduty-finding-maliciousip . Select Action and click Delete . Click on Logs in the navigation pane on the left. Click the radio button next to /aws/lambda/threat-detection-wksp-inspector-role-creation . Select Action and click Delete log group and then click Yes, Delete in the pop-up box. Repeat for: /aws/lambda/threat-detection-wksp-remediation-inspector /aws/lambda/threat-detection-wksp-remediation-nacl /threat-detection-wksp/var/log/secure Delete the SNS subscription that was created when you subscribed to SNS Topic. Go to the AWS SNS console. Click on Subscriptions on the left navigation. Select the check box next to the subscription that shows your e-mail as the Endpoint and has threat-detection-wksp in the Subscription ARN . Select Action and then click Delete subscriptions Disable Macie (if you didn't already have Macie enabled before the workshop). Go the Amazon Macie console. In the upper right-hand corner select the down arrow to the left of the Region and select Macie General Settings . Check the two boxes and click Disable Amazon Macie Disabling Macie will actually log you out of the AWS Console so you will need to log back to do any other tasks.","title":"Cleanup"},{"location":"level-300/threat-detection-remediation/04-review-and-discussion/#finished","text":"Congratulations on completing this workshop! This is the workshop's permanent home, so feel free to revisit as often as you'd like.","title":"Finished!"}]}