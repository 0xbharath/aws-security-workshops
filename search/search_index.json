{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AWS Security Workshops Welcome to the AWS security workshops portal! Here you will find a collection of workshops aimed at helping you gain an understanding of the service ecosystem and introduce you to a variety of best practices that can be applied to securing your environments and workloads running in AWS. Security and Compliance is a shared responsibility between AWS and the customer. AWS customers benefit from a data center and network architecture built to satisfy the requirements of the most security-sensitive organizations. AWS is responsible for protecting the infrastructure which runs all of the services offered and this responsibility is known as the Security of the Cloud . Customers responsibility, known as the Security in the Cloud , is determined by which services the customer chooses to use. The workshops contained in this portal are focused on the Security in the Cloud and they will guide you through prepared scenarios that represent common use cases and operational tasks you'll face in building on AWS. They will also highlight the design principals from the AWS Well-Architected Framework Security Pillar , which can help you improve your security posture. Implement a strong identity foundation Enable traceability Apply security at all layers Automate security best practices Protect data in transit and at rest Keep people away from data Prepare for security events","title":"Home"},{"location":"#aws-security-workshops","text":"Welcome to the AWS security workshops portal! Here you will find a collection of workshops aimed at helping you gain an understanding of the service ecosystem and introduce you to a variety of best practices that can be applied to securing your environments and workloads running in AWS. Security and Compliance is a shared responsibility between AWS and the customer. AWS customers benefit from a data center and network architecture built to satisfy the requirements of the most security-sensitive organizations. AWS is responsible for protecting the infrastructure which runs all of the services offered and this responsibility is known as the Security of the Cloud . Customers responsibility, known as the Security in the Cloud , is determined by which services the customer chooses to use. The workshops contained in this portal are focused on the Security in the Cloud and they will guide you through prepared scenarios that represent common use cases and operational tasks you'll face in building on AWS. They will also highlight the design principals from the AWS Well-Architected Framework Security Pillar , which can help you improve your security posture. Implement a strong identity foundation Enable traceability Apply security at all layers Automate security best practices Protect data in transit and at rest Keep people away from data Prepare for security events","title":"AWS Security Workshops"},{"location":"contribute/","text":"Contributing Guidelines Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution. Reporting Bugs/Feature Requests We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment Contributing via Pull Requests Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request . Finding contributions to work on Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start. Code of Conduct This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments. Security issue notifications If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue. Licensing See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Contributing"},{"location":"contribute/#contributing-guidelines","text":"Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution.","title":"Contributing Guidelines"},{"location":"contribute/#reporting-bugsfeature-requests","text":"We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment","title":"Reporting Bugs/Feature Requests"},{"location":"contribute/#contributing-via-pull-requests","text":"Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request .","title":"Contributing via Pull Requests"},{"location":"contribute/#finding-contributions-to-work-on","text":"Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.","title":"Finding contributions to work on"},{"location":"contribute/#code-of-conduct","text":"This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.","title":"Code of Conduct"},{"location":"contribute/#security-issue-notifications","text":"If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue.","title":"Security issue notifications"},{"location":"contribute/#licensing","text":"See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Licensing"},{"location":"getting-started/","text":"Getting Started Create an AWS account In order to complete these workshops, you'll need a valid, usable AWS Account . Use a personal account or create a new AWS account to ensure you have the necessary access and that you do not accidentally modify corporate resources. Do not use an AWS account from the company you work for. Create an admin user If you don't already have an AWS IAM user with admin permissions, please use the following instructions to create one: Browse to the AWS IAM console. Click Users on the left navigation and then click Add User . Enter a User Name , check the checkbox for AWS Management Console access , enter a Custom Password , and click Next:Permissions . Click Attach existing policies directly , click the checkbox next to the AdministratorAccess , and click Next:review . Click Create User Click Dashboard on the left navigation and use the IAM users sign-in link to login as the admin user you just created. Add credits (optional) If you are doing this workshop as part of an AWS sponsored event, you will receive credits to cover the costs. Below are the instructions for entering the credits: Browse to the AWS Account Settings console. Enter the Promo Code you received (these will be handed out at the beginning of the workshop). Enter the Security Check and click Redeem . Create a Cloud9 instance (optional) If the workshop you are doing requires you to run commands or scripts you will need to launch a an AWS Cloud9 instance which will provide you with a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. The workshop instructions will specify if this needed. Below are the instructions for launching an instance: Browse to the AWS Cloud9 console. Click Create environment on the right side. Enter a Name (security-workshop-ide) and click Next step . Leave all the defaults and click Next step . Click Create environment . The environment will open automatically after it has been provisioned. Browse back to the AWS Cloud9 console and you can click Open IDE on the environment you created to access it at anytime. You are now setup for the workshops!","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/#create-an-aws-account","text":"In order to complete these workshops, you'll need a valid, usable AWS Account . Use a personal account or create a new AWS account to ensure you have the necessary access and that you do not accidentally modify corporate resources. Do not use an AWS account from the company you work for.","title":"Create an AWS account"},{"location":"getting-started/#create-an-admin-user","text":"If you don't already have an AWS IAM user with admin permissions, please use the following instructions to create one: Browse to the AWS IAM console. Click Users on the left navigation and then click Add User . Enter a User Name , check the checkbox for AWS Management Console access , enter a Custom Password , and click Next:Permissions . Click Attach existing policies directly , click the checkbox next to the AdministratorAccess , and click Next:review . Click Create User Click Dashboard on the left navigation and use the IAM users sign-in link to login as the admin user you just created.","title":"Create an admin user"},{"location":"getting-started/#add-credits-optional","text":"If you are doing this workshop as part of an AWS sponsored event, you will receive credits to cover the costs. Below are the instructions for entering the credits: Browse to the AWS Account Settings console. Enter the Promo Code you received (these will be handed out at the beginning of the workshop). Enter the Security Check and click Redeem .","title":"Add credits (optional)"},{"location":"getting-started/#create-a-cloud9-instance-optional","text":"If the workshop you are doing requires you to run commands or scripts you will need to launch a an AWS Cloud9 instance which will provide you with a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. The workshop instructions will specify if this needed. Below are the instructions for launching an instance: Browse to the AWS Cloud9 console. Click Create environment on the right side. Enter a Name (security-workshop-ide) and click Next step . Leave all the defaults and click Next step . Click Create environment . The environment will open automatically after it has been provisioned. Browse back to the AWS Cloud9 console and you can click Open IDE on the environment you created to access it at anytime. You are now setup for the workshops!","title":"Create a Cloud9 instance (optional)"},{"location":"license/","text":"License MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"builder-sessions/","text":"Builder Sessions Title Description Permission Boundaries: How to Truly Delegate Permissions on AWS Permission boundaries is probably one of the most important new IAM feature that has launched in awhile. This feature addresses a longstanding customer issue, namely, how do I delegate administration to my users. If you have developers that need to be able to create roles for Lambda functions, system administrators that need to be able to create IAM roles and users, or any similar scenario, then you need permission boundaries. Presentation deck","title":"Directory"},{"location":"builder-sessions/#builder-sessions","text":"Title Description Permission Boundaries: How to Truly Delegate Permissions on AWS Permission boundaries is probably one of the most important new IAM feature that has launched in awhile. This feature addresses a longstanding customer issue, namely, how do I delegate administration to my users. If you have developers that need to be able to create roles for Lambda functions, system administrators that need to be able to create IAM roles and users, or any similar scenario, then you need permission boundaries. Presentation deck","title":"Builder Sessions"},{"location":"builder-sessions/permission-boundary/build/","text":"Permission Boundaries: How to Truly Delegate Permissions on AWS (Build Phase) Permission boundaries is probably one of the most important new IAM features that has launched in a while. This feature addresses a longstanding customer issue, namely, how do I delegate administration to my users. If you have system administrators that need to be able to create IAM roles and users, developers that need to be able to create roles for Lambda functions, or any similar scenario, then you need permission boundaries. Presentation deck Environment Setup AWS Sponsored Event Browse to the URL provided to you and login. After you login click the AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for the Management console . Click on that and you will be taken to the AWS console. Individual Launch the CloudFormation stack below to setup the Permission Boundary environment: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. Click Next on the Specify Template , Specify Details, and Options** sections. Finally, acknowledge that the template will create IAM roles under Capabilities and click Create**. This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE . Scenario As the administrator for an AWS account hosting multiple production applications, you've been tasked with creating a new administrator role to delegate some of your responsibilities. This new role will be responsible for doing all the administration on the resources for the Ares Mission . The diagram above showcases the two applications currently being hosted in the AWS account and their associated resources. Currently there is only one application related to the Ares Mission but there is a plan to migrate three more applications for this mission by the end of the year. The new role should account for current and future Ares Mission applications to reduce your overhead and friction with the web administrators. The web administrators for the Ares Mission should have permissions to create and administer resources related to that mission. This means they should be able to: Create, modify, and delete IAM policies and roles. Any role created must have restricted permissions to ensure a web administrator cannot elevate their privileges or the privileges of the application. Create, modify, and delete Ares Mission Lambda functions. The web administrators should not be able to impact any resources in the account that are not part of the Ares Mission application including users, groups, roles, S3 buckets, EC2 instances, etc. In this case, they should not be able to modify resources of the Rover Mission. All resources are located in the us-west-2 region. Task 1 - Create a permission boundary for Lambda Functions ACTION : Create a new IAM policy that will act as the permission boundary for the web admins. Name the policy identity-ex-permissionboundary-ares-lambda Hint : Friendly Names and Paths . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateLogGroup , Effect : Allow , Action : logs:CreateLogGroup , Resource : arn:aws:logs:us-west-2:ACCOUNT_ID:* }, { Sid : CreateLogStreamandEvents , Effect : Allow , Action : [ logs:CreateLogStream , logs:PutLogEvents ], Resource : arn:aws:logs:us-west-2:ACCOUNT_ID:log-group:/aws/lambda/identity-ex-????:* }, { Sid : AllowedS3GetObject , Effect : Allow , Action : [ s3:List* ], Resource : arn:aws:s3:::identity-ex-???? } ] } Task 2 - Create a permission policy for the Web Admin ACTION : Create the permission policy that will be attached to the webadmin AWS IAM user. Name the new policy identity-ex-webadmin-permissionpolicy . Hint : Friendly Names and Paths . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateCustomerManagedPolicies , Effect : Allow , Action : [ iam:CreatePolicy , iam:DeletePolicy , iam:CreatePolicyVersion , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : arn:aws:iam::ACCOUNT_ID:policy/identity-ex-???? }, { Sid : RoleandPolicyActionswithnoPermissionBoundarySupport , Effect : Allow , Action : [ iam:UpdateRole , iam:DeleteRole ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? ] }, { Sid : CreateRoles , Effect : Allow , Action : [ iam:CreateRole , iam:AttachRolePolicy , iam:DetachRolePolicy ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? ], Condition : { StringEquals : { iam:PermissionsBoundary : arn:aws:iam::ACCOUNT_ID:policy/identity-ex-permissionboundary-ares-lambda } } }, { Sid : LambdaFullAccesswithResourceRestrictions , Effect : Allow , Action : lambda:* , Resource : arn:aws:lambda:us-west-2:ACCOUNT_ID:function:identity-ex-???? }, { Sid : PassRoletoLambda , Effect : Allow , Action : iam:PassRole , Resource : arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? , Condition : { StringLikeIfExists : { iam:PassedToService : lambda.amazonaws.com } } }, { Sid : AdditionalPermissionsforLambda , Effect : Allow , Action : [ kms:ListAliases , logs:Describe* , logs:ListTagsLogGroup , logs:FilterLogEvents , logs:GetLogEvents ], Resource : * }, { Sid : DenyPermissionBoundaryandPolicyDeleteModify , Effect : Deny , Action : [ iam:CreatePolicyVersion , iam:DeletePolicy , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : [ arn:aws:iam::ACCOUNT_ID:policy/identity-ex-permissionboundary-ares-lambda , arn:aws:iam::ACCOUNT_ID:policy/identity-ex-webadmin-permissionpolicy ] }, { Sid : DenyRolePermissionBoundaryDelete , Effect : Deny , Action : iam:DeleteRolePermissionsBoundary , Resource : * } ] } Task 3 - Create the Web Admin user ACTION : Create an IAM User and name it webadmin . The user will need console access so give it a password. Attach the identity-ex-webadmin-permissionpolicy , IAMReadOnlyAccess AWSLambdaReadOnlyAccess policies to the IAM user. When you are done the webadmin user should have three policies attached: identity-ex-webadmin-permissionpolicy, IAMReadOnlyAccess AWSLambdaReadOnlyAccess. Task 4 - Gather info needed for the Verify phase ACTION : Now that you have setup the IAM user for the web admins, it's time to pass this information on to the next team who will work through the VERIFY tasks. You need to gather some details about your IAM user and then hand this info to the next team. Copy the IAM users sign-in link , the IAM user name (if you used a name other then webadmin ) and the password you used. You will also need the resource restriction that you used in your policies and the name you used for the permission policy and permission boundary (if you used names other than the ones recommended above) Here are all of the details you need to pass to another team: IAM users sign-in link: IAM user name: IAM user password: Resource restriction identifier: Permission boundary name: (recommended name: identity-ex-permissionboundary-ares-lambda ) Permission policy: (recommended name: identity-ex-webadmin-permissionpolicy ) Enter this information into the VERIFY phase form and exchange forms with another team so you both can work through the tasks. You can now move on to the Verify phase!","title":"Build Phase"},{"location":"builder-sessions/permission-boundary/build/#permission-boundaries-how-to-truly-delegate-permissions-on-aws-build-phase","text":"Permission boundaries is probably one of the most important new IAM features that has launched in a while. This feature addresses a longstanding customer issue, namely, how do I delegate administration to my users. If you have system administrators that need to be able to create IAM roles and users, developers that need to be able to create roles for Lambda functions, or any similar scenario, then you need permission boundaries. Presentation deck","title":"Permission Boundaries: How to Truly Delegate Permissions on AWS (Build Phase)"},{"location":"builder-sessions/permission-boundary/build/#environment-setup","text":"AWS Sponsored Event Browse to the URL provided to you and login. After you login click the AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for the Management console . Click on that and you will be taken to the AWS console. Individual Launch the CloudFormation stack below to setup the Permission Boundary environment: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. Click Next on the Specify Template , Specify Details, and Options** sections. Finally, acknowledge that the template will create IAM roles under Capabilities and click Create**. This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE .","title":"Environment Setup"},{"location":"builder-sessions/permission-boundary/build/#scenario","text":"As the administrator for an AWS account hosting multiple production applications, you've been tasked with creating a new administrator role to delegate some of your responsibilities. This new role will be responsible for doing all the administration on the resources for the Ares Mission . The diagram above showcases the two applications currently being hosted in the AWS account and their associated resources. Currently there is only one application related to the Ares Mission but there is a plan to migrate three more applications for this mission by the end of the year. The new role should account for current and future Ares Mission applications to reduce your overhead and friction with the web administrators. The web administrators for the Ares Mission should have permissions to create and administer resources related to that mission. This means they should be able to: Create, modify, and delete IAM policies and roles. Any role created must have restricted permissions to ensure a web administrator cannot elevate their privileges or the privileges of the application. Create, modify, and delete Ares Mission Lambda functions. The web administrators should not be able to impact any resources in the account that are not part of the Ares Mission application including users, groups, roles, S3 buckets, EC2 instances, etc. In this case, they should not be able to modify resources of the Rover Mission. All resources are located in the us-west-2 region.","title":"Scenario"},{"location":"builder-sessions/permission-boundary/build/#task-1-create-a-permission-boundary-for-lambda-functions","text":"ACTION : Create a new IAM policy that will act as the permission boundary for the web admins. Name the policy identity-ex-permissionboundary-ares-lambda Hint : Friendly Names and Paths . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateLogGroup , Effect : Allow , Action : logs:CreateLogGroup , Resource : arn:aws:logs:us-west-2:ACCOUNT_ID:* }, { Sid : CreateLogStreamandEvents , Effect : Allow , Action : [ logs:CreateLogStream , logs:PutLogEvents ], Resource : arn:aws:logs:us-west-2:ACCOUNT_ID:log-group:/aws/lambda/identity-ex-????:* }, { Sid : AllowedS3GetObject , Effect : Allow , Action : [ s3:List* ], Resource : arn:aws:s3:::identity-ex-???? } ] }","title":"Task 1 - Create a permission boundary for Lambda Functions"},{"location":"builder-sessions/permission-boundary/build/#task-2-create-a-permission-policy-for-the-web-admin","text":"ACTION : Create the permission policy that will be attached to the webadmin AWS IAM user. Name the new policy identity-ex-webadmin-permissionpolicy . Hint : Friendly Names and Paths . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateCustomerManagedPolicies , Effect : Allow , Action : [ iam:CreatePolicy , iam:DeletePolicy , iam:CreatePolicyVersion , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : arn:aws:iam::ACCOUNT_ID:policy/identity-ex-???? }, { Sid : RoleandPolicyActionswithnoPermissionBoundarySupport , Effect : Allow , Action : [ iam:UpdateRole , iam:DeleteRole ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? ] }, { Sid : CreateRoles , Effect : Allow , Action : [ iam:CreateRole , iam:AttachRolePolicy , iam:DetachRolePolicy ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? ], Condition : { StringEquals : { iam:PermissionsBoundary : arn:aws:iam::ACCOUNT_ID:policy/identity-ex-permissionboundary-ares-lambda } } }, { Sid : LambdaFullAccesswithResourceRestrictions , Effect : Allow , Action : lambda:* , Resource : arn:aws:lambda:us-west-2:ACCOUNT_ID:function:identity-ex-???? }, { Sid : PassRoletoLambda , Effect : Allow , Action : iam:PassRole , Resource : arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? , Condition : { StringLikeIfExists : { iam:PassedToService : lambda.amazonaws.com } } }, { Sid : AdditionalPermissionsforLambda , Effect : Allow , Action : [ kms:ListAliases , logs:Describe* , logs:ListTagsLogGroup , logs:FilterLogEvents , logs:GetLogEvents ], Resource : * }, { Sid : DenyPermissionBoundaryandPolicyDeleteModify , Effect : Deny , Action : [ iam:CreatePolicyVersion , iam:DeletePolicy , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : [ arn:aws:iam::ACCOUNT_ID:policy/identity-ex-permissionboundary-ares-lambda , arn:aws:iam::ACCOUNT_ID:policy/identity-ex-webadmin-permissionpolicy ] }, { Sid : DenyRolePermissionBoundaryDelete , Effect : Deny , Action : iam:DeleteRolePermissionsBoundary , Resource : * } ] }","title":"Task 2 - Create a permission policy for the Web Admin"},{"location":"builder-sessions/permission-boundary/build/#task-3-create-the-web-admin-user","text":"ACTION : Create an IAM User and name it webadmin . The user will need console access so give it a password. Attach the identity-ex-webadmin-permissionpolicy , IAMReadOnlyAccess AWSLambdaReadOnlyAccess policies to the IAM user. When you are done the webadmin user should have three policies attached: identity-ex-webadmin-permissionpolicy, IAMReadOnlyAccess AWSLambdaReadOnlyAccess.","title":"Task 3 - Create the Web Admin user"},{"location":"builder-sessions/permission-boundary/build/#task-4-gather-info-needed-for-the-verify-phase","text":"ACTION : Now that you have setup the IAM user for the web admins, it's time to pass this information on to the next team who will work through the VERIFY tasks. You need to gather some details about your IAM user and then hand this info to the next team. Copy the IAM users sign-in link , the IAM user name (if you used a name other then webadmin ) and the password you used. You will also need the resource restriction that you used in your policies and the name you used for the permission policy and permission boundary (if you used names other than the ones recommended above) Here are all of the details you need to pass to another team: IAM users sign-in link: IAM user name: IAM user password: Resource restriction identifier: Permission boundary name: (recommended name: identity-ex-permissionboundary-ares-lambda ) Permission policy: (recommended name: identity-ex-webadmin-permissionpolicy ) Enter this information into the VERIFY phase form and exchange forms with another team so you both can work through the tasks. You can now move on to the Verify phase!","title":"Task 4 - Gather info needed for the Verify phase"},{"location":"builder-sessions/permission-boundary/verify/","text":"Permission Boundaries: How to Truly Delegate Permissions on AWS (Verify Phase) We are now in the Verify phase. It is time to put on the hat of the web administrator and test the access to ensure the permissions are setup correctly. You'll be logging in to the AWS account you were delegated access to and perform a number of verification tasks. Console Login You should have received from another team the following information. You will need this information to access the AWS console IAM users sign-in link IAM user name IAM user password Resource restriction identifier Permission boundary name Requirements The only requirement is to verify you can complete the following tasks. The web admins should only have access to the following resources: IAM policies and roles created by the web admins Lambda functions created by the web admins The web admins should not be able to impact any resources in the account that they do not own including users, groups, roles, S3 buckets, EC2 instances, etc. The following steps should be taken to validate that the delegation was done properly. Verify that you are able to create an IAM policy, create an IAM role with that policy attached and then create a Lambda function and pass that role to it. Task 1 - Create a customer managed IAM policy The first step is to create a customer managed IAM policy. This will define the permissions of the role that you will pass to a Lambda function. Since the function will be working with S3 and since the point of this is to show how permission boundaries work, use the following policy which grants basic Lambda logging permissions and S3 full access. Keep in mind the resource restrictions put in place which will require you to use a certain name for the policy. What is the resource restriction identifier that was given to you? { Version : 2012-10-17 , Statement : [ { Effect : Allow , Action : [ logs:CreateLogGroup , logs:CreateLogStream , logs:PutLogEvents , s3:* ], Resource : * } ] } Task 2 - Create an IAM role Next you will create an IAM Role. Choose Lambda as the service for this role. Attach the policy you just created and the permission boundary (which will most likely be named: identity-ex-permissionboundary-ares-lambda ) Keep in mind the resource restrictions put in place which will require you to use a certain name for the role. What is the resource restriction identifier that was given to you? Task 3 - Create a Lambda function Finally you will create a Node.js 8.10 Lambda function using the code below and attach the IAM role you just created to it. You will need to replace \"ELB_ACCESS_LOGS_BUCKET_NAME\" with bucket from your account that begins with \"identity-ex-ares*\" . Keep in mind the resource restrictions put in place which will require you to use a certain name for the role. What is the resource restriction identifier that was given to you? const AWS = require ( aws-sdk ); const s3 = new AWS . S3 (); exports . handler = async ( event ) = { console.log( Loading function ) ; const allKeys = [] ; await getKeys({ Bucket : ELB_ACCESS_LOGS_BUCKET_NAME } , allKeys ); return allKeys ; } ; async function getKeys ( params , keys ) { const response = await s3.listObjectsV2(params).promise() ; response.Contents.forEach(obj = keys.push(obj.Key)) ; if (response.IsTruncated) { const newParams = Object.assign({ } , params ); newParams . ContinuationToken = response . NextContinuationToken ; await getKeys ( newParams , keys ); } } Test the Lambda function and make sure it is generating logs in CloudWatch logs and that it is able to list the ELB logs in the ELB access logs bucket the object in S3. In order to test you will need to create a test event. The parameters of the test do not matter. Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. Expand one of the following dropdowns and follow the instructions: AWS Sponsored Event No cleanup required! The responsibility falls to AWS. Individual You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete the Ares S3 bucket. Go to the Amazon S3 console. Click on the bucket named identity-ex-ares-app Click Delete Enter the bucket name again to confirm and click Delete . Delete the CloudFormation stack ( Identity-PB-Builder-Session ). Go to the AWS CloudFormation console. Select the appropriate stack. Select Action . Click Delete Stack . Summary Congratulations, you've completed the Permission Boundaries Builder session! Hopefully by going through this session you have a better idea of what permission boundaries are, where they can be used, and are starting to think about where you can apply them in your environments.","title":"Verify Phase"},{"location":"builder-sessions/permission-boundary/verify/#permission-boundaries-how-to-truly-delegate-permissions-on-aws-verify-phase","text":"We are now in the Verify phase. It is time to put on the hat of the web administrator and test the access to ensure the permissions are setup correctly. You'll be logging in to the AWS account you were delegated access to and perform a number of verification tasks.","title":"Permission Boundaries: How to Truly Delegate Permissions on AWS (Verify Phase)"},{"location":"builder-sessions/permission-boundary/verify/#console-login","text":"You should have received from another team the following information. You will need this information to access the AWS console IAM users sign-in link IAM user name IAM user password Resource restriction identifier Permission boundary name","title":"Console Login"},{"location":"builder-sessions/permission-boundary/verify/#requirements","text":"The only requirement is to verify you can complete the following tasks. The web admins should only have access to the following resources: IAM policies and roles created by the web admins Lambda functions created by the web admins The web admins should not be able to impact any resources in the account that they do not own including users, groups, roles, S3 buckets, EC2 instances, etc. The following steps should be taken to validate that the delegation was done properly. Verify that you are able to create an IAM policy, create an IAM role with that policy attached and then create a Lambda function and pass that role to it.","title":"Requirements"},{"location":"builder-sessions/permission-boundary/verify/#task-1-create-a-customer-managed-iam-policy","text":"The first step is to create a customer managed IAM policy. This will define the permissions of the role that you will pass to a Lambda function. Since the function will be working with S3 and since the point of this is to show how permission boundaries work, use the following policy which grants basic Lambda logging permissions and S3 full access. Keep in mind the resource restrictions put in place which will require you to use a certain name for the policy. What is the resource restriction identifier that was given to you? { Version : 2012-10-17 , Statement : [ { Effect : Allow , Action : [ logs:CreateLogGroup , logs:CreateLogStream , logs:PutLogEvents , s3:* ], Resource : * } ] }","title":"Task 1 - Create a customer managed IAM policy"},{"location":"builder-sessions/permission-boundary/verify/#task-2-create-an-iam-role","text":"Next you will create an IAM Role. Choose Lambda as the service for this role. Attach the policy you just created and the permission boundary (which will most likely be named: identity-ex-permissionboundary-ares-lambda ) Keep in mind the resource restrictions put in place which will require you to use a certain name for the role. What is the resource restriction identifier that was given to you?","title":"Task 2 - Create an IAM role"},{"location":"builder-sessions/permission-boundary/verify/#task-3-create-a-lambda-function","text":"Finally you will create a Node.js 8.10 Lambda function using the code below and attach the IAM role you just created to it. You will need to replace \"ELB_ACCESS_LOGS_BUCKET_NAME\" with bucket from your account that begins with \"identity-ex-ares*\" . Keep in mind the resource restrictions put in place which will require you to use a certain name for the role. What is the resource restriction identifier that was given to you? const AWS = require ( aws-sdk ); const s3 = new AWS . S3 (); exports . handler = async ( event ) = { console.log( Loading function ) ; const allKeys = [] ; await getKeys({ Bucket : ELB_ACCESS_LOGS_BUCKET_NAME } , allKeys ); return allKeys ; } ; async function getKeys ( params , keys ) { const response = await s3.listObjectsV2(params).promise() ; response.Contents.forEach(obj = keys.push(obj.Key)) ; if (response.IsTruncated) { const newParams = Object.assign({ } , params ); newParams . ContinuationToken = response . NextContinuationToken ; await getKeys ( newParams , keys ); } } Test the Lambda function and make sure it is generating logs in CloudWatch logs and that it is able to list the ELB logs in the ELB access logs bucket the object in S3. In order to test you will need to create a test event. The parameters of the test do not matter.","title":"Task 3 - Create a Lambda function"},{"location":"builder-sessions/permission-boundary/verify/#cleanup","text":"In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. Expand one of the following dropdowns and follow the instructions: AWS Sponsored Event No cleanup required! The responsibility falls to AWS. Individual You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete the Ares S3 bucket. Go to the Amazon S3 console. Click on the bucket named identity-ex-ares-app Click Delete Enter the bucket name again to confirm and click Delete . Delete the CloudFormation stack ( Identity-PB-Builder-Session ). Go to the AWS CloudFormation console. Select the appropriate stack. Select Action . Click Delete Stack .","title":"Cleanup"},{"location":"builder-sessions/permission-boundary/verify/#summary","text":"Congratulations, you've completed the Permission Boundaries Builder session! Hopefully by going through this session you have a better idea of what permission boundaries are, where they can be used, and are starting to think about where you can apply them in your environments.","title":"Summary"},{"location":"workshops/","text":"Workshops Title Description Find All the Threats: AWS Threat Detection and Remediation This hands-on workshop where you learn about a number of AWS services involved with threat detection and remediation as we walk through some real-world threat scenarios. Learn about the threat detection capabilities of Amazon GuardDuty, Amazon Macie, AWS Config, and the available remediation options. For each hands-on scenario, we review methods to remediate the threat using the following services: AWS CloudFormation, Amazon S3, AWS CloudTrail, Amazon VPC flow logs, Amazon CloudWatch Events, Amazon SNS, Amazon Macie, DNS logs, AWS Lambda, AWS Config, Amazon Inspector and, of course, Amazon GuardDuty.","title":"Directory"},{"location":"workshops/#workshops","text":"Title Description Find All the Threats: AWS Threat Detection and Remediation This hands-on workshop where you learn about a number of AWS services involved with threat detection and remediation as we walk through some real-world threat scenarios. Learn about the threat detection capabilities of Amazon GuardDuty, Amazon Macie, AWS Config, and the available remediation options. For each hands-on scenario, we review methods to remediate the threat using the following services: AWS CloudFormation, Amazon S3, AWS CloudTrail, Amazon VPC flow logs, Amazon CloudWatch Events, Amazon SNS, Amazon Macie, DNS logs, AWS Lambda, AWS Config, Amazon Inspector and, of course, Amazon GuardDuty.","title":"Workshops"},{"location":"workshops/identity-round-robin/","text":"Identity Round Robin COMING SOON!","title":"Overview"},{"location":"workshops/identity-round-robin/#identity-round-robin","text":"COMING SOON!","title":"Identity Round Robin"},{"location":"workshops/identity-round-robin/permission-boundaries/","text":"Permission boundaries round - Overview Hello fellow cloud consultant. Your customer has deployed a three tier web application in production. Different teams work on different aspects of the architecture but they don't always communicate well nor work well together. Just recently the team responsible for the web servers set up a Lambda function that inadvertently impacted the Application team's resources. The VP of Operations was furious. The VP has tasked you with setting up permissions for the web admins so that they can only impact they own resources while still being able to do their job. AWS Service/Feature Coverage : IAM permission boundaries (For additional reading see the IAM documentation and this blog post ), IAM Identifiers or resource restrictions , IAM users, IAM roles and AWS Lambda Using this workshop as an example, the three elements of a permission boundary are represented below. When your team does the BUILD tasks you will act as the admin. When your team does the VERIFY tasks you will act as the delegated admin. The delegated admins will create roles that can be considered \"bound\" since they will have permission boundaries attached. Agenda This workshop can be done as a team exercise or individually. The instructions are written with assumption that you are working as part of a team but you could just as easily do the steps below on your own. If done as part of an AWS sponsored event then you'll be split into teams of around 4-6 people. Each team will do the BUILD phase and then hand off their accounts to another team. Then each team will do the VERIFY phase. The round is broken down into first a BUILD phase followed by a VERIFY phase. BUILD (60 min): First each team will carry out the activities involved in the BUILD phase where they will set up access for the web admins and properly lock down the account. Then each team will hand credentials for an IAM user in their account to another team to act in the VERIFY phase. The VERIFY phase lasts about 30 min. VERIFY (30 min): Each team will carry out the VERIFY activities as if they were part of the web admins team. The VERIFY activities will include validating that the requirements were set up correctly in the BUILD phase and also investigate if the web admins are able to take actions that they shouldn't be allowed to. Presentation Workshop Presentation Setup Instructions To setup your environment please expand one of the following dropdowns (depending on how you're doing this workshop) and follow the instructions: AWS Sponsored Event Console Login: if you are attending this workshop at an official AWS event then your team should have the URL and login credentials for your account. This will allow you to login to the account using AWS SSO. Browse to that URL and login. After you login click AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for Management console . Click on that and you will be taken the AWS console. Make sure the region is set to Ohio (us-east-2) CloudFormation: Launch the CloudFormation stack below to setup the environment: Region Deploy US East 2 (Ohio) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. Click Next on the Select Template section. Click Next on the Specify Details section (the stack name will be prefilled - you can change it or leave it as is) Click Next on the Options section. Finally, acknowledge that the template will create IAM roles under Capabilitie and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE . Individual Log in to your account however you would normally CloudFormation: Launch the CloudFormation stack below to setup the environment: Region Deploy US East 2 (Ohio) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. Click Next on the Select Template section. Click Next on the Specify Details section (the stack name will be prefilled - you can change it or leave it as is) Click Next on the Options section. Finally, acknowledge that the template will create IAM roles under Capabilitie and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE . Requirements Application architecture: There are many teams working in this AWS account, including the web admins and the application admins. The ulimate goal of this workshop is to set up the web admins so they can create a Lambda function to read an S3 bucket while making sure they are not able to impact the resources of other teams. The web admins should only have access to the following resources: IAM policies and roles created by the web admins Lambda functions created by the web admins S3 buckets: The web admins are allowed to have read access to the bucket that starts with \"identitywksp-web-admins-applicat-rs3elbaccesslogs-\" and full access to the bucket that starts with \" The web admins should not be able to impact any resources in the account that they do not own including IAM users, groups, roles, S3 buckets, etc. Click here to go to the BUILD phase","title":"Scenario"},{"location":"workshops/identity-round-robin/permission-boundaries/#permission-boundaries-round-overview","text":"Hello fellow cloud consultant. Your customer has deployed a three tier web application in production. Different teams work on different aspects of the architecture but they don't always communicate well nor work well together. Just recently the team responsible for the web servers set up a Lambda function that inadvertently impacted the Application team's resources. The VP of Operations was furious. The VP has tasked you with setting up permissions for the web admins so that they can only impact they own resources while still being able to do their job. AWS Service/Feature Coverage : IAM permission boundaries (For additional reading see the IAM documentation and this blog post ), IAM Identifiers or resource restrictions , IAM users, IAM roles and AWS Lambda Using this workshop as an example, the three elements of a permission boundary are represented below. When your team does the BUILD tasks you will act as the admin. When your team does the VERIFY tasks you will act as the delegated admin. The delegated admins will create roles that can be considered \"bound\" since they will have permission boundaries attached.","title":"Permission boundaries round - Overview"},{"location":"workshops/identity-round-robin/permission-boundaries/#agenda","text":"This workshop can be done as a team exercise or individually. The instructions are written with assumption that you are working as part of a team but you could just as easily do the steps below on your own. If done as part of an AWS sponsored event then you'll be split into teams of around 4-6 people. Each team will do the BUILD phase and then hand off their accounts to another team. Then each team will do the VERIFY phase. The round is broken down into first a BUILD phase followed by a VERIFY phase. BUILD (60 min): First each team will carry out the activities involved in the BUILD phase where they will set up access for the web admins and properly lock down the account. Then each team will hand credentials for an IAM user in their account to another team to act in the VERIFY phase. The VERIFY phase lasts about 30 min. VERIFY (30 min): Each team will carry out the VERIFY activities as if they were part of the web admins team. The VERIFY activities will include validating that the requirements were set up correctly in the BUILD phase and also investigate if the web admins are able to take actions that they shouldn't be allowed to.","title":"Agenda"},{"location":"workshops/identity-round-robin/permission-boundaries/#presentation","text":"Workshop Presentation","title":"Presentation"},{"location":"workshops/identity-round-robin/permission-boundaries/#setup-instructions","text":"To setup your environment please expand one of the following dropdowns (depending on how you're doing this workshop) and follow the instructions: AWS Sponsored Event Console Login: if you are attending this workshop at an official AWS event then your team should have the URL and login credentials for your account. This will allow you to login to the account using AWS SSO. Browse to that URL and login. After you login click AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for Management console . Click on that and you will be taken the AWS console. Make sure the region is set to Ohio (us-east-2) CloudFormation: Launch the CloudFormation stack below to setup the environment: Region Deploy US East 2 (Ohio) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. Click Next on the Select Template section. Click Next on the Specify Details section (the stack name will be prefilled - you can change it or leave it as is) Click Next on the Options section. Finally, acknowledge that the template will create IAM roles under Capabilitie and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE . Individual Log in to your account however you would normally CloudFormation: Launch the CloudFormation stack below to setup the environment: Region Deploy US East 2 (Ohio) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. Click Next on the Select Template section. Click Next on the Specify Details section (the stack name will be prefilled - you can change it or leave it as is) Click Next on the Options section. Finally, acknowledge that the template will create IAM roles under Capabilitie and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE .","title":"Setup Instructions"},{"location":"workshops/identity-round-robin/permission-boundaries/#requirements","text":"Application architecture: There are many teams working in this AWS account, including the web admins and the application admins. The ulimate goal of this workshop is to set up the web admins so they can create a Lambda function to read an S3 bucket while making sure they are not able to impact the resources of other teams. The web admins should only have access to the following resources: IAM policies and roles created by the web admins Lambda functions created by the web admins S3 buckets: The web admins are allowed to have read access to the bucket that starts with \"identitywksp-web-admins-applicat-rs3elbaccesslogs-\" and full access to the bucket that starts with \" The web admins should not be able to impact any resources in the account that they do not own including IAM users, groups, roles, S3 buckets, etc.","title":"Requirements"},{"location":"workshops/identity-round-robin/permission-boundaries/#click-here-to-go-to-the-build-phase","text":"","title":"Click here to go to the BUILD phase"},{"location":"workshops/identity-round-robin/permission-boundaries/build/","text":"Permission boundaries round - Build Phase Below are a series of tasks to delegate permissions to the web admins. In these tasks you will be creating smaller policies and testing them. In Task 5 you will combine these policies together into one permission policy. You should create each policy and test it before moving on to the next task. It helps to divide the team into people doing the tasks and people testing things out. So some of the members of the team will be logged in using SSO and following the instructions in the tasks while other members will be logged in as the webadmin user (created in Task 1 below) to test out the work done in each task. Task 1 - Create an IAM user and an IAM policy with permission to create customer managed policies Build an IAM policy so that web admins can create customer managed policies. They should only be able to edit the policies they create (no other managed policies). We will not be using inline policies for this exercise. \"In most cases, we recommend that you use managed policies instead of inline policies.\" IMPORTANT! As you use the provided IAM policies hints, keep in mind where you need to add the account ID, what resource restrictions to use and where a region is specified in the resource. All of these items can cause issues. Walk Through : Begin by navigating to the IAM console . We will grab the AWS account ID. On the first screen you see in the IAM console (which should be the Dashboard) you will see an IAM users sign-in link . Copy that link because you will need the account ID in the URL for the policies and you will need the entire URL when you hand this account to another team for the VERIFY phase. Click Users on the left menu and create a new IAM user named webadmin . Check AWS Management Console access and then either autogenerate a password or set a custom password. Uncheck Require password reset . Attach the AWS managed policies IAMReadOnlyAccess AWSLambdaReadOnlyAccess to the user. Next click \u201cPolicies\u201d on the left menu. Create a new IAM policy based on the hint below. Attach this policy to the IAM user you created. Hint : IAM Identifiers . You will want to use either naming or pathing resource restrictions in the IAM policy. The question marks \" ???? \" in the resource element below should be replaced with something that could act as a resource restriction. Examine the existing resources (roles, Lambda functions) to make sure the policy will give access to existing resources owned by the web admins. Replacing the question marks is really the key to this round. { Version : 2012-10-17 , Statement : [ { Sid : CreateCustomerManagedPolicies , Effect : Allow , Action : [ iam:CreatePolicy , iam:DeletePolicy , iam:CreatePolicyVersion , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : arn:aws:iam::ACCOUNT_ID:policy/???? } ] } You should login with the webadmin IAM user (using a different browser) to verify the user can create a policy (while following the resource restriction.) Use the IAM users sign-in link you gathered earlier to login. The permissions assigned to the policy do not matter for the test. Question(s) : i. Why are we using resource restrictions here? ii. There are two ways of doing resource restrictions: naming and pathing. Which option allows you to create policies using both the AWS Console and CLI? iii. Is there an advantage to using the option that requires you to edit polices via the CLI? Task 2 - Create an IAM policy with permission to create IAM roles Build an IAM policy so that the web admins can create IAM roles (which they will use for AWS Lambda functions.) Web admins should be able to attach to these roles existing AWS and customer managed policies. The web admins should only be able to edit the roles they create, not any other roles. Walk Through : Create a new IAM policy based on the hint below. Attach this policy to the webadmin user created in Task 1 . Hint : IAM Identifiers . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. Examine the existing resources (roles, Lambda functions) to make sure the policy will give access to existing resources owned by the web admins. It is recommended to use the same resource restriction throughout this phase to simplify the policies. { Version : 2012-10-17 , Statement : [ { Sid : CreateRoles , Effect : Allow , Action : [ iam:CreateRole , iam:UpdateRole , iam:DeleteRole , iam:AttachRolePolicy , iam:DetachRolePolicy ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/???? ] } ] } From the browser where you are logged into the console as the webadmin , verify you can create a role (while following the resource restriction.) This role should use Lambda as the trusted entity (we will use this role to test the next task). The policy attached to the role do not matter at this point. Question(s) : i. Why do resource restriction matter for roles? Task 3 - IAM policy to create Lambda functions The web admins can now create IAM policies and roles, so the next step is to give them permissions to create Lambda functions. They should be able to attach only IAM roles they created to the Lambda functions. In addition they should only be able to edit the Lambda functions they create, no other Lambda functions. Walk Through : Create a new IAM policy based on the hint below. Attach this policy to the webadmin user. Hint : IAM Identifiers . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : LambdaFullAccesswithResourceRestrictions , Effect : Allow , Action : lambda:* , Resource : arn:aws:lambda:us-east-2:ACCOUNT_ID:function:???? }, { Sid : PassRoletoLambda , Effect : Allow , Action : iam:PassRole , Resource : arn:aws:iam::ACCOUNT_ID:role/???? , Condition : { StringLikeIfExists : { iam:PassedToService : lambda.amazonaws.com } } }, { Sid : AdditionalPermissionsforLambda , Effect : Allow , Action : [ kms:ListAliases , logs:Describe* , logs:ListTagsLogGroup , logs:FilterLogEvents , logs:GetLogEvents ], Resource : * } ] } Again from the browser where you are logged into the console as the webadmin , verify the user can create a lambda function (while following the resource restriction.) Question(s) : i. The scenario where you have admins in an account that need to be able to create IAM polices, roles and Lambda functions is common. The ability to restrict the permissions of the roles attached to the Lambda functions is relatively new though and important to proper least privilege administration. How was this situation handled before permission boundaries came along? ii. Why do we not allow the web admins to attach any role to Lambda functions? Why do we let the admins only pass IAM roles they create to Lambda functions? iii. Are resource restrictions in this case of Lambda function creation really necessary? Task 4 - Create a permission boundary We have policies now so that the web admins can create and edit customer managed policies, roles and Lambda functions. We need to limit the permissions of the roles they create though. If not then the web admins could simply create new policies with full admin rights, attach these to the roles, pass these roles to Lambda functions and escalate their permissions (either intentitionally or inadventently). We will use permission boundaries to limits the effective permissions of the roles. The permission boundary should allow the following effective permissions for any role created by the web admins: i. Create log groups (but can not overwrite any other log groups) ii. Create log streams and put logs iii. List the objects from the S3 bucket name that starts with \"identitywksp-web-admins-applicat-rs3elbaccesslogs\" Walk Through : Create a new IAM policy that will act as the permission boundary for the web admins. Name the policy webadminpermissionboundary Hint : Permission boundaries . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateLogGroup , Effect : Allow , Action : logs:CreateLogGroup , Resource : arn:aws:logs:us-east-2:ACCOUNT_ID:* }, { Sid : CreateLogStreamandEvents , Effect : Allow , Action : [ logs:CreateLogStream , logs:PutLogEvents ], Resource : arn:aws:logs:us-east-2:ACCOUNT_ID:log-group:/aws/lambda/????:* }, { Sid : AllowedS3GetObject , Effect : Allow , Action : [ s3:List* ], Resource : arn:aws:s3:::web-admins-ACCOUNT_ID-* } ] } How couldyou test the permission boundary at this point? Question : i. From the standpoint of the policy language and how it is presented in the console, how does a permission boundary differ from a standard IAM policy? Task 5 - Create one permission policy that incorporate all of the preceding tasks and add a permission boundary condition Walk Through : You have two options here: Combine the policies created so far and reference the permission boundary created in the previous step. Use the complete policy below (with the usual changes.) Note that the policy below contains two additional sections (last two sections in the full policy below) that we did not address in the earlier steps. The additions are focused on denying the ability to change or delete the permission policy or the permission boundary. Also the policy below includes the permission boundary conditions and a few other changes because not all actions support the permission boundary condition. Name the new policy webadminpermissionpolicy and attach it to the webadmin user. Remove the earlier policies you added during the testing. When you are done the webadmin user should have only three policies attached: webadminpermissionpolicy, IAMReadOnlyAccess AWSLambdaReadOnlyAccess. Hint : Permission boundaries . The question marks ???? in the resource elements below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateCustomerManagedPolicies , Effect : Allow , Action : [ iam:CreatePolicy , iam:DeletePolicy , iam:CreatePolicyVersion , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : arn:aws:iam::ACCOUNT_ID:policy/???? }, { Sid : RoleandPolicyActionswithnoPermissionBoundarySupport , Effect : Allow , Action : [ iam:UpdateRole , iam:DeleteRole ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/???? ] }, { Sid : CreateRoles , Effect : Allow , Action : [ iam:CreateRole , iam:AttachRolePolicy , iam:DetachRolePolicy ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/???? ], Condition : { StringEquals : { iam:PermissionsBoundary : arn:aws:iam::ACCOUNT_ID:policy/webadminpermissionboundary } } }, { Sid : LambdaFullAccesswithResourceRestrictions , Effect : Allow , Action : lambda:* , Resource : arn:aws:lambda:us-east-2:ACCOUNT_ID:function:???? }, { Sid : PassRoletoLambda , Effect : Allow , Action : iam:PassRole , Resource : arn:aws:iam::ACCOUNT_ID:role/???? , Condition : { StringLikeIfExists : { iam:PassedToService : lambda.amazonaws.com } } }, { Sid : AdditionalPermissionsforLambda , Effect : Allow , Action : [ kms:ListAliases , logs:Describe* , logs:ListTagsLogGroup , logs:FilterLogEvents , logs:GetLogEvents ], Resource : * }, { Sid : DenyPermissionBoundaryandPolicyDeleteModify , Effect : Deny , Action : [ iam:CreatePolicyVersion , iam:DeletePolicy , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : [ arn:aws:iam::ACCOUNT_ID:policy/webadminpermissionboundary , arn:aws:iam::ACCOUNT_ID:policy/webadminpermissionpolicy ] }, { Sid : DenyRolePermissionBoundaryDelete , Effect : Deny , Action : iam:DeleteRolePermissionsBoundary , Resource : * } ] } Again from the browser where you are logged into the console as the webadmin , verify the user can create a policy, create a role (attaching both a permssion policy and permission boundary to the role) and finally create a Lambda function into which you will pass that role. All of the preceding steps need to be done will also following the resource restrictions. Question : i. Why do we add the Deny for DeletePolicy actions? ii. What would happen if we didn't deny the ability to delete permission boundaries? Task 6 - Gather info needed for the VERIFY phase Walk Through Now that you have setup the IAM user for the web admins, it's time to pass this information on to the next team who will work through the VERIFY tasks. You need to gather some details about your setupo and then hand this info to the next team. Here are all of the details you need to pass to another team. If you following the recommended naming conventions than you can use the answers below. If you were given a form to fill out then enter the info into the form. This needs to be given to another team so they can do the VERIFY phase tasks. Your team should collect the VERIFY phase form from another team so you can also work through the VERIFY tasks. IAM users sign-in link: https://Account_ID.signin.aws.amazon.com/console IAM user name: webadmin IAM user password: Resource restriction identifier: Permission boundary name: webadminpermissionboundary Permission policy name: webadminpermissionpolicy Do not hand out this info to the same team that is giving you the info - this way we will end up properly swapping between teams if we have an odd number of teams. Click here to go to the VERIFY phase","title":"Build Phase"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#permission-boundaries-round-build-phase","text":"Below are a series of tasks to delegate permissions to the web admins. In these tasks you will be creating smaller policies and testing them. In Task 5 you will combine these policies together into one permission policy. You should create each policy and test it before moving on to the next task. It helps to divide the team into people doing the tasks and people testing things out. So some of the members of the team will be logged in using SSO and following the instructions in the tasks while other members will be logged in as the webadmin user (created in Task 1 below) to test out the work done in each task.","title":"Permission boundaries round - Build Phase"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#task-1-create-an-iam-user-and-an-iam-policy-with-permission-to-create-customer-managed-policies","text":"Build an IAM policy so that web admins can create customer managed policies. They should only be able to edit the policies they create (no other managed policies). We will not be using inline policies for this exercise. \"In most cases, we recommend that you use managed policies instead of inline policies.\" IMPORTANT! As you use the provided IAM policies hints, keep in mind where you need to add the account ID, what resource restrictions to use and where a region is specified in the resource. All of these items can cause issues.","title":"Task 1 - Create an IAM user and an IAM policy with permission to create customer managed policies"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#walk-through","text":"Begin by navigating to the IAM console . We will grab the AWS account ID. On the first screen you see in the IAM console (which should be the Dashboard) you will see an IAM users sign-in link . Copy that link because you will need the account ID in the URL for the policies and you will need the entire URL when you hand this account to another team for the VERIFY phase. Click Users on the left menu and create a new IAM user named webadmin . Check AWS Management Console access and then either autogenerate a password or set a custom password. Uncheck Require password reset . Attach the AWS managed policies IAMReadOnlyAccess AWSLambdaReadOnlyAccess to the user. Next click \u201cPolicies\u201d on the left menu. Create a new IAM policy based on the hint below. Attach this policy to the IAM user you created. Hint : IAM Identifiers . You will want to use either naming or pathing resource restrictions in the IAM policy. The question marks \" ???? \" in the resource element below should be replaced with something that could act as a resource restriction. Examine the existing resources (roles, Lambda functions) to make sure the policy will give access to existing resources owned by the web admins. Replacing the question marks is really the key to this round. { Version : 2012-10-17 , Statement : [ { Sid : CreateCustomerManagedPolicies , Effect : Allow , Action : [ iam:CreatePolicy , iam:DeletePolicy , iam:CreatePolicyVersion , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : arn:aws:iam::ACCOUNT_ID:policy/???? } ] } You should login with the webadmin IAM user (using a different browser) to verify the user can create a policy (while following the resource restriction.) Use the IAM users sign-in link you gathered earlier to login. The permissions assigned to the policy do not matter for the test.","title":"Walk Through:"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#questions","text":"i. Why are we using resource restrictions here? ii. There are two ways of doing resource restrictions: naming and pathing. Which option allows you to create policies using both the AWS Console and CLI? iii. Is there an advantage to using the option that requires you to edit polices via the CLI?","title":"Question(s):"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#task-2-create-an-iam-policy-with-permission-to-create-iam-roles","text":"Build an IAM policy so that the web admins can create IAM roles (which they will use for AWS Lambda functions.) Web admins should be able to attach to these roles existing AWS and customer managed policies. The web admins should only be able to edit the roles they create, not any other roles.","title":"Task 2 - Create an IAM policy with permission to create IAM roles"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#walk-through_1","text":"Create a new IAM policy based on the hint below. Attach this policy to the webadmin user created in Task 1 . Hint : IAM Identifiers . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. Examine the existing resources (roles, Lambda functions) to make sure the policy will give access to existing resources owned by the web admins. It is recommended to use the same resource restriction throughout this phase to simplify the policies. { Version : 2012-10-17 , Statement : [ { Sid : CreateRoles , Effect : Allow , Action : [ iam:CreateRole , iam:UpdateRole , iam:DeleteRole , iam:AttachRolePolicy , iam:DetachRolePolicy ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/???? ] } ] } From the browser where you are logged into the console as the webadmin , verify you can create a role (while following the resource restriction.) This role should use Lambda as the trusted entity (we will use this role to test the next task). The policy attached to the role do not matter at this point.","title":"Walk Through:"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#questions_1","text":"i. Why do resource restriction matter for roles?","title":"Question(s):"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#task-3-iam-policy-to-create-lambda-functions","text":"The web admins can now create IAM policies and roles, so the next step is to give them permissions to create Lambda functions. They should be able to attach only IAM roles they created to the Lambda functions. In addition they should only be able to edit the Lambda functions they create, no other Lambda functions.","title":"Task 3 - IAM policy to create Lambda functions"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#walk-through_2","text":"Create a new IAM policy based on the hint below. Attach this policy to the webadmin user. Hint : IAM Identifiers . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : LambdaFullAccesswithResourceRestrictions , Effect : Allow , Action : lambda:* , Resource : arn:aws:lambda:us-east-2:ACCOUNT_ID:function:???? }, { Sid : PassRoletoLambda , Effect : Allow , Action : iam:PassRole , Resource : arn:aws:iam::ACCOUNT_ID:role/???? , Condition : { StringLikeIfExists : { iam:PassedToService : lambda.amazonaws.com } } }, { Sid : AdditionalPermissionsforLambda , Effect : Allow , Action : [ kms:ListAliases , logs:Describe* , logs:ListTagsLogGroup , logs:FilterLogEvents , logs:GetLogEvents ], Resource : * } ] } Again from the browser where you are logged into the console as the webadmin , verify the user can create a lambda function (while following the resource restriction.)","title":"Walk Through:"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#questions_2","text":"i. The scenario where you have admins in an account that need to be able to create IAM polices, roles and Lambda functions is common. The ability to restrict the permissions of the roles attached to the Lambda functions is relatively new though and important to proper least privilege administration. How was this situation handled before permission boundaries came along? ii. Why do we not allow the web admins to attach any role to Lambda functions? Why do we let the admins only pass IAM roles they create to Lambda functions? iii. Are resource restrictions in this case of Lambda function creation really necessary?","title":"Question(s):"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#task-4-create-a-permission-boundary","text":"We have policies now so that the web admins can create and edit customer managed policies, roles and Lambda functions. We need to limit the permissions of the roles they create though. If not then the web admins could simply create new policies with full admin rights, attach these to the roles, pass these roles to Lambda functions and escalate their permissions (either intentitionally or inadventently). We will use permission boundaries to limits the effective permissions of the roles. The permission boundary should allow the following effective permissions for any role created by the web admins: i. Create log groups (but can not overwrite any other log groups) ii. Create log streams and put logs iii. List the objects from the S3 bucket name that starts with \"identitywksp-web-admins-applicat-rs3elbaccesslogs\"","title":"Task 4 - Create a permission boundary"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#walk-through_3","text":"Create a new IAM policy that will act as the permission boundary for the web admins. Name the policy webadminpermissionboundary Hint : Permission boundaries . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateLogGroup , Effect : Allow , Action : logs:CreateLogGroup , Resource : arn:aws:logs:us-east-2:ACCOUNT_ID:* }, { Sid : CreateLogStreamandEvents , Effect : Allow , Action : [ logs:CreateLogStream , logs:PutLogEvents ], Resource : arn:aws:logs:us-east-2:ACCOUNT_ID:log-group:/aws/lambda/????:* }, { Sid : AllowedS3GetObject , Effect : Allow , Action : [ s3:List* ], Resource : arn:aws:s3:::web-admins-ACCOUNT_ID-* } ] } How couldyou test the permission boundary at this point?","title":"Walk Through:"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#question","text":"i. From the standpoint of the policy language and how it is presented in the console, how does a permission boundary differ from a standard IAM policy?","title":"Question:"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#task-5-create-one-permission-policy-that-incorporate-all-of-the-preceding-tasks-and-add-a-permission-boundary-condition","text":"","title":"Task 5 - Create one permission policy that incorporate all of the preceding tasks and add a permission boundary condition"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#walk-through_4","text":"You have two options here: Combine the policies created so far and reference the permission boundary created in the previous step. Use the complete policy below (with the usual changes.) Note that the policy below contains two additional sections (last two sections in the full policy below) that we did not address in the earlier steps. The additions are focused on denying the ability to change or delete the permission policy or the permission boundary. Also the policy below includes the permission boundary conditions and a few other changes because not all actions support the permission boundary condition. Name the new policy webadminpermissionpolicy and attach it to the webadmin user. Remove the earlier policies you added during the testing. When you are done the webadmin user should have only three policies attached: webadminpermissionpolicy, IAMReadOnlyAccess AWSLambdaReadOnlyAccess. Hint : Permission boundaries . The question marks ???? in the resource elements below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateCustomerManagedPolicies , Effect : Allow , Action : [ iam:CreatePolicy , iam:DeletePolicy , iam:CreatePolicyVersion , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : arn:aws:iam::ACCOUNT_ID:policy/???? }, { Sid : RoleandPolicyActionswithnoPermissionBoundarySupport , Effect : Allow , Action : [ iam:UpdateRole , iam:DeleteRole ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/???? ] }, { Sid : CreateRoles , Effect : Allow , Action : [ iam:CreateRole , iam:AttachRolePolicy , iam:DetachRolePolicy ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/???? ], Condition : { StringEquals : { iam:PermissionsBoundary : arn:aws:iam::ACCOUNT_ID:policy/webadminpermissionboundary } } }, { Sid : LambdaFullAccesswithResourceRestrictions , Effect : Allow , Action : lambda:* , Resource : arn:aws:lambda:us-east-2:ACCOUNT_ID:function:???? }, { Sid : PassRoletoLambda , Effect : Allow , Action : iam:PassRole , Resource : arn:aws:iam::ACCOUNT_ID:role/???? , Condition : { StringLikeIfExists : { iam:PassedToService : lambda.amazonaws.com } } }, { Sid : AdditionalPermissionsforLambda , Effect : Allow , Action : [ kms:ListAliases , logs:Describe* , logs:ListTagsLogGroup , logs:FilterLogEvents , logs:GetLogEvents ], Resource : * }, { Sid : DenyPermissionBoundaryandPolicyDeleteModify , Effect : Deny , Action : [ iam:CreatePolicyVersion , iam:DeletePolicy , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : [ arn:aws:iam::ACCOUNT_ID:policy/webadminpermissionboundary , arn:aws:iam::ACCOUNT_ID:policy/webadminpermissionpolicy ] }, { Sid : DenyRolePermissionBoundaryDelete , Effect : Deny , Action : iam:DeleteRolePermissionsBoundary , Resource : * } ] } Again from the browser where you are logged into the console as the webadmin , verify the user can create a policy, create a role (attaching both a permssion policy and permission boundary to the role) and finally create a Lambda function into which you will pass that role. All of the preceding steps need to be done will also following the resource restrictions.","title":"Walk Through:"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#question_1","text":"i. Why do we add the Deny for DeletePolicy actions? ii. What would happen if we didn't deny the ability to delete permission boundaries?","title":"Question:"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#task-6-gather-info-needed-for-the-verify-phase","text":"Walk Through Now that you have setup the IAM user for the web admins, it's time to pass this information on to the next team who will work through the VERIFY tasks. You need to gather some details about your setupo and then hand this info to the next team. Here are all of the details you need to pass to another team. If you following the recommended naming conventions than you can use the answers below. If you were given a form to fill out then enter the info into the form. This needs to be given to another team so they can do the VERIFY phase tasks. Your team should collect the VERIFY phase form from another team so you can also work through the VERIFY tasks. IAM users sign-in link: https://Account_ID.signin.aws.amazon.com/console IAM user name: webadmin IAM user password: Resource restriction identifier: Permission boundary name: webadminpermissionboundary Permission policy name: webadminpermissionpolicy Do not hand out this info to the same team that is giving you the info - this way we will end up properly swapping between teams if we have an odd number of teams.","title":"Task 6 - Gather info needed for the VERIFY phase"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#click-here-to-go-to-the-verify-phase","text":"","title":"Click here to go to the VERIFY phase"},{"location":"workshops/identity-round-robin/permission-boundaries/verify/","text":"Permission boundaries round - VERIFY phase We are now in the VERIFY phase. It is time to put on the hat of the web admins and test out their access. First you verify that you are able to do what you should be allowed to do. With any remaining time, check if there are other resources in the account that you can access. You should have receieved from another team the following information: IAM users sign-in link: https://Account_ID.signin.aws.amazon.com/console IAM user name: webadmin IAM user password: Resource restriction identifier: Permission boundary name: webadminpermissionboundary Permission policy name: webadminpermissionpolicy The web admins should only have access to the following resources: IAM policies and roles created by the web admins Lambda functions created by the web admins The web admins should not be able to impact any resources in the account that they do not own including IAM users, roles, S3 buckets, Lambda functions, etc. You will be setting up an IAM policy, an IAM role and a Lambda function. The Lambda function should be able to list files in an S3 bucket. Application architecture: -- Task 1 - Create a customer managed IAM policy The first step is to create a customer managed IAM policy. This will set the permissions of the role that you will pass to a Lambda function. Since the function will be working with S3 and since the point of this is to show how permission boundaries work, use the following policy which grants basic Lambda logging permissions and S3 full access. Keep in mind the resource restrictions put in place which will require you to use a certain name for the policy. { Version : 2012-10-17 , Statement : [ { Effect : Allow , Action : [ logs:CreateLogGroup , logs:CreateLogStream , logs:PutLogEvents , s3:* ], Resource : * } ] } Task 2 - Create an IAM role Next you will create an IAM Role. Choose Lambda as the service for this role. Attach the policy you just created and the permission boundary (which will most likely be named: webadminpermissionboundary ) Keep in mind the resource restrictions put in place which will require you to use a certain name for the role. Task 3 - Create a Lambda function Finally you will create a Node.js 8.10 Lambda function using the code below and attach the IAM role you just created to it. You will need to replace \"WEB_ADMIN_BUCKET_NAME\" with the bucket from the account that begins with \"web-admins-\" . and ends in \"-data\" const AWS = require ( aws-sdk ); const s3 = new AWS . S3 (); exports . handler = async ( event ) = { console.log( Loading function ) ; const allKeys = [] ; await getKeys({ Bucket : WEB_ADMIN_BUCKET_NAME } , allKeys ); return allKeys ; } ; async function getKeys ( params , keys ) { const response = await s3.listObjectsV2(params).promise() ; response.Contents.forEach(obj = keys.push(obj.Key)) ; if (response.IsTruncated) { const newParams = Object.assign({ } , params ); newParams . ContinuationToken = response . NextContinuationToken ; await getKeys ( newParams , keys ); } } Test the Lambda function and make sure it is generating logs in CloudWatch logs and that it is able to list the objects in the bucket. In order to test you will need to create a test event. The parameters of the test do not matter. Task 4 - Investigate if you are able to do anything else. The final step is to determine if you can do anything else in the account. Can you impact any resources not owned by the web admins?","title":"Verify Phase"},{"location":"workshops/identity-round-robin/permission-boundaries/verify/#permission-boundaries-round-verify-phase","text":"We are now in the VERIFY phase. It is time to put on the hat of the web admins and test out their access. First you verify that you are able to do what you should be allowed to do. With any remaining time, check if there are other resources in the account that you can access. You should have receieved from another team the following information: IAM users sign-in link: https://Account_ID.signin.aws.amazon.com/console IAM user name: webadmin IAM user password: Resource restriction identifier: Permission boundary name: webadminpermissionboundary Permission policy name: webadminpermissionpolicy The web admins should only have access to the following resources: IAM policies and roles created by the web admins Lambda functions created by the web admins The web admins should not be able to impact any resources in the account that they do not own including IAM users, roles, S3 buckets, Lambda functions, etc. You will be setting up an IAM policy, an IAM role and a Lambda function. The Lambda function should be able to list files in an S3 bucket. Application architecture: --","title":"Permission boundaries round - VERIFY phase"},{"location":"workshops/identity-round-robin/permission-boundaries/verify/#task-1-create-a-customer-managed-iam-policy","text":"The first step is to create a customer managed IAM policy. This will set the permissions of the role that you will pass to a Lambda function. Since the function will be working with S3 and since the point of this is to show how permission boundaries work, use the following policy which grants basic Lambda logging permissions and S3 full access. Keep in mind the resource restrictions put in place which will require you to use a certain name for the policy. { Version : 2012-10-17 , Statement : [ { Effect : Allow , Action : [ logs:CreateLogGroup , logs:CreateLogStream , logs:PutLogEvents , s3:* ], Resource : * } ] }","title":"Task 1 - Create a customer managed IAM policy"},{"location":"workshops/identity-round-robin/permission-boundaries/verify/#task-2-create-an-iam-role","text":"Next you will create an IAM Role. Choose Lambda as the service for this role. Attach the policy you just created and the permission boundary (which will most likely be named: webadminpermissionboundary ) Keep in mind the resource restrictions put in place which will require you to use a certain name for the role.","title":"Task 2 - Create an IAM role"},{"location":"workshops/identity-round-robin/permission-boundaries/verify/#task-3-create-a-lambda-function","text":"Finally you will create a Node.js 8.10 Lambda function using the code below and attach the IAM role you just created to it. You will need to replace \"WEB_ADMIN_BUCKET_NAME\" with the bucket from the account that begins with \"web-admins-\" . and ends in \"-data\" const AWS = require ( aws-sdk ); const s3 = new AWS . S3 (); exports . handler = async ( event ) = { console.log( Loading function ) ; const allKeys = [] ; await getKeys({ Bucket : WEB_ADMIN_BUCKET_NAME } , allKeys ); return allKeys ; } ; async function getKeys ( params , keys ) { const response = await s3.listObjectsV2(params).promise() ; response.Contents.forEach(obj = keys.push(obj.Key)) ; if (response.IsTruncated) { const newParams = Object.assign({ } , params ); newParams . ContinuationToken = response . NextContinuationToken ; await getKeys ( newParams , keys ); } } Test the Lambda function and make sure it is generating logs in CloudWatch logs and that it is able to list the objects in the bucket. In order to test you will need to create a test event. The parameters of the test do not matter.","title":"Task 3 - Create a Lambda function"},{"location":"workshops/identity-round-robin/permission-boundaries/verify/#task-4-investigate-if-you-are-able-to-do-anything-else","text":"The final step is to determine if you can do anything else in the account. Can you impact any resources not owned by the web admins?","title":"Task 4 - Investigate if you are able to do anything else."},{"location":"workshops/identity-round-robin/serverless/","text":"Serverless Round Welcome to the world of serverless! Now you may be asking yourself, What is serverless ? Well, it is an architecture paradigm that allows you to create your applications without provisioning or managing any servers. Sounds great, right? Organizations look at building serverless applications as a way of improving their scalability and reducing their operational overhead. The responsibility of the underlying infrastructure is shifted off your plate so you can spend more time focusing on building your applications. So with less infrastructure to manage you are no longer responsible for patching your operating systems and the attack surface you need to worry about has been significantly reduced. But with the use of serverless technologies comes other responsibility. When you hear the word serverless you may think specifically of AWS Lambda but it is important to remember that there are other services used within a serverless application and securing an application involves more than just securing your Lambda functions. In this round you will be focused on improving the identity controls of the WildRydes serverless application (which is borrowed from aws-serverless-workshops and retrofitted for the purposes of this round). You will get exposed to different identity concepts through the use of a variety of services such as AWS IAM , Amazon S3 , Amazon CloudFront , and Amazon Cognito . Upon completion you should have a better idea of how to use native AWS identity controls to improve the security posture of a serverless application. AWS Service/Feature Coverage : S3 Bucket Policies S3 ACLs CloudFront Origin Access Identities Cognito User Pools Cognito Hosted UI Agenda This round is broken down into a BUILD VERIFY phase. BUILD (60 min): The Build phase involves evaluating, implementing, and enhancing the identity controls of the WildRydes application based on a set of business level functional and non-functional requirements. VERIFY (15 min): The Verify phase involves putting on the hat of an end user and testing the controls you put in place to ensure the requirements were met. In addition you will also ensure that a systems administrator is still able to manage the resources. Team or Individual Exercise This workshop can be done as a team exercise or individually. The instructions are written with the assumption that you are working as part of a team but you could just as easily do the steps below individually. If done as part of an AWS sponsored event then you'll be split into teams of around 4-6 people. Each team will do the BUILD phase and then hand off their accounts to another team. Then each team will do the VERIFY phase. Presentation Workshop Presentation Powerpoint Environment setup To setup your environment please expand one of the following dropdown sections (depending on how you're doing this workshop) and follow the instructions: AWS Sponsored Event Browse to the URL provided to you and login. After you login click the AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for the Management console . Click on that and you will be taken to the AWS console. Individual Launch the CloudFormation stack below to setup the WildRydes application: Region Deploy US East 1 (N. Virginia) Click the Deploy to AWS button above (right click and open in a new tab). This will automatically take you to the console to run the template. Click Next on the Specify Template section. On the Specify Details step, add a Team Number and a validation AWS Account and then click Next . The Team Name is only relevant when running this as a team so that the Verify team can reach out to the Build team with any questions. The account will be the one the Verify team uses to validate the controls put in place during the BUILD phase. If you are doing both phases in a single AWS account and as an individual put whatever you want for the team name and the AWS account number for the account you are currently using. Click Next on the Options section. Finally, acknowledge that the template will create IAM roles under Capabilities and click Create**. This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE . WildRydes identity overhaul You just joined a new DevOps team who manages a suite of animal-based ride sharing applications. Given your security background you've been embedded on the team to take the lead on security related tasks, evangelize security best practices, and represent your team when interacting with your security organization. Recently, your team inherited a new application; WildRydes. View your application Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and click on WebsiteCloudFrontURL . As part of the hand off to your team, the product team shared their vision for the application and stated that future iterations will include more dynamic features. After doing an evaluation of the architecture you determined that the WildRydes application is a static website hosted in an S3 bucket. There is a CloudFront Distribution setup to be used as a content delivery network and a Cognito User Pool for user management. Current application architecture After thoroughly evaluating the architecture and doing a threat modeling exercise your team has identified a number of broken features and misconfigurations. It looks as though someone started putting in place certain security controls but were not able to fully implement them. These reviews resulted in the creation of a couple tasks that were added to the backlog for your team and given a high priority. Click Next to move on to the Build Phase !","title":"Scenario"},{"location":"workshops/identity-round-robin/serverless/#serverless-round","text":"Welcome to the world of serverless! Now you may be asking yourself, What is serverless ? Well, it is an architecture paradigm that allows you to create your applications without provisioning or managing any servers. Sounds great, right? Organizations look at building serverless applications as a way of improving their scalability and reducing their operational overhead. The responsibility of the underlying infrastructure is shifted off your plate so you can spend more time focusing on building your applications. So with less infrastructure to manage you are no longer responsible for patching your operating systems and the attack surface you need to worry about has been significantly reduced. But with the use of serverless technologies comes other responsibility. When you hear the word serverless you may think specifically of AWS Lambda but it is important to remember that there are other services used within a serverless application and securing an application involves more than just securing your Lambda functions. In this round you will be focused on improving the identity controls of the WildRydes serverless application (which is borrowed from aws-serverless-workshops and retrofitted for the purposes of this round). You will get exposed to different identity concepts through the use of a variety of services such as AWS IAM , Amazon S3 , Amazon CloudFront , and Amazon Cognito . Upon completion you should have a better idea of how to use native AWS identity controls to improve the security posture of a serverless application. AWS Service/Feature Coverage : S3 Bucket Policies S3 ACLs CloudFront Origin Access Identities Cognito User Pools Cognito Hosted UI","title":"Serverless Round"},{"location":"workshops/identity-round-robin/serverless/#agenda","text":"This round is broken down into a BUILD VERIFY phase. BUILD (60 min): The Build phase involves evaluating, implementing, and enhancing the identity controls of the WildRydes application based on a set of business level functional and non-functional requirements. VERIFY (15 min): The Verify phase involves putting on the hat of an end user and testing the controls you put in place to ensure the requirements were met. In addition you will also ensure that a systems administrator is still able to manage the resources. Team or Individual Exercise This workshop can be done as a team exercise or individually. The instructions are written with the assumption that you are working as part of a team but you could just as easily do the steps below individually. If done as part of an AWS sponsored event then you'll be split into teams of around 4-6 people. Each team will do the BUILD phase and then hand off their accounts to another team. Then each team will do the VERIFY phase.","title":"Agenda"},{"location":"workshops/identity-round-robin/serverless/#presentation","text":"Workshop Presentation Powerpoint","title":"Presentation"},{"location":"workshops/identity-round-robin/serverless/#environment-setup","text":"To setup your environment please expand one of the following dropdown sections (depending on how you're doing this workshop) and follow the instructions: AWS Sponsored Event Browse to the URL provided to you and login. After you login click the AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for the Management console . Click on that and you will be taken to the AWS console. Individual Launch the CloudFormation stack below to setup the WildRydes application: Region Deploy US East 1 (N. Virginia) Click the Deploy to AWS button above (right click and open in a new tab). This will automatically take you to the console to run the template. Click Next on the Specify Template section. On the Specify Details step, add a Team Number and a validation AWS Account and then click Next . The Team Name is only relevant when running this as a team so that the Verify team can reach out to the Build team with any questions. The account will be the one the Verify team uses to validate the controls put in place during the BUILD phase. If you are doing both phases in a single AWS account and as an individual put whatever you want for the team name and the AWS account number for the account you are currently using. Click Next on the Options section. Finally, acknowledge that the template will create IAM roles under Capabilities and click Create**. This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE .","title":"Environment setup"},{"location":"workshops/identity-round-robin/serverless/#wildrydes-identity-overhaul","text":"You just joined a new DevOps team who manages a suite of animal-based ride sharing applications. Given your security background you've been embedded on the team to take the lead on security related tasks, evangelize security best practices, and represent your team when interacting with your security organization. Recently, your team inherited a new application; WildRydes.","title":"WildRydes identity overhaul"},{"location":"workshops/identity-round-robin/serverless/#view-your-application","text":"Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and click on WebsiteCloudFrontURL . As part of the hand off to your team, the product team shared their vision for the application and stated that future iterations will include more dynamic features. After doing an evaluation of the architecture you determined that the WildRydes application is a static website hosted in an S3 bucket. There is a CloudFront Distribution setup to be used as a content delivery network and a Cognito User Pool for user management.","title":"View your application"},{"location":"workshops/identity-round-robin/serverless/#current-application-architecture","text":"After thoroughly evaluating the architecture and doing a threat modeling exercise your team has identified a number of broken features and misconfigurations. It looks as though someone started putting in place certain security controls but were not able to fully implement them. These reviews resulted in the creation of a couple tasks that were added to the backlog for your team and given a high priority. Click Next to move on to the Build Phase !","title":"Current application architecture"},{"location":"workshops/identity-round-robin/serverless/build/","text":"Serverless Round Build Phase Since you are championing the security tasks for your team, you pick up the two tasks for the WildRydes application. Please read through and complete the following tasks. Good Luck! Task 1 Reduce the attack surface of the origin Ensure the application serves content out through the CloudFront Distribution and that your end users can only access the application through CloudFront URLs and not Amazon S3 URLs. As part of this configuration your end users should not be able to affect the availability or integrity of the application. Key Security Benefits Obfuscates the S3 origin Forces traffic over HTTPS with custom certificates Adds DDoS protection to your application and enables the future use of AWS WAF and AWS Shield View the Existing Policy First, view the existing S3 bucket policy to see what permissions the previous engineers created. Go to the Amazon S3 console Click on the identity-wksp-serverless- ACCOUNT# >-us-east-1-wildrydes bucket. Click on the Permissions tab and then click on Bucket Policy . What's wrong with this policy? What does \"Principal\": \"*\" mean? Both \"Principal\": \"*\" and \"Principal\":{\"AWS\":\"*\"} grant permission to everyone (also referred to as anonymous access). Use caution when granting anonymous access to your S3 bucket. When you grant anonymous access, anyone in the world can access your bucket. We highly recommend that you never grant any kind of anonymous write access to your S3 bucket. Modify Principal Since the current bucket allows for anonymous access, you need to change this to only allow access from the CloudFront Distribution. Go to the Amazon CloudFront console. You should see a Web Distribution for the WildRydes web application. Click on Origin Access Identities in the left navigation. You should see an identity named Unicorn OAI . CloudFront Origin Access Identity An Origin Access Identity (OAI) is a special CloudFront identity that you can associate with a Distribution in order restrict access using AWS IAM. You can also find the OAI by viewing your Web Distribution Copy down the ID. Go back to the Amazon S3 console and open up the bucket policy. Replace the principal with the following and click save : Principal : { AWS : arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity OAI ID } , Info You could also use the canonical user id as the principal: \"CanonicalUser\": \" OAI S3CanonicalUserId \" Modify Actions Now that the principal is restricted to the identity associated with the CloudFront distribution you can take a closer look at the permissions. Go back to the Amazon S3 console and open up the bucket policy. Does CloudFront really need access to Delete Objects? The distribution is acting as a CDN for the static site so it only needs read access to the S3 bucket. Change the actions to ensure an end user can not affect the integrity of the site. Test the new bucket policy Now that the bucket policy has been updated, go validate that you can not access the website using an S3 URL. Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and click on WebsiteS3URL . Are you still able to access the site using the S3 URL? Solve the Mystery So you've modified the bucket policy to restrict access to read only actions from the CloudFront Distribution but for some reason you are still able to access the site using S3 URLs. Do some investigation into why this is the case and put in the additional control necessary to restrict the traffic. Tip What other access controls exist within S3? Look into the following resources: S3 Block Public Access (easiest) AWS IAM Policy Elements: NotPrincipal (hardest) Be sure to clear your cache when testing! Task 2 Set up application user management Set up user management for the application using Cognito User pools. To reduce the operational overhead of creating and maintaining forms and custom logic for authentication, the decision has been made to use the Cognito hosted-UI to integrate the application with the User Pool. As part of the user experience users should be able to sign themselves up, they should have to validate their email address, and be required to create a password that meets the password complexity requirements for applications set in your security standards. Password Complexity Requirements for Applications Minimum length of 10 characters Must include symbols Must include numbers Must include uppercase characters Must include lowercase characters Application Integration Requirements Implicit grant OAuth flow Scopes: email openid Upon successful authentication the user should be redirected to ride.html Configure User Pool Go to the Amazon Cognito console (us-east-1) Click on Manage User Pools and then click on the WildRydes pool. Click on Policies in the left navigation and modify the password policy, enable users to sign themselves up, and save your changes. Click on MFA and Verifications in the left navigation, enable email verification, and save your changes. Configure App Integration Click on App Client Settings in the left navigation and enter the following and click Save changes : Enabled Identity Providers: Cognito User Pool Callback URL: WebsiteCloudFrontURL>/ride.html Sign Out URL: WebsiteCloudFrontURL>/index.html Allowed OAuth Flows: Implicit Grant Allowed OAuth Scope: email openid Click on Domain Name in the left navigation, enter a unique domain name, and save your changes. Construct the Hosted-UI URL Now that your User Pool and App Integration have been configured you can construct the URL to allow users to sign-in via the Cognito Hosted Wed UI (built-in webpages for signing up and signing in your users). your_domain /login?response_type= code or token client_id= your_app_client_id redirect_uri= your_callback_url Tip Replace the values in (including the carrots) to the correct values. All can be found in your Cognito configuration. The response type is based on the OAuth flow. Reference Documentation Go to the S3 console and click on the bucket named: identity-wksp-serverless- ACCOUNT#>-us-east-1-wildrydes . Open index.html and add the hosted UI URL to the Giddy Up button. Upload index.html back to the S3 bucket. After you have completed these tasks you can move on to the Verify Phase. Warning If you are doing this as part of an AWS sponsored event STOP here and wait for further instructions on the hand off to the next team.","title":"Build Phase"},{"location":"workshops/identity-round-robin/serverless/build/#serverless-round-build-phase","text":"Since you are championing the security tasks for your team, you pick up the two tasks for the WildRydes application. Please read through and complete the following tasks. Good Luck!","title":"Serverless Round Build Phase"},{"location":"workshops/identity-round-robin/serverless/build/#task-1-reduce-the-attack-surface-of-the-origin","text":"Ensure the application serves content out through the CloudFront Distribution and that your end users can only access the application through CloudFront URLs and not Amazon S3 URLs. As part of this configuration your end users should not be able to affect the availability or integrity of the application. Key Security Benefits Obfuscates the S3 origin Forces traffic over HTTPS with custom certificates Adds DDoS protection to your application and enables the future use of AWS WAF and AWS Shield","title":"Task 1 Reduce the attack surface of the origin"},{"location":"workshops/identity-round-robin/serverless/build/#view-the-existing-policy","text":"First, view the existing S3 bucket policy to see what permissions the previous engineers created. Go to the Amazon S3 console Click on the identity-wksp-serverless- ACCOUNT# >-us-east-1-wildrydes bucket. Click on the Permissions tab and then click on Bucket Policy . What's wrong with this policy? What does \"Principal\": \"*\" mean? Both \"Principal\": \"*\" and \"Principal\":{\"AWS\":\"*\"} grant permission to everyone (also referred to as anonymous access). Use caution when granting anonymous access to your S3 bucket. When you grant anonymous access, anyone in the world can access your bucket. We highly recommend that you never grant any kind of anonymous write access to your S3 bucket.","title":"View the Existing Policy"},{"location":"workshops/identity-round-robin/serverless/build/#modify-principal","text":"Since the current bucket allows for anonymous access, you need to change this to only allow access from the CloudFront Distribution. Go to the Amazon CloudFront console. You should see a Web Distribution for the WildRydes web application. Click on Origin Access Identities in the left navigation. You should see an identity named Unicorn OAI . CloudFront Origin Access Identity An Origin Access Identity (OAI) is a special CloudFront identity that you can associate with a Distribution in order restrict access using AWS IAM. You can also find the OAI by viewing your Web Distribution Copy down the ID. Go back to the Amazon S3 console and open up the bucket policy. Replace the principal with the following and click save : Principal : { AWS : arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity OAI ID } , Info You could also use the canonical user id as the principal: \"CanonicalUser\": \" OAI S3CanonicalUserId \"","title":"Modify Principal"},{"location":"workshops/identity-round-robin/serverless/build/#modify-actions","text":"Now that the principal is restricted to the identity associated with the CloudFront distribution you can take a closer look at the permissions. Go back to the Amazon S3 console and open up the bucket policy. Does CloudFront really need access to Delete Objects? The distribution is acting as a CDN for the static site so it only needs read access to the S3 bucket. Change the actions to ensure an end user can not affect the integrity of the site.","title":"Modify Actions"},{"location":"workshops/identity-round-robin/serverless/build/#test-the-new-bucket-policy","text":"Now that the bucket policy has been updated, go validate that you can not access the website using an S3 URL. Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and click on WebsiteS3URL . Are you still able to access the site using the S3 URL?","title":"Test the new bucket policy"},{"location":"workshops/identity-round-robin/serverless/build/#solve-the-mystery","text":"So you've modified the bucket policy to restrict access to read only actions from the CloudFront Distribution but for some reason you are still able to access the site using S3 URLs. Do some investigation into why this is the case and put in the additional control necessary to restrict the traffic. Tip What other access controls exist within S3? Look into the following resources: S3 Block Public Access (easiest) AWS IAM Policy Elements: NotPrincipal (hardest) Be sure to clear your cache when testing!","title":"Solve the Mystery"},{"location":"workshops/identity-round-robin/serverless/build/#task-2-set-up-application-user-management","text":"Set up user management for the application using Cognito User pools. To reduce the operational overhead of creating and maintaining forms and custom logic for authentication, the decision has been made to use the Cognito hosted-UI to integrate the application with the User Pool. As part of the user experience users should be able to sign themselves up, they should have to validate their email address, and be required to create a password that meets the password complexity requirements for applications set in your security standards. Password Complexity Requirements for Applications Minimum length of 10 characters Must include symbols Must include numbers Must include uppercase characters Must include lowercase characters Application Integration Requirements Implicit grant OAuth flow Scopes: email openid Upon successful authentication the user should be redirected to ride.html","title":"Task 2 Set up application user management"},{"location":"workshops/identity-round-robin/serverless/build/#configure-user-pool","text":"Go to the Amazon Cognito console (us-east-1) Click on Manage User Pools and then click on the WildRydes pool. Click on Policies in the left navigation and modify the password policy, enable users to sign themselves up, and save your changes. Click on MFA and Verifications in the left navigation, enable email verification, and save your changes.","title":"Configure User Pool"},{"location":"workshops/identity-round-robin/serverless/build/#configure-app-integration","text":"Click on App Client Settings in the left navigation and enter the following and click Save changes : Enabled Identity Providers: Cognito User Pool Callback URL: WebsiteCloudFrontURL>/ride.html Sign Out URL: WebsiteCloudFrontURL>/index.html Allowed OAuth Flows: Implicit Grant Allowed OAuth Scope: email openid Click on Domain Name in the left navigation, enter a unique domain name, and save your changes.","title":"Configure App Integration"},{"location":"workshops/identity-round-robin/serverless/build/#construct-the-hosted-ui-url","text":"Now that your User Pool and App Integration have been configured you can construct the URL to allow users to sign-in via the Cognito Hosted Wed UI (built-in webpages for signing up and signing in your users). your_domain /login?response_type= code or token client_id= your_app_client_id redirect_uri= your_callback_url Tip Replace the values in (including the carrots) to the correct values. All can be found in your Cognito configuration. The response type is based on the OAuth flow. Reference Documentation Go to the S3 console and click on the bucket named: identity-wksp-serverless- ACCOUNT#>-us-east-1-wildrydes . Open index.html and add the hosted UI URL to the Giddy Up button. Upload index.html back to the S3 bucket. After you have completed these tasks you can move on to the Verify Phase. Warning If you are doing this as part of an AWS sponsored event STOP here and wait for further instructions on the hand off to the next team.","title":"Construct the Hosted-UI URL"},{"location":"workshops/identity-round-robin/serverless/verify/","text":"Serverless Round Verify Phase Now that the additional identity controls have been added to the application, you have been tasked with acting as an end user and manually testing to verify that the controls have been put in place correctly and that the requirements have been met. Login Instructions The Build team created a cross-account AWS IAM Role to allow you complete your testing and verification tasks. To complete your tasks switch roles in the AWS Management Console to this role. Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and copy down VerifyAWSAccount . Click your account drop down in the top right corner of the Management Console next to the bell (third from the right). Click on Switch Roles Enter the following information Account : VerifyAWSAccount # Role : identity-wksp-serverless-verify Display Name : Build Color : your choice Now that you are logged into the Build AWS account you can access find their application URLs in the CloudFormation stack Outputs. Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and use WebsiteCloudFrontURL and WebsiteS3URL . Verify Task 1 Ensure the application serves content out through the CloudFront Distribution and that your end users can only access the application through CloudFront URLs and not Amazon S3 URLs. As part of this configuration your end users should not be able to affect the availability or integrity of the application. Verification Checklist You can access the site through the CloudFront Distribution URL ( WebsiteCloudFrontURL>). You are restricted from accessing any of the application resources through S3 URLs ( WebsiteS3URL>). Try some deep links (e.g. WebsiteS3URL>/js/vendor/unicorn-icon) You can not delete or modify any of the application resources through the CloudFront Distribution. Try using something like curl or Postman to make requests with different HTTP verbs (e.g. Delete). Below is an example using curl: curl -i -X DELETE WebsiteCloudFrontURL /index.html Verify Task 2 Set up user management for the application using Cognito User pools. To reduce the operational overhead of creating and maintaining forms and custom logic for authentication, the decision has been made to use the Cognito hosted-UI to integrate the application with the User Pool. As part of the user experience users should be able to sign themselves up, they should have to validate their email address, and be required to create a password that meets the password complexity requirements for applications set in your security standards. Verification Checklist You are taken to the hosted UI when clicking on Giddy Up . You are able to sign your self up for the site. You are required to create a password with the following complexity: Minimum length of 10 characters Must include symbols Must include numbers Must include uppercase characters You are required to verify your email address. After authentication, you are redirected to ride.html and are presented with your JWT IdToken. Final Architecture Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created, especially if you are doing other Identity rounds. Expand one of the following dropdown sections and follow the instructions: AWS Sponsored Event No cleanup required! The responsibility falls to AWS. Individual You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete the Amazon Cognito Domain for the hosted-UI. Go to the Amazon Cognito console. Click on the WildRydes pool. On the left navigation under App Integration , click on Domain Name . Click Delete Click the acknowledgement checkbox and click Delete Delete the CloudFormation stack ( Identity-RR-Wksp-Serverless-Round ). Go to the AWS CloudFormation console. Select the appropriate stack. Select Action . Click Delete Stack . Congratulations on completing the Serverless Round!","title":"Verify Phase"},{"location":"workshops/identity-round-robin/serverless/verify/#serverless-round-verify-phase","text":"Now that the additional identity controls have been added to the application, you have been tasked with acting as an end user and manually testing to verify that the controls have been put in place correctly and that the requirements have been met.","title":"Serverless Round Verify Phase"},{"location":"workshops/identity-round-robin/serverless/verify/#login-instructions","text":"The Build team created a cross-account AWS IAM Role to allow you complete your testing and verification tasks. To complete your tasks switch roles in the AWS Management Console to this role. Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and copy down VerifyAWSAccount . Click your account drop down in the top right corner of the Management Console next to the bell (third from the right). Click on Switch Roles Enter the following information Account : VerifyAWSAccount # Role : identity-wksp-serverless-verify Display Name : Build Color : your choice Now that you are logged into the Build AWS account you can access find their application URLs in the CloudFormation stack Outputs. Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and use WebsiteCloudFrontURL and WebsiteS3URL .","title":"Login Instructions"},{"location":"workshops/identity-round-robin/serverless/verify/#verify-task-1","text":"Ensure the application serves content out through the CloudFront Distribution and that your end users can only access the application through CloudFront URLs and not Amazon S3 URLs. As part of this configuration your end users should not be able to affect the availability or integrity of the application. Verification Checklist You can access the site through the CloudFront Distribution URL ( WebsiteCloudFrontURL>). You are restricted from accessing any of the application resources through S3 URLs ( WebsiteS3URL>). Try some deep links (e.g. WebsiteS3URL>/js/vendor/unicorn-icon) You can not delete or modify any of the application resources through the CloudFront Distribution. Try using something like curl or Postman to make requests with different HTTP verbs (e.g. Delete). Below is an example using curl: curl -i -X DELETE WebsiteCloudFrontURL /index.html","title":"Verify Task 1"},{"location":"workshops/identity-round-robin/serverless/verify/#verify-task-2","text":"Set up user management for the application using Cognito User pools. To reduce the operational overhead of creating and maintaining forms and custom logic for authentication, the decision has been made to use the Cognito hosted-UI to integrate the application with the User Pool. As part of the user experience users should be able to sign themselves up, they should have to validate their email address, and be required to create a password that meets the password complexity requirements for applications set in your security standards. Verification Checklist You are taken to the hosted UI when clicking on Giddy Up . You are able to sign your self up for the site. You are required to create a password with the following complexity: Minimum length of 10 characters Must include symbols Must include numbers Must include uppercase characters You are required to verify your email address. After authentication, you are redirected to ride.html and are presented with your JWT IdToken.","title":"Verify Task 2"},{"location":"workshops/identity-round-robin/serverless/verify/#final-architecture","text":"","title":"Final Architecture"},{"location":"workshops/identity-round-robin/serverless/verify/#cleanup","text":"In order to prevent charges to your account we recommend cleaning up the infrastructure that was created, especially if you are doing other Identity rounds. Expand one of the following dropdown sections and follow the instructions: AWS Sponsored Event No cleanup required! The responsibility falls to AWS. Individual You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete the Amazon Cognito Domain for the hosted-UI. Go to the Amazon Cognito console. Click on the WildRydes pool. On the left navigation under App Integration , click on Domain Name . Click Delete Click the acknowledgement checkbox and click Delete Delete the CloudFormation stack ( Identity-RR-Wksp-Serverless-Round ). Go to the AWS CloudFormation console. Select the appropriate stack. Select Action . Click Delete Stack . Congratulations on completing the Serverless Round!","title":"Cleanup"},{"location":"workshops/threat-detection-remediation/","text":"Find All the Threats: AWS Threat Detection and Remediation This workshop is designed to help you get familiar with AWS Security services and learn how to use them to identify and remediate threats in your environment. You'll be working with services such as Amazon GuardDuty, Amazon Macie, Amazon Inspector, Amazon CloudWatch, AWS Lambda, AWS Systems Manager, AWS Config, and AWS CloudTrail. You will learn how to use these services to investigate threats during and after an attack, set up a notification and remediation pipeline, and add additional protections to improve the security posture of your environment. Scenario Your company is new to the cloud and has recently performed a lift-and-shift of your infrastructure for piloting purposes. You are a systems administrator and have been tasked with security monitoring within your AWS environment. As part of that maintenance you are also responsible for responding to any security event in your environment. Architecture overview For this Workshop you will have a single instance setup in the us-west-2 region. As this was a \u201clift-and-shift\u201d migration for piloting, you have yet to build redundancy into your application, so you have a single public-facing web server. The web server has access to the Internet Gateway through an Elastic Network Interface. Customers access your web server through a DNS entry pointing to the Elastic Network Interface. You store static content in an S3 bucket and use the VPC S3 Endpoint Gateway for access from the web server. Presentation deck Workshop Presentation Deck Region Please use the us-west-2 (Oregon) region for this workshop. Modules Environment Build and Configuration Attack Simulation Detection and Remediation Review and Discussion Total time: 2 hours","title":"Overview"},{"location":"workshops/threat-detection-remediation/#find-all-the-threats-aws-threat-detection-and-remediation","text":"This workshop is designed to help you get familiar with AWS Security services and learn how to use them to identify and remediate threats in your environment. You'll be working with services such as Amazon GuardDuty, Amazon Macie, Amazon Inspector, Amazon CloudWatch, AWS Lambda, AWS Systems Manager, AWS Config, and AWS CloudTrail. You will learn how to use these services to investigate threats during and after an attack, set up a notification and remediation pipeline, and add additional protections to improve the security posture of your environment.","title":"Find All the Threats: AWS Threat Detection and Remediation"},{"location":"workshops/threat-detection-remediation/#scenario","text":"Your company is new to the cloud and has recently performed a lift-and-shift of your infrastructure for piloting purposes. You are a systems administrator and have been tasked with security monitoring within your AWS environment. As part of that maintenance you are also responsible for responding to any security event in your environment.","title":"Scenario"},{"location":"workshops/threat-detection-remediation/#architecture-overview","text":"For this Workshop you will have a single instance setup in the us-west-2 region. As this was a \u201clift-and-shift\u201d migration for piloting, you have yet to build redundancy into your application, so you have a single public-facing web server. The web server has access to the Internet Gateway through an Elastic Network Interface. Customers access your web server through a DNS entry pointing to the Elastic Network Interface. You store static content in an S3 bucket and use the VPC S3 Endpoint Gateway for access from the web server.","title":"Architecture overview"},{"location":"workshops/threat-detection-remediation/#presentation-deck","text":"Workshop Presentation Deck","title":"Presentation deck"},{"location":"workshops/threat-detection-remediation/#region","text":"Please use the us-west-2 (Oregon) region for this workshop.","title":"Region"},{"location":"workshops/threat-detection-remediation/#modules","text":"Environment Build and Configuration Attack Simulation Detection and Remediation Review and Discussion Total time: 2 hours","title":"Modules"},{"location":"workshops/threat-detection-remediation/01-environment-setup/","text":"Module 1: Environment build and configuration In the first module you will be configuring detective and responsive controls for your environment. You'll be running the first of two CloudFormation templates which will automate the creation of some of these controls and then you will manually configure the rest. Deploy the AWS CloudFormation template To initiate the scenario and configure your environment you will need to run the module 1 CloudFormation template: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. On the Specify Details section enter the necessary parameters as shown below. Parameter Value Stack name ThreatDetectionWksp-Env-Setup Email Address A valid email address Once you have entered your parameters click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status as shown below. You will get an email from SNS asking you to confirm the Subscription. Confirm the subscription so you can receive email alerts from AWS services during the Workshop. Setup Amazon CloudWatch event rules and automatic response The CloudFormation template you just ran created three CloudWatch Event Rules for alerting and response purposes. The steps below will walk you through creating the final rule. After this you'll have rules in place to receive email notifications and trigger AWS Lambda functions to respond to threats. Below are steps to create this rule through the console but you can also find out more about doing it programmatically by reviewing the Amazon GuardDuty Documentation . Open the CloudWatch console (us-west-2) In the navigation pane on the left, under Events , click Rules What are the current Rules in place setup to do? Click Create Rule Under Event Pattern click Build event pattern to match events by service and select Custom event pattern in the drop down. Copy and paste in the custom event pattern below: { source : [ aws.guardduty ], detail : { type : [ UnauthorizedAccess:EC2/MaliciousIPCaller.Custom ] } } For Targets , click Add Target , select Lambda Function , and then select threat-detection-wksp-remediation-nacl . Click Configure details . On the Configure rule details screen fill out the Name and Description (suggestions below). Name: threat-detection-wksp-guardduty-finding-ec2-maliciousip Description: GuardDuty Finding: UnauthorizedAccess:EC2/MaliciousIPCaller.Custom Click Create rule . Optional: Consider examining the Lambda function to see what it does. Open the Lambda console . Click on the function named threat-detection-wksp-remediation-nacl What will the function do when invoked? What will the threat-detection-wksp-remediation-inspector functions do? Enable Amazon GuardDuty The next step is to enable Amazon GuardDuty, which will continuously monitor your environment for malicious or unauthorized behavior. Go to the Amazon GuardDuty console (us-west-2). Click the Get Started button. On the next screen click the Enable GuardDuty button. GuardDuty is now enabled and continuously monitoring your CloudTrail logs, VPC flow logs, and DNS Query logs for threats in your environment. Enable Amazon Macie Since you plan on storing sensitive data in S3, let\u2019s quickly enable Amazon Macie. Macie is a security service that will continuously monitor data access activity for anomalies and generate alerts when it detects risk of unauthorized access or inadvertent data leaks. Go to the Amazon Macie console (us-west-2). Click Get Started . Macie will create a service-linked role when you enable it. If you would like to see the permissions that the role will have you can click the View service role permissions . Click Enable Macie . Setup Amazon Macie for data discovery classification Macie is also used for automatically discovering and classifying sensitive data. Now that Macie is enabled, setup an integration to classify data in your S3 bucket. In the Amazon Macie console click on Integrations on the left navigation. Find your AWS account ID (there should be only one) and click Select Click Add then on the next screen click the check box next to the S3 bucket that ends with \u201c-data\u201d . Click Add Leave the options here at the default, click Review . On the next screen click Start Classification . Finally click Done . Macie is now enabled and has begun to discover, classify and protect your data. Enable AWS Security Hub Now that all of your detective controls have been configured you need to enable AWS Security Hub , which will provide you with a comprehensive view of the security and compliance of your AWS environment. Go to the AWS Security Hub console. Click the Enable Security Hub button. On the next screen click the Enable AWS Security Hub button. AWS Security Hub is now enabled and will begin collecting and aggregating findings from the security services we have enabled so far. Architecture overview Your environment is now configured and ready for operations. Below is a diagram to depict the detective controls you now have in place. After you have successfully setup your environment, you can proceed to the next module.","title":"Module 1: Environment Build"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#module-1-environment-build-and-configuration","text":"In the first module you will be configuring detective and responsive controls for your environment. You'll be running the first of two CloudFormation templates which will automate the creation of some of these controls and then you will manually configure the rest.","title":"Module 1: Environment build and configuration"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#deploy-the-aws-cloudformation-template","text":"To initiate the scenario and configure your environment you will need to run the module 1 CloudFormation template: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. On the Specify Details section enter the necessary parameters as shown below. Parameter Value Stack name ThreatDetectionWksp-Env-Setup Email Address A valid email address Once you have entered your parameters click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status as shown below. You will get an email from SNS asking you to confirm the Subscription. Confirm the subscription so you can receive email alerts from AWS services during the Workshop.","title":"Deploy the AWS CloudFormation template"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#setup-amazon-cloudwatch-event-rules-and-automatic-response","text":"The CloudFormation template you just ran created three CloudWatch Event Rules for alerting and response purposes. The steps below will walk you through creating the final rule. After this you'll have rules in place to receive email notifications and trigger AWS Lambda functions to respond to threats. Below are steps to create this rule through the console but you can also find out more about doing it programmatically by reviewing the Amazon GuardDuty Documentation . Open the CloudWatch console (us-west-2) In the navigation pane on the left, under Events , click Rules What are the current Rules in place setup to do? Click Create Rule Under Event Pattern click Build event pattern to match events by service and select Custom event pattern in the drop down. Copy and paste in the custom event pattern below: { source : [ aws.guardduty ], detail : { type : [ UnauthorizedAccess:EC2/MaliciousIPCaller.Custom ] } } For Targets , click Add Target , select Lambda Function , and then select threat-detection-wksp-remediation-nacl . Click Configure details . On the Configure rule details screen fill out the Name and Description (suggestions below). Name: threat-detection-wksp-guardduty-finding-ec2-maliciousip Description: GuardDuty Finding: UnauthorizedAccess:EC2/MaliciousIPCaller.Custom Click Create rule . Optional: Consider examining the Lambda function to see what it does. Open the Lambda console . Click on the function named threat-detection-wksp-remediation-nacl What will the function do when invoked? What will the threat-detection-wksp-remediation-inspector functions do?","title":"Setup Amazon CloudWatch event rules and automatic response"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#enable-amazon-guardduty","text":"The next step is to enable Amazon GuardDuty, which will continuously monitor your environment for malicious or unauthorized behavior. Go to the Amazon GuardDuty console (us-west-2). Click the Get Started button. On the next screen click the Enable GuardDuty button. GuardDuty is now enabled and continuously monitoring your CloudTrail logs, VPC flow logs, and DNS Query logs for threats in your environment.","title":"Enable Amazon GuardDuty"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#enable-amazon-macie","text":"Since you plan on storing sensitive data in S3, let\u2019s quickly enable Amazon Macie. Macie is a security service that will continuously monitor data access activity for anomalies and generate alerts when it detects risk of unauthorized access or inadvertent data leaks. Go to the Amazon Macie console (us-west-2). Click Get Started . Macie will create a service-linked role when you enable it. If you would like to see the permissions that the role will have you can click the View service role permissions . Click Enable Macie .","title":"Enable Amazon Macie"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#setup-amazon-macie-for-data-discovery-classification","text":"Macie is also used for automatically discovering and classifying sensitive data. Now that Macie is enabled, setup an integration to classify data in your S3 bucket. In the Amazon Macie console click on Integrations on the left navigation. Find your AWS account ID (there should be only one) and click Select Click Add then on the next screen click the check box next to the S3 bucket that ends with \u201c-data\u201d . Click Add Leave the options here at the default, click Review . On the next screen click Start Classification . Finally click Done . Macie is now enabled and has begun to discover, classify and protect your data.","title":"Setup Amazon Macie for data discovery &amp; classification"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#enable-aws-security-hub","text":"Now that all of your detective controls have been configured you need to enable AWS Security Hub , which will provide you with a comprehensive view of the security and compliance of your AWS environment. Go to the AWS Security Hub console. Click the Enable Security Hub button. On the next screen click the Enable AWS Security Hub button. AWS Security Hub is now enabled and will begin collecting and aggregating findings from the security services we have enabled so far.","title":"Enable AWS Security Hub"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#architecture-overview","text":"Your environment is now configured and ready for operations. Below is a diagram to depict the detective controls you now have in place. After you have successfully setup your environment, you can proceed to the next module.","title":"Architecture overview"},{"location":"workshops/threat-detection-remediation/02-attack-simulation/","text":"Module 2: Attack Simulation Now that you have detective and responsive controls setup, you'll be running another CloudFormation template which will simulate the actual attack you will be investigating. Agenda Run the second CloudFormation template \u2013 5 min Threat detection and response presentation \u2013 25 min Deploy the CloudFormation template To initiate the attack simulation you will need to run the module 2 CloudFormation template: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. The name of the stack will be automatically populated but you are free to change it, after which click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and click Create This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status as shown below. Threat detection and response presentation Below is a diagram of the setup after the module 2 CloudFormation stack is created. If you are going through this workshop in a classroom setting then wait till the presentation is over before starting module 3 (the presentation will allow enough time to pass for the attack scenario to complete.) If you are going through this workshop outside of a classroom setting you can proceed to Module 3. Please note it will take at least 20 minutes after the 2nd CloudFormation template has completed before you will start seeing findings.","title":"Module 2: Attack Simulation"},{"location":"workshops/threat-detection-remediation/02-attack-simulation/#module-2-attack-simulation","text":"Now that you have detective and responsive controls setup, you'll be running another CloudFormation template which will simulate the actual attack you will be investigating. Agenda Run the second CloudFormation template \u2013 5 min Threat detection and response presentation \u2013 25 min","title":"Module 2: Attack Simulation"},{"location":"workshops/threat-detection-remediation/02-attack-simulation/#deploy-the-cloudformation-template","text":"To initiate the attack simulation you will need to run the module 2 CloudFormation template: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. The name of the stack will be automatically populated but you are free to change it, after which click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and click Create This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status as shown below.","title":"Deploy the CloudFormation template"},{"location":"workshops/threat-detection-remediation/02-attack-simulation/#threat-detection-and-response-presentation","text":"Below is a diagram of the setup after the module 2 CloudFormation stack is created. If you are going through this workshop in a classroom setting then wait till the presentation is over before starting module 3 (the presentation will allow enough time to pass for the attack scenario to complete.) If you are going through this workshop outside of a classroom setting you can proceed to Module 3. Please note it will take at least 20 minutes after the 2nd CloudFormation template has completed before you will start seeing findings.","title":"Threat detection and response presentation"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/","text":"Module 3: Detect, Investigate Respond Unfortunately, due to a misconfiguration in your environment, an attacker may have been able to gain access to the web server. You are getting alerts from the security services you\u2019ve put in place indicating malicious activity. These alerts include communication with known malicious IP addresses, account reconnaissance, changes to an Amazon S3 bucket configuration, and disabling security configurations. You must identify what activity the intruder may have performed and how they did it so you can block the intruder\u2019s access, remediate the vulnerabilities, and restore the configuration to its proper state. Part 1 - Compromised AWS IAM credentials Detect and investigate By now you\u2019ve received email alerts from the security services you enabled. Now what? As part of your risk driven detection strategy your organization has decided to prioritize AWS IAM related findings. Sort through your email alerts and identity an alert related to an AWS IAM principals (e.g. Amazon GuardDuty Finding: UnauthorizedAccess:IAMUser/MaliciousIPCaller.Custom ). Copy the Access Key ID from the e-mail alert. Explore findings related to the access key (Amazon GuardDuty) Now that you have a resource identifier to go off of you can use Amazon GuardDuty to start doing some investigation into the findings. Go to the Amazon GuardDuty console (us-west-2). Click in the Add filter criteria box: Select Access Key ID . and then paste in the Access Key ID you copied from the e-mail. What findings do you see related to this access key ID? Click on one of the findings to see the details. Where did these credentials come from? Examining User type under Resource affected you can see that the access key referenced in this finding is from an IAM assumed role. Examining Principal ID under Resource affected you will find two strings separated by a colon. The first is the unique ID for the IAM role and the second is the EC2 instance ID. The Principal ID contains a unique ID for the entity making the API request, and when the request is made using temporary security credentials (which is what happens for an assume role call) it also includes a session name. In this case the session name is the EC2 instance ID since the assume role call was done using an IAM role for EC2. Copy the full Principal Id which contains both the unique ID of the role and the session name: \"principalId\": \" unique ID : session name \" Examine the User name under Resource affected . This corresponds to the name of the IAM role involved since the temp creds used to make the API call came from EC2 instance with an IAM role attached. How could you have found the IAM role name just using the unique ID found earlier? Respond Now that you have identified that a temporary security credential from an IAM role for EC2 is being used by an attacker, the decision has been made to rotate the credential immediately to prevent any further misuse or potential escalation of privilege. Revoke the IAM role sessions (IAM) Browse to the AWS IAM console. Click Roles and find the role you identified in the previous section (this is the role attached to the compromised instance). Click on the Revoke sessions tab. Click on Revoke active sessions . Click the acknowledgement check box and then click Revoke active sessions . What is the mechanism that is put in place by this step to actually prevent the use of the temporary security credentials issued by this role? Restart the EC2 instance to rotate the access keys (EC2) All active credentials for the compromised IAM role have been invalidated. This means the attacker can no longer use those access keys, but it also means that any applications that use this role can't as well. You knew this going in but decided it was necessary due to the high risk of a compromised IAM access key. In order to ensure the availability of your application you need to refresh the access keys on the instance by stopping and starting the instance. A simple reboot will not change the keys. If you waited the temporary security credential on the instance would be refreshed but this procedure will speed things up. Since you are using AWS Systems Manager for doing administration on your EC2 Instances you can use it to query the metadata to validate that the access keys were rotated after the rotation. In the EC2 console Stop the Instance named threat-detection-wksp: Compromised Instance . Wait for the Instance State to say stopped under Instance State (you may need to refresh the EC2 console) and then Start the instance. Verify the access keys have been rotated (Systems Manager) Go to AWS Systems Manager console and click on Session Manager on the left navigation and then click Start Session . You should see an instance named threat-detection-wksp: Compromised Instance with a Instance state of running . To see the credentials currently active on the instance, click on the radio button next to threat-detection-wksp: Compromised Instance and click Start Session . Run the following command in the shell: curl http://169.254.169.254/latest/meta-data/iam/security-credentials/threat-detection-wksp-compromised-ec2 Compare the access key ID to the one found in the email alerts to ensure it has changed. Why would this scenario be a good use case for auto-scaling groups and golden-image AMI\u2019s? At this point you've successfully revoked all the active sessions from AWS IAM role and rotated the temporary security credentials on the EC2 instance. Part 2 - Compromised EC2 instance Detect and investigate Now that you've addressed the compromised IAM credential you need focus in on how the attacker was able to compromise the EC2 instance. It's this compromise which allowed them to query the instance metadata and steal the credentials. Explore findings related to the instance ID (AWS Security Hub) When investigating the compromised IAM credential you discovered that it was from an IAM role for EC2 and identified the EC2 instance ID from the principal ID of the finding. Using the instance ID you can use AWS Security Hub to start investigating the findings. To start, you are going to research the GuardDuty findings related to the EC2 instance. Go to the AWS Security Hub console. The link should take you to the Findings section but if not, click on Findings in the navigation on the left. Click in the Add filter box: Scroll down to Resource ID , change the operator to CONTAINS and paste in the Instance ID you copied earlier (from the principal ID you gathered in the GuardDuty finding). Add another filter by again clicking in the Add filter box and scrolling down to Product Name , and paste in the word GuardDuty . What findings do you see related to this instance ID? One of the findings should indicate that the EC2 instance is communicating with an IP address on a threat list ( disallowed IP ) which adds further evidence to the conclusion that the instance has been compromised. The other finding should indicate that a system at a particular IP address is performing an SSH brute force attack against your instance. You now need to investigate if the SSH brute force attack was successful and if that is what allowed the attacker to gain access to the instance. Determine if ssh password authentication is enabled on the EC2 instance (AWS Security Hub) Automated responses to threats can do many things. For example, you could have an trigger that helps gather information about the threat that could then be used in the investigation by the security team. With that option in mind, we have a CloudWatch event rule in place that will trigger an Amazon Inspector scan of an EC2 instance when GuardDuty detects a particular attack. We will use AWS Security Hub to view the findings from Inspector. We want to determine if the SSH configuration adheres to best practices. Go to the AWS Security Hub console. The link should take you to the Findings section but if not, click on Findings in the navigation on the left. Click in the Add filter box: Scroll down to Title , change the operator to CONTAINS and paste in password authentication over SSH . In the results do you see a finding regarding SSH and password authentication for the instance that experienced the SSH brute force attack? If you do not see any findings after awhile, there may have been an issue with your Inspector agent. Go to the Inspector console, click on Assessment Templates , check the template that starts with threat-detection-wksp , and click Run . Please allow 15 minutes for the scan to complete. You can also look in Assessment runs and check the status . Feel free to continue through this module and check the results later on. Based on the findings you should see that password authentication over SSH is configured on the instance. In addition if you examine some of the other Inspector findings you will see that there are no password complexity restrictions. This means the instance is more susceptible to an SSH brute force attack. Determine if the attacker was able to login to the EC2 instance (CloudWatch logs) Now that we know that the instance was more susceptible to an SSH brute force attack, let\u2019s look at the CloudWatch logs and create a metric to see if there were any successful SSH logins (to finally answer the question of whether the SSH brute force attack was successful.) Your corporate policy is to send security certain logs from EC2 instances to CloudWatch. Go to CloudWatch logs . Click on the log group /threat-detection-wksp/var/log/secure If you have multiple log streams, filter using the Instance ID you copied earlier and click on the stream. Within the Filter Events text-box put the following Filter Pattern: [Mon, day, timestamp, ip, id, msg1= Invalid, msg2 = user, ...] Do you see any failed (invalid user) attempts to log into the instance? Would that be consistent with an SSH brute force attack? Now replace the Filter with one for successful attempts: [Mon, day, timestamp, ip, id, msg1= Accepted, msg2 = password, ...] Do you see any successful attempts to log into the instance? Which linux user was compromised? Respond Modify the EC2 security group (EC2) The active session from the attacker was automatically stopped by an update to the NACL on the subnet where the instance resides. This was done by a CloudWatch event rule trigger that is invoked based on certain GuardDuty findings. A good next step would be to modify the security group associated with the EC2 instance to prevent the attacker or anyone else from connecting from a different source IP. Go to the Amazon EC2 Console. Find the running instances with the name threat-detection-wksp: Compromised Instance . Under the Description tab, click on the Security Group for the compromised instance. View the rules under the Inbound tab. Click Edit and delete the inbound SSH rule. You've decided that all administration on EC2 Instances will be done through AWS Systems Manager so you no longer need this port open. In your initial setup you already installed the SSM Agent on your EC2 Instance. Click Save Part 3 - Compromised S3 bucket Detect and investigate Now that we know the SSH brute force attack was successful and we disabled the IAM credentials that were stolen, we need to determine if anything else occurred. One step we could take here is to examine the IAM policy attached the IAM role that generated the temp credentials. We notice in the policy that there are permissions relating to the Amazon S3 service so that is something to keep in mind as you continue the investigation. Truncated policy from the IAM role attached to the compromised EC2 instance: { Version : 2012-10-17 , Statement : [ { Action : s3:PutObject , Resource : arn:aws:s3:::threat-detection-wksp-ACCOUNT_ID-us-west-2-gd-threatlist/* , Effect : Allow }, { Action : [ s3:* ], Resource : arn:aws:s3:::threat-detection-wksp-ACCOUNT_ID-us-west-2-data/* , Effect : Allow }, { Action : [ s3:* ], Resource : arn:aws:s3:::threat-detection-wksp-ACCOUNT_ID-us-west-2-data , Effect : Allow } ] } Investigate any S3 related findings (AWS Security Hub) There are many ways to approach this next step. We are going to start with a Security Hub insight that may be helpful in situations like this. This is not the only way you could approach this but it can definitely save time initially as you investigate the full repercussions of an attack. Go to AWS Security Hub in the AWS Management Console. The link should take you to the Insights section but if not, click on Insights in the navigation on the left. Click in the Filter insights box and type Top S3 which will display the built in Insight \"Top S3 buckets by counts of findings.\" Click on that Insight. Which buckets are displayed? There should be one that with threat-detection-wksp- and ends in -data . Click on that. What do the findings show? This Security Hub Insight is one way of determining what an attacker may have done. It is not going to help in every situation though. What additional steps would you take to investigate what an attacker had done? Check if sensitive data was involved (Macie) At this point you know how the attacker was able to get into your systems and a general idea of what they did. In the previous step you determined that the S3 bucket that starts with threat-detection-wksp- and ends in -data has an ACL that grants global read rights. We will now check if there is any sensitive and business-critical data in any of the buckets (but especially that data bucket) and take a closer at the Macie Alerts. Go to the Amazon Macie in the AWS Management console. Look through the latest alerts. Do you see any critical alerts? Does this match what you found in Security Hub? Next lets verify what sort of sensitive data exists in that bucket. Click Dashboard on the left navigation. You should see the following data classifications: You can slide the risk slider to filter data classifications based on risk levels. Above the risk slider, click the icon for S3 public objects and buckets . The icon will be in the shape of a globe but you can also hover over the icons to find the right one. Click the magnifying glass to the left of the bucket name listed. Check if any of the data in the bucket is considered a high risk Look for the Object PII priority field and Object risk level field Verify if any of the data is unencrypted Look for the Object encryption field. (Does a portion of the blue bar indicate that encryption is set to none?) Respond Fix the permissions and encryption on the bucket (S3) In the previous step we determined that the S3 bucket that starts with threat-detection-wksp- and ends in -data has sensitive data and some of that data is unencrypted. We also know that the bucket grants global read rights. We need to manually fix these issues. Go to Amazon S3 in the AWS Management Console. First we will fix the permissions: Find the bucket that starts with threat-detection-wksp- and ends in -data Click on the Permissions tab then click on ACL Control List Under Public access click on the radio button next to Everyone . Uncheck List objects then click Save Now we need to fix the encryption: In the same bucket, click on the Properties tab then click on Default encryption Set the encryption to AWS-KMS. Select the aws/s3 key. Finally click Save . Do you know what impact you had on existing objects in the bucket by enabling Default encryption ? Congratulations! You have successfully remediated the incident and further hardened your environment. This is obviously a simulation and we can not cover every aspect of the response function in the short time allotted but hopefully this gave you an idea of the capabilities available on AWS to detect, investigate and respond to threats and attacks. Here is a diagram of the attack you just investigated. Numbers 1 2 show the SSH brute force attack and successful SSH login. Number 3 shows the S3 bucket changes the attacker made. Number 4 shows the API calls the attacker made with the IAM temporary credentials stolen from the compromised EC2 instance. If you are going through this workshop in a classroom setting then the instructor should start the module 4 presentation soon.","title":"Module 3: Detect & Respond"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#module-3-detect-investigate-respond","text":"Unfortunately, due to a misconfiguration in your environment, an attacker may have been able to gain access to the web server. You are getting alerts from the security services you\u2019ve put in place indicating malicious activity. These alerts include communication with known malicious IP addresses, account reconnaissance, changes to an Amazon S3 bucket configuration, and disabling security configurations. You must identify what activity the intruder may have performed and how they did it so you can block the intruder\u2019s access, remediate the vulnerabilities, and restore the configuration to its proper state.","title":"Module 3: Detect, Investigate &amp; Respond"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#part-1-compromised-aws-iam-credentials","text":"","title":"Part 1 - Compromised AWS IAM credentials"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#detect-and-investigate","text":"By now you\u2019ve received email alerts from the security services you enabled. Now what? As part of your risk driven detection strategy your organization has decided to prioritize AWS IAM related findings. Sort through your email alerts and identity an alert related to an AWS IAM principals (e.g. Amazon GuardDuty Finding: UnauthorizedAccess:IAMUser/MaliciousIPCaller.Custom ). Copy the Access Key ID from the e-mail alert. Explore findings related to the access key (Amazon GuardDuty) Now that you have a resource identifier to go off of you can use Amazon GuardDuty to start doing some investigation into the findings. Go to the Amazon GuardDuty console (us-west-2). Click in the Add filter criteria box: Select Access Key ID . and then paste in the Access Key ID you copied from the e-mail. What findings do you see related to this access key ID? Click on one of the findings to see the details. Where did these credentials come from? Examining User type under Resource affected you can see that the access key referenced in this finding is from an IAM assumed role. Examining Principal ID under Resource affected you will find two strings separated by a colon. The first is the unique ID for the IAM role and the second is the EC2 instance ID. The Principal ID contains a unique ID for the entity making the API request, and when the request is made using temporary security credentials (which is what happens for an assume role call) it also includes a session name. In this case the session name is the EC2 instance ID since the assume role call was done using an IAM role for EC2. Copy the full Principal Id which contains both the unique ID of the role and the session name: \"principalId\": \" unique ID : session name \" Examine the User name under Resource affected . This corresponds to the name of the IAM role involved since the temp creds used to make the API call came from EC2 instance with an IAM role attached. How could you have found the IAM role name just using the unique ID found earlier?","title":"Detect and investigate"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#respond","text":"Now that you have identified that a temporary security credential from an IAM role for EC2 is being used by an attacker, the decision has been made to rotate the credential immediately to prevent any further misuse or potential escalation of privilege. Revoke the IAM role sessions (IAM) Browse to the AWS IAM console. Click Roles and find the role you identified in the previous section (this is the role attached to the compromised instance). Click on the Revoke sessions tab. Click on Revoke active sessions . Click the acknowledgement check box and then click Revoke active sessions . What is the mechanism that is put in place by this step to actually prevent the use of the temporary security credentials issued by this role? Restart the EC2 instance to rotate the access keys (EC2) All active credentials for the compromised IAM role have been invalidated. This means the attacker can no longer use those access keys, but it also means that any applications that use this role can't as well. You knew this going in but decided it was necessary due to the high risk of a compromised IAM access key. In order to ensure the availability of your application you need to refresh the access keys on the instance by stopping and starting the instance. A simple reboot will not change the keys. If you waited the temporary security credential on the instance would be refreshed but this procedure will speed things up. Since you are using AWS Systems Manager for doing administration on your EC2 Instances you can use it to query the metadata to validate that the access keys were rotated after the rotation. In the EC2 console Stop the Instance named threat-detection-wksp: Compromised Instance . Wait for the Instance State to say stopped under Instance State (you may need to refresh the EC2 console) and then Start the instance. Verify the access keys have been rotated (Systems Manager) Go to AWS Systems Manager console and click on Session Manager on the left navigation and then click Start Session . You should see an instance named threat-detection-wksp: Compromised Instance with a Instance state of running . To see the credentials currently active on the instance, click on the radio button next to threat-detection-wksp: Compromised Instance and click Start Session . Run the following command in the shell: curl http://169.254.169.254/latest/meta-data/iam/security-credentials/threat-detection-wksp-compromised-ec2 Compare the access key ID to the one found in the email alerts to ensure it has changed. Why would this scenario be a good use case for auto-scaling groups and golden-image AMI\u2019s? At this point you've successfully revoked all the active sessions from AWS IAM role and rotated the temporary security credentials on the EC2 instance.","title":"Respond"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#part-2-compromised-ec2-instance","text":"","title":"Part 2 - Compromised EC2 instance"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#detect-and-investigate_1","text":"Now that you've addressed the compromised IAM credential you need focus in on how the attacker was able to compromise the EC2 instance. It's this compromise which allowed them to query the instance metadata and steal the credentials. Explore findings related to the instance ID (AWS Security Hub) When investigating the compromised IAM credential you discovered that it was from an IAM role for EC2 and identified the EC2 instance ID from the principal ID of the finding. Using the instance ID you can use AWS Security Hub to start investigating the findings. To start, you are going to research the GuardDuty findings related to the EC2 instance. Go to the AWS Security Hub console. The link should take you to the Findings section but if not, click on Findings in the navigation on the left. Click in the Add filter box: Scroll down to Resource ID , change the operator to CONTAINS and paste in the Instance ID you copied earlier (from the principal ID you gathered in the GuardDuty finding). Add another filter by again clicking in the Add filter box and scrolling down to Product Name , and paste in the word GuardDuty . What findings do you see related to this instance ID? One of the findings should indicate that the EC2 instance is communicating with an IP address on a threat list ( disallowed IP ) which adds further evidence to the conclusion that the instance has been compromised. The other finding should indicate that a system at a particular IP address is performing an SSH brute force attack against your instance. You now need to investigate if the SSH brute force attack was successful and if that is what allowed the attacker to gain access to the instance. Determine if ssh password authentication is enabled on the EC2 instance (AWS Security Hub) Automated responses to threats can do many things. For example, you could have an trigger that helps gather information about the threat that could then be used in the investigation by the security team. With that option in mind, we have a CloudWatch event rule in place that will trigger an Amazon Inspector scan of an EC2 instance when GuardDuty detects a particular attack. We will use AWS Security Hub to view the findings from Inspector. We want to determine if the SSH configuration adheres to best practices. Go to the AWS Security Hub console. The link should take you to the Findings section but if not, click on Findings in the navigation on the left. Click in the Add filter box: Scroll down to Title , change the operator to CONTAINS and paste in password authentication over SSH . In the results do you see a finding regarding SSH and password authentication for the instance that experienced the SSH brute force attack? If you do not see any findings after awhile, there may have been an issue with your Inspector agent. Go to the Inspector console, click on Assessment Templates , check the template that starts with threat-detection-wksp , and click Run . Please allow 15 minutes for the scan to complete. You can also look in Assessment runs and check the status . Feel free to continue through this module and check the results later on. Based on the findings you should see that password authentication over SSH is configured on the instance. In addition if you examine some of the other Inspector findings you will see that there are no password complexity restrictions. This means the instance is more susceptible to an SSH brute force attack. Determine if the attacker was able to login to the EC2 instance (CloudWatch logs) Now that we know that the instance was more susceptible to an SSH brute force attack, let\u2019s look at the CloudWatch logs and create a metric to see if there were any successful SSH logins (to finally answer the question of whether the SSH brute force attack was successful.) Your corporate policy is to send security certain logs from EC2 instances to CloudWatch. Go to CloudWatch logs . Click on the log group /threat-detection-wksp/var/log/secure If you have multiple log streams, filter using the Instance ID you copied earlier and click on the stream. Within the Filter Events text-box put the following Filter Pattern: [Mon, day, timestamp, ip, id, msg1= Invalid, msg2 = user, ...] Do you see any failed (invalid user) attempts to log into the instance? Would that be consistent with an SSH brute force attack? Now replace the Filter with one for successful attempts: [Mon, day, timestamp, ip, id, msg1= Accepted, msg2 = password, ...] Do you see any successful attempts to log into the instance? Which linux user was compromised?","title":"Detect and investigate"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#respond_1","text":"Modify the EC2 security group (EC2) The active session from the attacker was automatically stopped by an update to the NACL on the subnet where the instance resides. This was done by a CloudWatch event rule trigger that is invoked based on certain GuardDuty findings. A good next step would be to modify the security group associated with the EC2 instance to prevent the attacker or anyone else from connecting from a different source IP. Go to the Amazon EC2 Console. Find the running instances with the name threat-detection-wksp: Compromised Instance . Under the Description tab, click on the Security Group for the compromised instance. View the rules under the Inbound tab. Click Edit and delete the inbound SSH rule. You've decided that all administration on EC2 Instances will be done through AWS Systems Manager so you no longer need this port open. In your initial setup you already installed the SSM Agent on your EC2 Instance. Click Save","title":"Respond"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#part-3-compromised-s3-bucket","text":"","title":"Part 3 - Compromised S3 bucket"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#detect-and-investigate_2","text":"Now that we know the SSH brute force attack was successful and we disabled the IAM credentials that were stolen, we need to determine if anything else occurred. One step we could take here is to examine the IAM policy attached the IAM role that generated the temp credentials. We notice in the policy that there are permissions relating to the Amazon S3 service so that is something to keep in mind as you continue the investigation. Truncated policy from the IAM role attached to the compromised EC2 instance: { Version : 2012-10-17 , Statement : [ { Action : s3:PutObject , Resource : arn:aws:s3:::threat-detection-wksp-ACCOUNT_ID-us-west-2-gd-threatlist/* , Effect : Allow }, { Action : [ s3:* ], Resource : arn:aws:s3:::threat-detection-wksp-ACCOUNT_ID-us-west-2-data/* , Effect : Allow }, { Action : [ s3:* ], Resource : arn:aws:s3:::threat-detection-wksp-ACCOUNT_ID-us-west-2-data , Effect : Allow } ] } Investigate any S3 related findings (AWS Security Hub) There are many ways to approach this next step. We are going to start with a Security Hub insight that may be helpful in situations like this. This is not the only way you could approach this but it can definitely save time initially as you investigate the full repercussions of an attack. Go to AWS Security Hub in the AWS Management Console. The link should take you to the Insights section but if not, click on Insights in the navigation on the left. Click in the Filter insights box and type Top S3 which will display the built in Insight \"Top S3 buckets by counts of findings.\" Click on that Insight. Which buckets are displayed? There should be one that with threat-detection-wksp- and ends in -data . Click on that. What do the findings show? This Security Hub Insight is one way of determining what an attacker may have done. It is not going to help in every situation though. What additional steps would you take to investigate what an attacker had done? Check if sensitive data was involved (Macie) At this point you know how the attacker was able to get into your systems and a general idea of what they did. In the previous step you determined that the S3 bucket that starts with threat-detection-wksp- and ends in -data has an ACL that grants global read rights. We will now check if there is any sensitive and business-critical data in any of the buckets (but especially that data bucket) and take a closer at the Macie Alerts. Go to the Amazon Macie in the AWS Management console. Look through the latest alerts. Do you see any critical alerts? Does this match what you found in Security Hub? Next lets verify what sort of sensitive data exists in that bucket. Click Dashboard on the left navigation. You should see the following data classifications: You can slide the risk slider to filter data classifications based on risk levels. Above the risk slider, click the icon for S3 public objects and buckets . The icon will be in the shape of a globe but you can also hover over the icons to find the right one. Click the magnifying glass to the left of the bucket name listed. Check if any of the data in the bucket is considered a high risk Look for the Object PII priority field and Object risk level field Verify if any of the data is unencrypted Look for the Object encryption field. (Does a portion of the blue bar indicate that encryption is set to none?)","title":"Detect and investigate"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#respond_2","text":"Fix the permissions and encryption on the bucket (S3) In the previous step we determined that the S3 bucket that starts with threat-detection-wksp- and ends in -data has sensitive data and some of that data is unencrypted. We also know that the bucket grants global read rights. We need to manually fix these issues. Go to Amazon S3 in the AWS Management Console. First we will fix the permissions: Find the bucket that starts with threat-detection-wksp- and ends in -data Click on the Permissions tab then click on ACL Control List Under Public access click on the radio button next to Everyone . Uncheck List objects then click Save Now we need to fix the encryption: In the same bucket, click on the Properties tab then click on Default encryption Set the encryption to AWS-KMS. Select the aws/s3 key. Finally click Save . Do you know what impact you had on existing objects in the bucket by enabling Default encryption ? Congratulations! You have successfully remediated the incident and further hardened your environment. This is obviously a simulation and we can not cover every aspect of the response function in the short time allotted but hopefully this gave you an idea of the capabilities available on AWS to detect, investigate and respond to threats and attacks. Here is a diagram of the attack you just investigated. Numbers 1 2 show the SSH brute force attack and successful SSH login. Number 3 shows the S3 bucket changes the attacker made. Number 4 shows the API calls the attacker made with the IAM temporary credentials stolen from the compromised EC2 instance. If you are going through this workshop in a classroom setting then the instructor should start the module 4 presentation soon.","title":"Respond"},{"location":"workshops/threat-detection-remediation/04-review-and-discussion/","text":"Module 4: Review and Discussion In the last module we will have a short discussion of the workshop (and discuss exactly what occurred.) We will also go over a number of questions and then provide instructions on how to clean up the workshop environment (to prevent future charges in your AWS account.) Agenda Review Discussion \u2013 10 min Questions \u2013 10 min Cleanup \u2013 5 min Architecture Overview Diagram of the overall workshop setup: What is Really Going On? In Module 1 of the workshop you setup the initial components of your infrastructure including GuardDuty, Macie and a simple notification and remediation pipeline. Some of the steps required manual configuration but you also ran a CloudFormation template which setup some of the components. In Module 2 you launched a second CloudFormation template that initiated the attack simulated by this workshop. The CloudFormation template created two EC2 instances. One instance (named Malicious Host ) had an EIP attached to it that was added to your GuardDuty custom threat list. Although the Malicious Host is in the same VPC as the other instance, for the sake of the scenario (and to prevent the need to submit a penetration testing request) we acted as if it is on the Internet and represented the attack's computer. The other instance (named Compromised Instance ) was your web server and it was taken over by the Malicious Host . In Module 3 you investigated the attack, remediated the damage, and setup some automated remediations for future attacks. Here is what occurred in the attack: There are two instances created by the Module 2 CloudFormation template. They are in the same VPC but different subnets. The Malicious Host represents the attacker which we pretend is on the Internet. The Elastic IP on the Malicious Host is in a custom threat list in GuardDuty. The other instance named Compromised Instance represents the web server that was lifted and shifted into AWS. Although company policy is that only key-based authentication should be enabled for SSH, at some point password authentication for SSH was enabled on the Compromised Instance . This misconfiguration is identified in the Inspector scan that is triggered from the GuardDuty finding. The Malicious Host performed a brute force SSH password attack against the Compromised Instance . The brute force attack is designed to be successful. GuardDuty Finding : UnauthorizedAccess:EC2/SSHBruteForce The SSH brute force attack was successful and the attacker was able to log in to the Compromised Instance . Successful login is confirmed in CloudWatch Logs (/threat-detection-wksp/var/log/secure). The EC2 Instance that is created in the Module 2 CloudFormation template disabled default encryption on the Data bucket. In addition the CloudFormation template made the Data bucket public. This is used for the Macie part of the investigation in Module 3. We pretend that the attacker made the bucket public and removed the default encryption from the bucket. Macie Alert : S3 Bucket IAM policy grants global read rights The Compromised Instance also has a cron job that continuously pings the Malicious Host to generate a GuardDuty finding based off the custom threat list. GuardDuty Finding : UnauthorizedAccess:EC2/MaliciousIPCaller.Custom The API Calls that generated the API findings come from the Malicious Host . The calls use the temp creds from the IAM role for EC2 running on the Malicious Host . The GuardDuty findings are generated because the EIP attached to the Malicious Host is in a custom threat list. GuardDuty Finding : Recon:IAMUser/MaliciousIPCaller.Custom GuardDuty Finding : UnauthorizedAccess:IAMUser/MaliciousIPCaller.Custom A number of CloudWatch Events Rules are evoked by the GuardDuty findings and then these trigger various services. CloudWatch Event Rule : The generic GuardDuty finding invokes a CloudWatch Event rule which triggers SNS to send an email. CloudWatch Event Rule : The generic Macie alert invokes a CloudWatch Event rule which triggers SNS to send an email. CloudWatch Event Rule : The SSH brute force attack finding invokes a CloudWatch Event rule which triggers a Lambda function to block the attacker IP address of the attacker via a NACL as well as a Lambda function that runs an Inspector scan on the EC2 instance. CloudWatch Event Rule : The Unauthorized Access Custom MaliciousIP finding invokes a CloudWatch Event rule which triggers a Lambda function to block the IP address of the attacker via a NACL. Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forgot about it, and then accrue charges. You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete the Inspector objects created for the workshop. Go to the Amazon Inspector console. Click on Assessment targets in the navigation pane on the left. Delete all that start with threat-detection-wksp . Delete the IAM Role for the compromised EC2 instance and the Service-Linked Role for Inspector (if you didn't already have this Role created). Go to AWS IAM console. Click on Roles Search for the role named threat-detection-wksp-compromised-ec2 . Click the check box next to it and click Delete . Repeat the steps above for the role named AWSServiceRoleForAmazonInspector . Delete all three S3 buckets created by the Module 1 CloudFormation template (the buckets that start with threat-detection-wksp and end with -data , -threatlist and -logs ) Go to Amazon S3 console. Click on the appropiate bucket. Click Delete Bucket . Copy and paste the name of the bucket (this is an extra verification that you actually want to delete the bucket). Repeat the steps above for all three buckets. Delete Module 1 and 2 CloudFormation stacks ( ThreatDetectionWksp-Env-Setup and ThreatDetectionWksp-Attacks ). Go to the AWS CloudFormation console. Select the appropiate stack. Select Action . Click Delete Stack . Repeat the steps above for each stack. You do not need to wait for the first stack to delete before you delete the second one. Delete the GuardDuty custom threat list and disable GuardDuty (if you didn't already have it configured before the workshop) Go to the Amazon GuardDuty console. Click on Lists on the left navigation. Click the X next to the threat list that starts with Custom-Threat-List . Click Settings in the navigation pane on the left navigation. Click the check box next to Disable . Click Save settings and then click Disable in the pop-up box. Disable AWS Security Hub Go to the AWS Security Hub console. Click on Settings on the left navigation. Click the General on the top navigation. Click Disable AWS Security Hub . Delete the manual CloudWatch Event Rule you created and the CloudWatch Logs that were generated. Go to the AWS CloudWatch console. Click on Rules in the navigation pane on the left. Click the radio button next threat-detection-wksp-guardduty-finding-maliciousip . Select Action and click Delete . Click on Logs in the navigation pane on the left. Click the radio button next to /aws/lambda/threat-detection-wksp-inspector-role-creation . Select Action and click Delete log group and then click Yes, Delete in the pop-up box. Repeat for: /aws/lambda/threat-detection-wksp-remediation-inspector /aws/lambda/threat-detection-wksp-remediation-nacl /threat-detection-wksp/var/log/secure Delete the SNS subscription that was created when you subscribed to SNS Topic. Go to the AWS SNS console. Click on Subscriptions on the left navigation. Select the check box next to the subscription that shows your e-mail as the Endpoint and has threat-detection-wksp in the Subscription ARN . Select Action and then click Delete subscriptions Disable Macie (if you didn't already have Macie enabled before the workshop). Go the Amazon Macie console. In the upper right-hand corner select the down arrow to the left of the Region and select Macie General Settings . Check the two boxes and click Disable Amazon Macie Disabling Macie will actually log you out of the AWS Console so you will need to log back to do any other tasks. Finished! Congratulations on completing this workshop! This is the workshop's permanent home, so feel free to revisit as often as you'd like.","title":"Module 4: Discussion"},{"location":"workshops/threat-detection-remediation/04-review-and-discussion/#module-4-review-and-discussion","text":"In the last module we will have a short discussion of the workshop (and discuss exactly what occurred.) We will also go over a number of questions and then provide instructions on how to clean up the workshop environment (to prevent future charges in your AWS account.) Agenda Review Discussion \u2013 10 min Questions \u2013 10 min Cleanup \u2013 5 min","title":"Module 4: Review and Discussion"},{"location":"workshops/threat-detection-remediation/04-review-and-discussion/#architecture-overview","text":"Diagram of the overall workshop setup:","title":"Architecture Overview"},{"location":"workshops/threat-detection-remediation/04-review-and-discussion/#what-is-really-going-on","text":"In Module 1 of the workshop you setup the initial components of your infrastructure including GuardDuty, Macie and a simple notification and remediation pipeline. Some of the steps required manual configuration but you also ran a CloudFormation template which setup some of the components. In Module 2 you launched a second CloudFormation template that initiated the attack simulated by this workshop. The CloudFormation template created two EC2 instances. One instance (named Malicious Host ) had an EIP attached to it that was added to your GuardDuty custom threat list. Although the Malicious Host is in the same VPC as the other instance, for the sake of the scenario (and to prevent the need to submit a penetration testing request) we acted as if it is on the Internet and represented the attack's computer. The other instance (named Compromised Instance ) was your web server and it was taken over by the Malicious Host . In Module 3 you investigated the attack, remediated the damage, and setup some automated remediations for future attacks. Here is what occurred in the attack: There are two instances created by the Module 2 CloudFormation template. They are in the same VPC but different subnets. The Malicious Host represents the attacker which we pretend is on the Internet. The Elastic IP on the Malicious Host is in a custom threat list in GuardDuty. The other instance named Compromised Instance represents the web server that was lifted and shifted into AWS. Although company policy is that only key-based authentication should be enabled for SSH, at some point password authentication for SSH was enabled on the Compromised Instance . This misconfiguration is identified in the Inspector scan that is triggered from the GuardDuty finding. The Malicious Host performed a brute force SSH password attack against the Compromised Instance . The brute force attack is designed to be successful. GuardDuty Finding : UnauthorizedAccess:EC2/SSHBruteForce The SSH brute force attack was successful and the attacker was able to log in to the Compromised Instance . Successful login is confirmed in CloudWatch Logs (/threat-detection-wksp/var/log/secure). The EC2 Instance that is created in the Module 2 CloudFormation template disabled default encryption on the Data bucket. In addition the CloudFormation template made the Data bucket public. This is used for the Macie part of the investigation in Module 3. We pretend that the attacker made the bucket public and removed the default encryption from the bucket. Macie Alert : S3 Bucket IAM policy grants global read rights The Compromised Instance also has a cron job that continuously pings the Malicious Host to generate a GuardDuty finding based off the custom threat list. GuardDuty Finding : UnauthorizedAccess:EC2/MaliciousIPCaller.Custom The API Calls that generated the API findings come from the Malicious Host . The calls use the temp creds from the IAM role for EC2 running on the Malicious Host . The GuardDuty findings are generated because the EIP attached to the Malicious Host is in a custom threat list. GuardDuty Finding : Recon:IAMUser/MaliciousIPCaller.Custom GuardDuty Finding : UnauthorizedAccess:IAMUser/MaliciousIPCaller.Custom A number of CloudWatch Events Rules are evoked by the GuardDuty findings and then these trigger various services. CloudWatch Event Rule : The generic GuardDuty finding invokes a CloudWatch Event rule which triggers SNS to send an email. CloudWatch Event Rule : The generic Macie alert invokes a CloudWatch Event rule which triggers SNS to send an email. CloudWatch Event Rule : The SSH brute force attack finding invokes a CloudWatch Event rule which triggers a Lambda function to block the attacker IP address of the attacker via a NACL as well as a Lambda function that runs an Inspector scan on the EC2 instance. CloudWatch Event Rule : The Unauthorized Access Custom MaliciousIP finding invokes a CloudWatch Event rule which triggers a Lambda function to block the IP address of the attacker via a NACL.","title":"What is Really Going On?"},{"location":"workshops/threat-detection-remediation/04-review-and-discussion/#cleanup","text":"In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forgot about it, and then accrue charges. You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete the Inspector objects created for the workshop. Go to the Amazon Inspector console. Click on Assessment targets in the navigation pane on the left. Delete all that start with threat-detection-wksp . Delete the IAM Role for the compromised EC2 instance and the Service-Linked Role for Inspector (if you didn't already have this Role created). Go to AWS IAM console. Click on Roles Search for the role named threat-detection-wksp-compromised-ec2 . Click the check box next to it and click Delete . Repeat the steps above for the role named AWSServiceRoleForAmazonInspector . Delete all three S3 buckets created by the Module 1 CloudFormation template (the buckets that start with threat-detection-wksp and end with -data , -threatlist and -logs ) Go to Amazon S3 console. Click on the appropiate bucket. Click Delete Bucket . Copy and paste the name of the bucket (this is an extra verification that you actually want to delete the bucket). Repeat the steps above for all three buckets. Delete Module 1 and 2 CloudFormation stacks ( ThreatDetectionWksp-Env-Setup and ThreatDetectionWksp-Attacks ). Go to the AWS CloudFormation console. Select the appropiate stack. Select Action . Click Delete Stack . Repeat the steps above for each stack. You do not need to wait for the first stack to delete before you delete the second one. Delete the GuardDuty custom threat list and disable GuardDuty (if you didn't already have it configured before the workshop) Go to the Amazon GuardDuty console. Click on Lists on the left navigation. Click the X next to the threat list that starts with Custom-Threat-List . Click Settings in the navigation pane on the left navigation. Click the check box next to Disable . Click Save settings and then click Disable in the pop-up box. Disable AWS Security Hub Go to the AWS Security Hub console. Click on Settings on the left navigation. Click the General on the top navigation. Click Disable AWS Security Hub . Delete the manual CloudWatch Event Rule you created and the CloudWatch Logs that were generated. Go to the AWS CloudWatch console. Click on Rules in the navigation pane on the left. Click the radio button next threat-detection-wksp-guardduty-finding-maliciousip . Select Action and click Delete . Click on Logs in the navigation pane on the left. Click the radio button next to /aws/lambda/threat-detection-wksp-inspector-role-creation . Select Action and click Delete log group and then click Yes, Delete in the pop-up box. Repeat for: /aws/lambda/threat-detection-wksp-remediation-inspector /aws/lambda/threat-detection-wksp-remediation-nacl /threat-detection-wksp/var/log/secure Delete the SNS subscription that was created when you subscribed to SNS Topic. Go to the AWS SNS console. Click on Subscriptions on the left navigation. Select the check box next to the subscription that shows your e-mail as the Endpoint and has threat-detection-wksp in the Subscription ARN . Select Action and then click Delete subscriptions Disable Macie (if you didn't already have Macie enabled before the workshop). Go the Amazon Macie console. In the upper right-hand corner select the down arrow to the left of the Region and select Macie General Settings . Check the two boxes and click Disable Amazon Macie Disabling Macie will actually log you out of the AWS Console so you will need to log back to do any other tasks.","title":"Cleanup"},{"location":"workshops/threat-detection-remediation/04-review-and-discussion/#finished","text":"Congratulations on completing this workshop! This is the workshop's permanent home, so feel free to revisit as often as you'd like.","title":"Finished!"}]}