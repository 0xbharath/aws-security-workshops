{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AWS Security Workshops Welcome to the AWS security workshops portal! Here you will find a collection of workshops aimed at helping you gain an understanding of the service ecosystem and introduce you to a variety of best practices that can be applied to securing your environments and workloads running in AWS. Security and Compliance is a shared responsibility between AWS and the customer. AWS customers benefit from a data center and network architecture built to satisfy the requirements of the most security-sensitive organizations. AWS is responsible for protecting the infrastructure which runs all of the services offered and this responsibility is known as the Security of the Cloud . Customers responsibility, known as the Security in the Cloud , is determined by which services the customer chooses to use. The workshops contained in this portal are focused on the Security in the Cloud and they will guide you through prepared scenarios that represent common use cases and operational tasks you'll face in building on AWS. They will also highlight the design principals from the AWS Well-Architected Framework Security Pillar , which can help you improve your security posture. Implement a strong identity foundation Enable traceability Apply security at all layers Automate security best practices Protect data in transit and at rest Keep people away from data Prepare for security events","title":"Home"},{"location":"#aws-security-workshops","text":"Welcome to the AWS security workshops portal! Here you will find a collection of workshops aimed at helping you gain an understanding of the service ecosystem and introduce you to a variety of best practices that can be applied to securing your environments and workloads running in AWS. Security and Compliance is a shared responsibility between AWS and the customer. AWS customers benefit from a data center and network architecture built to satisfy the requirements of the most security-sensitive organizations. AWS is responsible for protecting the infrastructure which runs all of the services offered and this responsibility is known as the Security of the Cloud . Customers responsibility, known as the Security in the Cloud , is determined by which services the customer chooses to use. The workshops contained in this portal are focused on the Security in the Cloud and they will guide you through prepared scenarios that represent common use cases and operational tasks you'll face in building on AWS. They will also highlight the design principals from the AWS Well-Architected Framework Security Pillar , which can help you improve your security posture. Implement a strong identity foundation Enable traceability Apply security at all layers Automate security best practices Protect data in transit and at rest Keep people away from data Prepare for security events","title":"AWS Security Workshops"},{"location":"contribute/","text":"Contributing Guidelines Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution. Reporting Bugs/Feature Requests We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment Contributing via Pull Requests Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request . Finding contributions to work on Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start. Code of Conduct This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments. Security issue notifications If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue. Licensing See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Contributing"},{"location":"contribute/#contributing-guidelines","text":"Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution.","title":"Contributing Guidelines"},{"location":"contribute/#reporting-bugsfeature-requests","text":"We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment","title":"Reporting Bugs/Feature Requests"},{"location":"contribute/#contributing-via-pull-requests","text":"Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request .","title":"Contributing via Pull Requests"},{"location":"contribute/#finding-contributions-to-work-on","text":"Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.","title":"Finding contributions to work on"},{"location":"contribute/#code-of-conduct","text":"This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.","title":"Code of Conduct"},{"location":"contribute/#security-issue-notifications","text":"If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue.","title":"Security issue notifications"},{"location":"contribute/#licensing","text":"See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Licensing"},{"location":"getting-started/","text":"Getting Started Create an AWS account In order to complete these workshops, you'll need a valid, usable AWS Account . Use a personal account or create a new AWS account to ensure you have the necessary access and that you do not accidentally modify corporate resources. Do not use an AWS account from the company you work for. Create an admin user If you don't already have an AWS IAM user with admin permissions, please use the following instructions to create one: Browse to the AWS IAM console. Click Users on the left navigation and then click Add User . Enter a User Name , check the checkbox for AWS Management Console access , enter a Custom Password , and click Next:Permissions . Click Attach existing policies directly , click the checkbox next to the AdministratorAccess , and click Next:review . Click Create User Click Dashboard on the left navigation and use the IAM users sign-in link to login as the admin user you just created. Add credits (optional) If you are doing this workshop as part of an AWS sponsored event, you will receive credits to cover the costs. Below are the instructions for entering the credits: Browse to the AWS Account Settings console. Enter the Promo Code you received (these will be handed out at the beginning of the workshop). Enter the Security Check and click Redeem . Create a Cloud9 instance (optional) If the workshop you are doing requires you to run commands or scripts you will need to launch a an AWS Cloud9 instance which will provide you with a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. The workshop instructions will specify if this needed. Below are the instructions for launching an instance: Browse to the AWS Cloud9 console. Click Create environment on the right side. Enter a Name (security-workshop-ide) and click Next step . Leave all the defaults and click Next step . Click Create environment . The environment will open automatically after it has been provisioned. Browse back to the AWS Cloud9 console and you can click Open IDE on the environment you created to access it at anytime. You are now setup for the workshops!","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/#create-an-aws-account","text":"In order to complete these workshops, you'll need a valid, usable AWS Account . Use a personal account or create a new AWS account to ensure you have the necessary access and that you do not accidentally modify corporate resources. Do not use an AWS account from the company you work for.","title":"Create an AWS account"},{"location":"getting-started/#create-an-admin-user","text":"If you don't already have an AWS IAM user with admin permissions, please use the following instructions to create one: Browse to the AWS IAM console. Click Users on the left navigation and then click Add User . Enter a User Name , check the checkbox for AWS Management Console access , enter a Custom Password , and click Next:Permissions . Click Attach existing policies directly , click the checkbox next to the AdministratorAccess , and click Next:review . Click Create User Click Dashboard on the left navigation and use the IAM users sign-in link to login as the admin user you just created.","title":"Create an admin user"},{"location":"getting-started/#add-credits-optional","text":"If you are doing this workshop as part of an AWS sponsored event, you will receive credits to cover the costs. Below are the instructions for entering the credits: Browse to the AWS Account Settings console. Enter the Promo Code you received (these will be handed out at the beginning of the workshop). Enter the Security Check and click Redeem .","title":"Add credits (optional)"},{"location":"getting-started/#create-a-cloud9-instance-optional","text":"If the workshop you are doing requires you to run commands or scripts you will need to launch a an AWS Cloud9 instance which will provide you with a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. The workshop instructions will specify if this needed. Below are the instructions for launching an instance: Browse to the AWS Cloud9 console. Click Create environment on the right side. Enter a Name (security-workshop-ide) and click Next step . Leave all the defaults and click Next step . Click Create environment . The environment will open automatically after it has been provisioned. Browse back to the AWS Cloud9 console and you can click Open IDE on the environment you created to access it at anytime. You are now setup for the workshops!","title":"Create a Cloud9 instance (optional)"},{"location":"license/","text":"License MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"builder-sessions/","text":"Builder Sessions Title Description Permission Boundaries: How to Truly Delegate Permissions on AWS Permission boundaries is probably one of the most important new IAM feature that has launched in awhile. This feature addresses a longstanding customer issue, namely, how do I delegate administration to my users. If you have developers that need to be able to create roles for Lambda functions, system administrators that need to be able to create IAM roles and users, or any similar scenario, then you need permission boundaries. Presentation deck","title":"Directory"},{"location":"builder-sessions/#builder-sessions","text":"Title Description Permission Boundaries: How to Truly Delegate Permissions on AWS Permission boundaries is probably one of the most important new IAM feature that has launched in awhile. This feature addresses a longstanding customer issue, namely, how do I delegate administration to my users. If you have developers that need to be able to create roles for Lambda functions, system administrators that need to be able to create IAM roles and users, or any similar scenario, then you need permission boundaries. Presentation deck","title":"Builder Sessions"},{"location":"builder-sessions/permission-boundary/build/","text":"Permission Boundaries: How to Truly Delegate Permissions on AWS (Build Phase) Permission boundaries is probably one of the most important new IAM features that has launched in a while. This feature addresses a longstanding customer issue, namely, how do I delegate administration to my users. If you have system administrators that need to be able to create IAM roles and users, developers that need to be able to create roles for Lambda functions, or any similar scenario, then you need permission boundaries. Presentation deck Environment Setup AWS Sponsored Event Browse to the URL provided to you and login. After you login click the AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for the Management console . Click on that and you will be taken to the AWS console. Individual Launch the CloudFormation stack below to setup the Permission Boundary environment: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. Click Next on the Specify Template , Specify Details, and Options** sections. Finally, acknowledge that the template will create IAM roles under Capabilities and click Create**. This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE . Scenario As the administrator for an AWS account hosting multiple production applications, you've been tasked with creating a new administrator role to delegate some of your responsibilities. This new role will be responsible for doing all the administration on the resources for the Ares Mission . The diagram above showcases the two applications currently being hosted in the AWS account and their associated resources. Currently there is only one application related to the Ares Mission but there is a plan to migrate three more applications for this mission by the end of the year. The new role should account for current and future Ares Mission applications to reduce your overhead and friction with the web administrators. The web administrators for the Ares Mission should have permissions to create and administer resources related to that mission. This means they should be able to: Create, modify, and delete IAM policies and roles. Any role created must have restricted permissions to ensure a web administrator cannot elevate their privileges or the privileges of the application. Create, modify, and delete Ares Mission Lambda functions. The web administrators should not be able to impact any resources in the account that are not part of the Ares Mission application including users, groups, roles, S3 buckets, EC2 instances, etc. In this case, they should not be able to modify resources of the Rover Mission. All resources are located in the us-west-2 region. Task 1 - Create a permission boundary for Lambda Functions ACTION : Create a new IAM policy that will act as the permission boundary for the web admins. Name the policy identity-ex-permissionboundary-ares-lambda Hint : Friendly Names and Paths . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateLogGroup , Effect : Allow , Action : logs:CreateLogGroup , Resource : arn:aws:logs:us-west-2:ACCOUNT_ID:* }, { Sid : CreateLogStreamandEvents , Effect : Allow , Action : [ logs:CreateLogStream , logs:PutLogEvents ], Resource : arn:aws:logs:us-west-2:ACCOUNT_ID:log-group:/aws/lambda/identity-ex-????:* }, { Sid : AllowedS3GetObject , Effect : Allow , Action : [ s3:List* ], Resource : arn:aws:s3:::identity-ex-???? } ] } Task 2 - Create a permission policy for the Web Admin ACTION : Create the permission policy that will be attached to the webadmin AWS IAM user. Name the new policy identity-ex-webadmin-permissionpolicy . Hint : Friendly Names and Paths . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateCustomerManagedPolicies , Effect : Allow , Action : [ iam:CreatePolicy , iam:DeletePolicy , iam:CreatePolicyVersion , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : arn:aws:iam::ACCOUNT_ID:policy/identity-ex-???? }, { Sid : RoleandPolicyActionswithnoPermissionBoundarySupport , Effect : Allow , Action : [ iam:UpdateRole , iam:DeleteRole ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? ] }, { Sid : CreateRoles , Effect : Allow , Action : [ iam:CreateRole , iam:AttachRolePolicy , iam:DetachRolePolicy ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? ], Condition : { StringEquals : { iam:PermissionsBoundary : arn:aws:iam::ACCOUNT_ID:policy/identity-ex-permissionboundary-ares-lambda } } }, { Sid : LambdaFullAccesswithResourceRestrictions , Effect : Allow , Action : lambda:* , Resource : arn:aws:lambda:us-west-2:ACCOUNT_ID:function:identity-ex-???? }, { Sid : PassRoletoLambda , Effect : Allow , Action : iam:PassRole , Resource : arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? , Condition : { StringLikeIfExists : { iam:PassedToService : lambda.amazonaws.com } } }, { Sid : AdditionalPermissionsforLambda , Effect : Allow , Action : [ kms:ListAliases , logs:Describe* , logs:ListTagsLogGroup , logs:FilterLogEvents , logs:GetLogEvents ], Resource : * }, { Sid : DenyPermissionBoundaryandPolicyDeleteModify , Effect : Deny , Action : [ iam:CreatePolicyVersion , iam:DeletePolicy , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : [ arn:aws:iam::ACCOUNT_ID:policy/identity-ex-permissionboundary-ares-lambda , arn:aws:iam::ACCOUNT_ID:policy/identity-ex-webadmin-permissionpolicy ] }, { Sid : DenyRolePermissionBoundaryDelete , Effect : Deny , Action : iam:DeleteRolePermissionsBoundary , Resource : * } ] } Task 3 - Create the Web Admin user ACTION : Create an IAM User and name it webadmin . The user will need console access so give it a password. Attach the identity-ex-webadmin-permissionpolicy , IAMReadOnlyAccess AWSLambdaReadOnlyAccess policies to the IAM user. When you are done the webadmin user should have three policies attached: identity-ex-webadmin-permissionpolicy, IAMReadOnlyAccess AWSLambdaReadOnlyAccess. Task 4 - Gather info needed for the Verify phase ACTION : Now that you have setup the IAM user for the web admins, it's time to pass this information on to the next team who will work through the VERIFY tasks. You need to gather some details about your IAM user and then hand this info to the next team. Copy the IAM users sign-in link , the IAM user name (if you used a name other then webadmin ) and the password you used. You will also need the resource restriction that you used in your policies and the name you used for the permission policy and permission boundary (if you used names other than the ones recommended above) Here are all of the details you need to pass to another team: IAM users sign-in link: IAM user name: IAM user password: Resource restriction identifier: Permission boundary name: (recommended name: identity-ex-permissionboundary-ares-lambda ) Permission policy: (recommended name: identity-ex-webadmin-permissionpolicy ) Enter this information into the VERIFY phase form and exchange forms with another team so you both can work through the tasks. You can now move on to the Verify phase!","title":"Build Phase"},{"location":"builder-sessions/permission-boundary/build/#permission-boundaries-how-to-truly-delegate-permissions-on-aws-build-phase","text":"Permission boundaries is probably one of the most important new IAM features that has launched in a while. This feature addresses a longstanding customer issue, namely, how do I delegate administration to my users. If you have system administrators that need to be able to create IAM roles and users, developers that need to be able to create roles for Lambda functions, or any similar scenario, then you need permission boundaries. Presentation deck","title":"Permission Boundaries: How to Truly Delegate Permissions on AWS (Build Phase)"},{"location":"builder-sessions/permission-boundary/build/#environment-setup","text":"AWS Sponsored Event Browse to the URL provided to you and login. After you login click the AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for the Management console . Click on that and you will be taken to the AWS console. Individual Launch the CloudFormation stack below to setup the Permission Boundary environment: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. Click Next on the Specify Template , Specify Details, and Options** sections. Finally, acknowledge that the template will create IAM roles under Capabilities and click Create**. This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE .","title":"Environment Setup"},{"location":"builder-sessions/permission-boundary/build/#scenario","text":"As the administrator for an AWS account hosting multiple production applications, you've been tasked with creating a new administrator role to delegate some of your responsibilities. This new role will be responsible for doing all the administration on the resources for the Ares Mission . The diagram above showcases the two applications currently being hosted in the AWS account and their associated resources. Currently there is only one application related to the Ares Mission but there is a plan to migrate three more applications for this mission by the end of the year. The new role should account for current and future Ares Mission applications to reduce your overhead and friction with the web administrators. The web administrators for the Ares Mission should have permissions to create and administer resources related to that mission. This means they should be able to: Create, modify, and delete IAM policies and roles. Any role created must have restricted permissions to ensure a web administrator cannot elevate their privileges or the privileges of the application. Create, modify, and delete Ares Mission Lambda functions. The web administrators should not be able to impact any resources in the account that are not part of the Ares Mission application including users, groups, roles, S3 buckets, EC2 instances, etc. In this case, they should not be able to modify resources of the Rover Mission. All resources are located in the us-west-2 region.","title":"Scenario"},{"location":"builder-sessions/permission-boundary/build/#task-1-create-a-permission-boundary-for-lambda-functions","text":"ACTION : Create a new IAM policy that will act as the permission boundary for the web admins. Name the policy identity-ex-permissionboundary-ares-lambda Hint : Friendly Names and Paths . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateLogGroup , Effect : Allow , Action : logs:CreateLogGroup , Resource : arn:aws:logs:us-west-2:ACCOUNT_ID:* }, { Sid : CreateLogStreamandEvents , Effect : Allow , Action : [ logs:CreateLogStream , logs:PutLogEvents ], Resource : arn:aws:logs:us-west-2:ACCOUNT_ID:log-group:/aws/lambda/identity-ex-????:* }, { Sid : AllowedS3GetObject , Effect : Allow , Action : [ s3:List* ], Resource : arn:aws:s3:::identity-ex-???? } ] }","title":"Task 1 - Create a permission boundary for Lambda Functions"},{"location":"builder-sessions/permission-boundary/build/#task-2-create-a-permission-policy-for-the-web-admin","text":"ACTION : Create the permission policy that will be attached to the webadmin AWS IAM user. Name the new policy identity-ex-webadmin-permissionpolicy . Hint : Friendly Names and Paths . The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateCustomerManagedPolicies , Effect : Allow , Action : [ iam:CreatePolicy , iam:DeletePolicy , iam:CreatePolicyVersion , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : arn:aws:iam::ACCOUNT_ID:policy/identity-ex-???? }, { Sid : RoleandPolicyActionswithnoPermissionBoundarySupport , Effect : Allow , Action : [ iam:UpdateRole , iam:DeleteRole ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? ] }, { Sid : CreateRoles , Effect : Allow , Action : [ iam:CreateRole , iam:AttachRolePolicy , iam:DetachRolePolicy ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? ], Condition : { StringEquals : { iam:PermissionsBoundary : arn:aws:iam::ACCOUNT_ID:policy/identity-ex-permissionboundary-ares-lambda } } }, { Sid : LambdaFullAccesswithResourceRestrictions , Effect : Allow , Action : lambda:* , Resource : arn:aws:lambda:us-west-2:ACCOUNT_ID:function:identity-ex-???? }, { Sid : PassRoletoLambda , Effect : Allow , Action : iam:PassRole , Resource : arn:aws:iam::ACCOUNT_ID:role/identity-ex-???? , Condition : { StringLikeIfExists : { iam:PassedToService : lambda.amazonaws.com } } }, { Sid : AdditionalPermissionsforLambda , Effect : Allow , Action : [ kms:ListAliases , logs:Describe* , logs:ListTagsLogGroup , logs:FilterLogEvents , logs:GetLogEvents ], Resource : * }, { Sid : DenyPermissionBoundaryandPolicyDeleteModify , Effect : Deny , Action : [ iam:CreatePolicyVersion , iam:DeletePolicy , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : [ arn:aws:iam::ACCOUNT_ID:policy/identity-ex-permissionboundary-ares-lambda , arn:aws:iam::ACCOUNT_ID:policy/identity-ex-webadmin-permissionpolicy ] }, { Sid : DenyRolePermissionBoundaryDelete , Effect : Deny , Action : iam:DeleteRolePermissionsBoundary , Resource : * } ] }","title":"Task 2 - Create a permission policy for the Web Admin"},{"location":"builder-sessions/permission-boundary/build/#task-3-create-the-web-admin-user","text":"ACTION : Create an IAM User and name it webadmin . The user will need console access so give it a password. Attach the identity-ex-webadmin-permissionpolicy , IAMReadOnlyAccess AWSLambdaReadOnlyAccess policies to the IAM user. When you are done the webadmin user should have three policies attached: identity-ex-webadmin-permissionpolicy, IAMReadOnlyAccess AWSLambdaReadOnlyAccess.","title":"Task 3 - Create the Web Admin user"},{"location":"builder-sessions/permission-boundary/build/#task-4-gather-info-needed-for-the-verify-phase","text":"ACTION : Now that you have setup the IAM user for the web admins, it's time to pass this information on to the next team who will work through the VERIFY tasks. You need to gather some details about your IAM user and then hand this info to the next team. Copy the IAM users sign-in link , the IAM user name (if you used a name other then webadmin ) and the password you used. You will also need the resource restriction that you used in your policies and the name you used for the permission policy and permission boundary (if you used names other than the ones recommended above) Here are all of the details you need to pass to another team: IAM users sign-in link: IAM user name: IAM user password: Resource restriction identifier: Permission boundary name: (recommended name: identity-ex-permissionboundary-ares-lambda ) Permission policy: (recommended name: identity-ex-webadmin-permissionpolicy ) Enter this information into the VERIFY phase form and exchange forms with another team so you both can work through the tasks. You can now move on to the Verify phase!","title":"Task 4 - Gather info needed for the Verify phase"},{"location":"builder-sessions/permission-boundary/verify/","text":"Permission Boundaries: How to Truly Delegate Permissions on AWS (Verify Phase) We are now in the Verify phase. It is time to put on the hat of the web administrator and test the access to ensure the permissions are setup correctly. You'll be logging in to the AWS account you were delegated access to and perform a number of verification tasks. Console Login You should have received from another team the following information. You will need this information to access the AWS console IAM users sign-in link IAM user name IAM user password Resource restriction identifier Permission boundary name Requirements The only requirement is to verify you can complete the following tasks. The web admins should only have access to the following resources: IAM policies and roles created by the web admins Lambda functions created by the web admins The web admins should not be able to impact any resources in the account that they do not own including users, groups, roles, S3 buckets, EC2 instances, etc. The following steps should be taken to validate that the delegation was done properly. Verify that you are able to create an IAM policy, create an IAM role with that policy attached and then create a Lambda function and pass that role to it. Task 1 - Create a customer managed IAM policy The first step is to create a customer managed IAM policy. This will define the permissions of the role that you will pass to a Lambda function. Since the function will be working with S3 and since the point of this is to show how permission boundaries work, use the following policy which grants basic Lambda logging permissions and S3 full access. Keep in mind the resource restrictions put in place which will require you to use a certain name for the policy. What is the resource restriction identifier that was given to you? { Version : 2012-10-17 , Statement : [ { Effect : Allow , Action : [ logs:CreateLogGroup , logs:CreateLogStream , logs:PutLogEvents , s3:* ], Resource : * } ] } Task 2 - Create an IAM role Next you will create an IAM Role. Choose Lambda as the service for this role. Attach the policy you just created and the permission boundary (which will most likely be named: identity-ex-permissionboundary-ares-lambda ) Keep in mind the resource restrictions put in place which will require you to use a certain name for the role. What is the resource restriction identifier that was given to you? Task 3 - Create a Lambda function Finally you will create a Node.js 8.10 Lambda function using the code below and attach the IAM role you just created to it. You will need to replace \"ELB_ACCESS_LOGS_BUCKET_NAME\" with bucket from your account that begins with \"identity-ex-ares*\" . Keep in mind the resource restrictions put in place which will require you to use a certain name for the role. What is the resource restriction identifier that was given to you? const AWS = require ( aws-sdk ); const s3 = new AWS . S3 (); exports . handler = async ( event ) = { console.log( Loading function ) ; const allKeys = [] ; await getKeys({ Bucket : ELB_ACCESS_LOGS_BUCKET_NAME } , allKeys ); return allKeys ; } ; async function getKeys ( params , keys ) { const response = await s3.listObjectsV2(params).promise() ; response.Contents.forEach(obj = keys.push(obj.Key)) ; if (response.IsTruncated) { const newParams = Object.assign({ } , params ); newParams . ContinuationToken = response . NextContinuationToken ; await getKeys ( newParams , keys ); } } Test the Lambda function and make sure it is generating logs in CloudWatch logs and that it is able to list the ELB logs in the ELB access logs bucket the object in S3. In order to test you will need to create a test event. The parameters of the test do not matter. Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. Expand one of the following dropdowns and follow the instructions: AWS Sponsored Event No cleanup required! The responsibility falls to AWS. Individual You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete the Ares S3 bucket. Go to the Amazon S3 console. Click on the bucket named identity-ex-ares-app Click Delete Enter the bucket name again to confirm and click Delete . Delete the CloudFormation stack ( Identity-PB-Builder-Session ). Go to the AWS CloudFormation console. Select the appropriate stack. Select Action . Click Delete Stack . Summary Congratulations, you've completed the Permission Boundaries Builder session! Hopefully by going through this session you have a better idea of what permission boundaries are, where they can be used, and are starting to think about where you can apply them in your environments.","title":"Verify Phase"},{"location":"builder-sessions/permission-boundary/verify/#permission-boundaries-how-to-truly-delegate-permissions-on-aws-verify-phase","text":"We are now in the Verify phase. It is time to put on the hat of the web administrator and test the access to ensure the permissions are setup correctly. You'll be logging in to the AWS account you were delegated access to and perform a number of verification tasks.","title":"Permission Boundaries: How to Truly Delegate Permissions on AWS (Verify Phase)"},{"location":"builder-sessions/permission-boundary/verify/#console-login","text":"You should have received from another team the following information. You will need this information to access the AWS console IAM users sign-in link IAM user name IAM user password Resource restriction identifier Permission boundary name","title":"Console Login"},{"location":"builder-sessions/permission-boundary/verify/#requirements","text":"The only requirement is to verify you can complete the following tasks. The web admins should only have access to the following resources: IAM policies and roles created by the web admins Lambda functions created by the web admins The web admins should not be able to impact any resources in the account that they do not own including users, groups, roles, S3 buckets, EC2 instances, etc. The following steps should be taken to validate that the delegation was done properly. Verify that you are able to create an IAM policy, create an IAM role with that policy attached and then create a Lambda function and pass that role to it.","title":"Requirements"},{"location":"builder-sessions/permission-boundary/verify/#task-1-create-a-customer-managed-iam-policy","text":"The first step is to create a customer managed IAM policy. This will define the permissions of the role that you will pass to a Lambda function. Since the function will be working with S3 and since the point of this is to show how permission boundaries work, use the following policy which grants basic Lambda logging permissions and S3 full access. Keep in mind the resource restrictions put in place which will require you to use a certain name for the policy. What is the resource restriction identifier that was given to you? { Version : 2012-10-17 , Statement : [ { Effect : Allow , Action : [ logs:CreateLogGroup , logs:CreateLogStream , logs:PutLogEvents , s3:* ], Resource : * } ] }","title":"Task 1 - Create a customer managed IAM policy"},{"location":"builder-sessions/permission-boundary/verify/#task-2-create-an-iam-role","text":"Next you will create an IAM Role. Choose Lambda as the service for this role. Attach the policy you just created and the permission boundary (which will most likely be named: identity-ex-permissionboundary-ares-lambda ) Keep in mind the resource restrictions put in place which will require you to use a certain name for the role. What is the resource restriction identifier that was given to you?","title":"Task 2 - Create an IAM role"},{"location":"builder-sessions/permission-boundary/verify/#task-3-create-a-lambda-function","text":"Finally you will create a Node.js 8.10 Lambda function using the code below and attach the IAM role you just created to it. You will need to replace \"ELB_ACCESS_LOGS_BUCKET_NAME\" with bucket from your account that begins with \"identity-ex-ares*\" . Keep in mind the resource restrictions put in place which will require you to use a certain name for the role. What is the resource restriction identifier that was given to you? const AWS = require ( aws-sdk ); const s3 = new AWS . S3 (); exports . handler = async ( event ) = { console.log( Loading function ) ; const allKeys = [] ; await getKeys({ Bucket : ELB_ACCESS_LOGS_BUCKET_NAME } , allKeys ); return allKeys ; } ; async function getKeys ( params , keys ) { const response = await s3.listObjectsV2(params).promise() ; response.Contents.forEach(obj = keys.push(obj.Key)) ; if (response.IsTruncated) { const newParams = Object.assign({ } , params ); newParams . ContinuationToken = response . NextContinuationToken ; await getKeys ( newParams , keys ); } } Test the Lambda function and make sure it is generating logs in CloudWatch logs and that it is able to list the ELB logs in the ELB access logs bucket the object in S3. In order to test you will need to create a test event. The parameters of the test do not matter.","title":"Task 3 - Create a Lambda function"},{"location":"builder-sessions/permission-boundary/verify/#cleanup","text":"In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. Expand one of the following dropdowns and follow the instructions: AWS Sponsored Event No cleanup required! The responsibility falls to AWS. Individual You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete the Ares S3 bucket. Go to the Amazon S3 console. Click on the bucket named identity-ex-ares-app Click Delete Enter the bucket name again to confirm and click Delete . Delete the CloudFormation stack ( Identity-PB-Builder-Session ). Go to the AWS CloudFormation console. Select the appropriate stack. Select Action . Click Delete Stack .","title":"Cleanup"},{"location":"builder-sessions/permission-boundary/verify/#summary","text":"Congratulations, you've completed the Permission Boundaries Builder session! Hopefully by going through this session you have a better idea of what permission boundaries are, where they can be used, and are starting to think about where you can apply them in your environments.","title":"Summary"},{"location":"workshops/","text":"Workshops Title Description Detection with Machine Learning This workshop shows how you can use an IP-based machine learning algorithm with Amazon SageMaker to augment and enrich findings from AWS Security services such as Amazon GuardDuty. You'll learn how to load the notebook in SageMaker, train the model, and score findings to determine abnormality of the activity. Find All the Threats: AWS Threat Detection and Remediation This hands-on workshop is where you will learn about a number of AWS services involved with threat detection and response as we walk through real-world threat scenarios. Learn about the threat detection capabilities of Amazon GuardDuty, Amazon Macie and AWS Security Hub and the available response options. For each hands-on scenario, we review methods to detect and respond to threats using the following services: AWS CloudTrail, Amazon VPC flow logs, Amazon CloudWatch Events, Amazon Macie, AWS Lambda, Amazon Inspector, Amazon GuardDuty and Amazon Security Hub. Identity Round Robin This workshop is composed of a series of rounds covering a range of identity and access management topics. These topics cover identity in general, not just the AWS IAM service. To that end you will find coverage for platform identity, application identity and infrastructure identity on AWS. Some of the services covered (this is not a complete list) include AWS IAM, AWS CloudTrail, Amazon CloudWatch Events, Amazon S3, AWS Lambda, Amazon Macie, Amazon Inspector and Amazon GuardDuty.","title":"Directory"},{"location":"workshops/#workshops","text":"Title Description Detection with Machine Learning This workshop shows how you can use an IP-based machine learning algorithm with Amazon SageMaker to augment and enrich findings from AWS Security services such as Amazon GuardDuty. You'll learn how to load the notebook in SageMaker, train the model, and score findings to determine abnormality of the activity. Find All the Threats: AWS Threat Detection and Remediation This hands-on workshop is where you will learn about a number of AWS services involved with threat detection and response as we walk through real-world threat scenarios. Learn about the threat detection capabilities of Amazon GuardDuty, Amazon Macie and AWS Security Hub and the available response options. For each hands-on scenario, we review methods to detect and respond to threats using the following services: AWS CloudTrail, Amazon VPC flow logs, Amazon CloudWatch Events, Amazon Macie, AWS Lambda, Amazon Inspector, Amazon GuardDuty and Amazon Security Hub. Identity Round Robin This workshop is composed of a series of rounds covering a range of identity and access management topics. These topics cover identity in general, not just the AWS IAM service. To that end you will find coverage for platform identity, application identity and infrastructure identity on AWS. Some of the services covered (this is not a complete list) include AWS IAM, AWS CloudTrail, Amazon CloudWatch Events, Amazon S3, AWS Lambda, Amazon Macie, Amazon Inspector and Amazon GuardDuty.","title":"Workshops"},{"location":"workshops/detection-ml/","text":"Scalable, Automated Anomaly Detection with Amazon GuardDuty and SageMaker In this README you will find instructions and pointers to the resources used for the workshop. This workshop contains the following exercises: Examining GuardDuty findings IP-based anomaly detection in SageMaker After the setup steps below, there are instructions provided for all of the hands-on exercises, instructions of how to delete the CloudFormation stack, and following that a full walkthrough guide on how to complete the exercises. What's in here? This repository contains the following files that will be used for this workshop: aws_lambda/ cloudtrail_ingest.zip - Lambda zip bundle for workshop CloudTrail log ingest guardduty_ingest.zip - Lambda zip bundle for workshop GuardDuty finding ingest cleanup.sh - Shell script to delete the workshop CloudFormation stack at the end sec405-ipinsights.ipynb - Jupyter notebook for the workshop to load into SageMaker templates/ cloudformation.yaml - The CloudFormation template to deploy the stack of resources for the workshop Initial setup Prerequisites Before getting started, you will need the following: AWS account Modern, graphical web browser (sorry Lynx users!) IAM user with administrator access to the account Deploying the CloudFormation template The CloudFormation template creates the following: 2 Lambda functions CloudTrail log file ingester GuardDuty finding ingester IAM role used by the Lambda functions S3 bucket used for outputting (principal ID, IP address) tuples First, log in to your AWS account using the IAM user with administrator access. For this workshop, we will be working within the Canada Central (ca-central-1) region. To switch regions, click the region dropdown in the top right of the window and select Canada (Central) . To easily deploy the CloudFormation stack in the Canada (Central) region, please browse to the following stack launch URL: https://console.aws.amazon.com/cloudformation/home?region=ca-central-1#/stacks/new?stackName=SEC405 templateURL=https://s3.ca-central-1.amazonaws.com/aws-reinvent2018-sec405-de42b9ca/cloudformation.yaml The stack launch URL uses a copy of the CloudFormation template from templates/cloudformation.yaml that is contained in an S3 bucket and is the same as the one in this code repository. On the Select Template page, note that the template location where it says \"Specify an Amazon S3 template URL\" is pre-populated with the S3 URL to the template. Click Next . On the Specify Details page, the stack name is pre-populated as \"SEC405\", but you may change it if you wish. Click Next . On the Options screen, click Next . On the Review page, check the box for \u201cI acknowledge that AWS CloudFormation might create IAM resources\u201d since the template creates an IAM role. Click Create to deploy the stack. While the CloudFormation stack is being created, you can view its status in the AWS CloudFormation console. You should see a green Status of CREATE_COMPLETE in just a few minutes. While waiting for the CloudFormation stack to complete, you may proceed to Exercise 1. Exercise 1: Examining GuardDuty findings In this exercise, you will generate and examine sample GuardDuty findings to understand what information they contain, and then also look at several \"real\" GuardDuty findings that were generated in advance from actual AWS account activity. The goal of this exercise is to familiarize with the kinds of information contained in GuardDuty findings, and the structure of the findings themselves.. 1.1 Generate sample findings From the Services dropdown in the top left, browse to the GuardDuty console. Double check that you are in the Canada (Central) region via the region dropdown in the top right, and switch to it if you are not. If GuardDuty is not yet enabled, click the button labelled Enable GuardDuty to turn it on with a single click. In the left menu click Settings , scroll down to the section titled \"Sample Findings\", and then click on the button labelled Generate sample findings to generate a sample GuardDuty finding for every finding type. Click on Findings in the left menu and then examine some of the findings shown in the GuardDuty console. What kinds of information do you see? Examine some of the findings with a threat purpose of \"UnauthorizedAccess\". 1.2 Examining real findings The \"real\" GuardDuty findings that were generated for this workshop are contained in an S3 bucket. Rather than read them directly, we're going to run the AWS Lambda ingester function for the GuardDuty findings that will read in the findings from the S3 bucket and print them out. Browse to the AWS Lambda console, again ensuring you're in the Canada (Central) region, and then click on the Lambda function whose name starts with \"SEC405-GuardDutyIngestLambda\". Scroll down to view the code for the Lambda function in the inline, browser-based editor. Skim through the code to familiarize with what it does. Click the Test button to run the function. You will need to create a test event to do this, but the event actually does not matter in this case, so just use the \"Hello World\" event template and give it a name \"SEC405\", then click Create . You then need to click the Test button once more. Examine the output, where you'll see the JSON for each GuardDuty finding being printed by the function print_full_finding . Look over the findings to see what information they contain. A function called print_short_finding is also defined to print out a shortened, one-line version of each GuardDuty finding. Replace the call to the function print_full_finding with print_short_finding (hint: Search for \"TODO\" around line 135. You will see multiple TODOs in the file, but only the first one applies here.). Click the Save button at the top of the screen to save your changes to the function, then click Test to run it again. Observe the new output, where you will now see a summarized version of each finding being printed. Exercise 2: IP-based anomaly detection in SageMaker In this exercise, you will use the IP Insights SageMaker machine learning algorithm to learn how unusual GuardDuty findings are for given principals (i.e., IAM users or roles) based on IP address. First, you will use two Lambda functions to prepare the input data for the ML algorithm from the source CloudTrail and GuardDuty log data. You will generate training data consisting of principal ID, IP address tuples from the CloudTrail logs and then you will call the trained model to make inferences to score the GuardDuty findings from Exercise 1 by using a similar set of tuples generated from the findings. The GuardDuty findings are based on the same set of account activity as the CloudTrail logs. 2.1 Generate training data using CloudTrail logs In order to use the IP Insights model, we need some training data. We will train the model by passing principal ID, IP address tuples extracted from CloudTrail logs. An AWS Lambda function has been created to do this, but you'll need to make a small change to the function and then run it to generate the tuples. Browse to the AWS Lambda console and click on the Lambda function whose name starts with \"SEC405-CloudTrailIngestLambda\". Scroll down to view the code for the Lambda function in the inline, browser-based editor. Skim through the code to familiarize with what it does. Click the Test button to run the function. You will need to create a test event to do this, but the event actually does not matter in this case, so just use the \"Hello World\" event template and give it a name \"SEC405\", then click Create . You then need to click the Test button once more. Look at the output of the function, where you'll see a short version of each CloudTrail record returned by the function print_short_record being printed. A function get_tuple has been provided to take a CloudTrail record as input and return a principal ID, IP address tuple for each record. A call to this function has already been set up in the handler function, but the lines are commented out (hint: search for the string \"TODO\"). Uncomment both lines. Click the Save button at the top to save your function changes. Click the Test button to run the function again. This time it will write the tuples to the S3 bucket where they can be loaded into the IP Insights algorithm for training the model. In the S3 console, if you find the bucket whose name starts with \"sec405-tuplesbucket\", you should now see a file \"train/cloudtrail_tuples.csv\" inside that contains some principal ID, IP address tuples. 2.2 Generate scoring data using GuardDuty findings To make use of the trained model, we will pass principal ID, IP address tuples extracted from the GuardDuty findings to it for scoring (i.e., inference). The activity contained in these GuardDuty findings directly corresponds to the activity contained in the CloudTrail logs. An AWS Lambda function has been created to do this, but you'll need to make a small change to the function and then run it to generate the tuples. Browse to the AWS Lambda console and click on the Lambda function whose name starts with \"SEC405-GuardDutyIngestLambda\". A function get_tuples has been provided to take GuardDuty findings as input and return principal ID, IP address tuples for each finding. A call to this function has already been set up in the handler function (search for the string \"TODO\"), but the line is is commented out. Uncomment it. Click the Save button at the top to save your function changes. Click the Test button to run the function again. This time it write the tuples to the S3 bucket where they can be loaded into the IP Insights algorithm for scoring. In the S3 console, if you find the bucket whose name starts with \"sec405-tuplesbucket\", you should now see a file \"infer/guardduty_tuples.csv\" inside that contains some principal ID, IP address tuples. 2.3 Set up the SageMaker notebook To use the IP Insights algorithm, you will work from a Jupyter notebook, which is an interactive coding environment that lets you mix notes and documentation with code blocks that can be \"run\" in a stepwise fashion throughout the notebook and share the same interpreter. First, go to the S3 console and look for the bucket whose name starts with \"sec405-tuplesbucket\" (e.g., sec405-tuplesbucket-1fnqifqbmsfxy). Copy the name of this bucket; you will need it in a moment. Browse to the Amazon SageMaker console and click on the button called Create notebook instance . On the next screen, give the notebook a name \"SEC405\". For Notebook instance type, we recommend selecting ml.t2.medium. For IAM role, choose \"Create a new role\" in the dropdown. On the next dialog, ensure \"S3 buckets you specify\" is selected, in the text field for \"Specific S3 buckets\" paste the name of the S3 bucket from step 1, and click Create role . All other notebook options can be left at defaults. Click Create notebook instance . Once the notebook is running, click Open Jupyter to open the notebook. Download the sample notebook file for the workshop where we will be working with the IP Insights algorithm: https://s3.ca-central-1.amazonaws.com/aws-reinvent2018-sec405-de42b9ca/sec405-ipinsights.ipynb Once you download the notebook file, click the Upload button on the upper right hand side in Jupyter to upload it to your running notebook instance. 2.4 Training and scoring with the IP Insights algorithm Click on the notebook and work through it step by step to learn how to train the model using the tuples from the CloudTrail logs and then make inferences by scoring the tuples from the GuardDuty findings. We recommend using the \"Run\" command to walk through each code block one by one rather than doing \"Run All\". IP Insights is an unsupervised learning algorithm for detecting anomalous behavior and usage patterns of IP addresses, that helps users identifying fraudulent behavior using IP addresses, describe the Amazon SageMaker IP Insights algorithm, demonstrate how you can use it in a real-world application, and share some of our results using it internally. For more information about the IP Insights algorithm, please read the following AWS blog post: https://aws.amazon.com/blogs/machine-learning/detect-suspicious-ip-addresses-with-the-amazon-sagemaker-ip-insights-algorithm/ You can also view the IP Insights documentation here: https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights.html 2.4.1 (BONUS) IP Insights algorithm tutorial If you would like to experiment with the IP Insights algorithm using a much larger dataset, you can choose the SageMaker Examples tab in Jupyter to see a list of all the Amazon SageMaker examples. Expand the Introduction to Amazon Algorithms section, look for a notebook called ipinsights-tutorial.ipynb , then click its Use button and Create copy in the dialog to create a copy of it, then work through it step by step. Cleaning up In order to prevent charges to your account from the resources created during this workshop, we recommend cleaning up the infrastructure that was created by deleting the CloudFormation stack. You can leave things running though if you want to do more with the workshop; the following cleanup steps can be performed at any time. We've created a Bash script to delete the CloudFormation stack, which will remove the Lambda functions, IAM role, and S3 bucket. We use a script because the S3 bucket has The script, cleanup.sh , is provided in this repository. Download it and then run as follows: chmod +x cleanup.sh ./cleanup.sh If you are using a different AWS CLI profile than the default, you can specify it with the -p PROFILE parameter to the script, like cleanup.sh -p foo . If you cannot run the Bash script, you can manually clean-up these resources by the following steps: Go to the S3 console and delete the bucket whose name starts with \"sec405-tuplesbucket\". Delete the CloudFormation stack by going to the CloudFormation console, selecting the stack called SEC405 , and from the top menu choosing action Delete Stack . This step will fail if you haven't deleted the S3 bucket first. You will also need to turn off or remove the following resources, unless you wish to keep them running or retain them: GuardDuty ( pricing info ) Go to the GuardDuty console, go to Settings , then scroll down and choose either Suspend GuardDuty or Disable GuardDuty . SageMaker ( pricing info ) Notebook - On the Notebook instances page in the SageMaker console, click the circle to select the \"SEC405\" notebook then under Actions choose Stop . Once the notebook is stopped, under Actions choose Delete . If you'd rather keep the notebook around to work with again, then just Stop is enough. Endpoint - On the Endpoints page in the SageMaker console, click the circle to select the endpoint for the workshop (the endpoint with the name stored in the variable endpoint_name from the notebook), then under Actions choose Delete . CloudWatch ( pricing info ) Logs - CloudWatch log groups will have been created for the \"SEC405-CloudTrailIngestLambda\" and \"SEC405-GuardDutyIngestLambda\" AWS Lambda functions. You can delete a log group by selecting it and then under Actions choosing Delete log group .","title":"Detection with Machine Learning"},{"location":"workshops/detection-ml/#scalable-automated-anomaly-detection-with-amazon-guardduty-and-sagemaker","text":"In this README you will find instructions and pointers to the resources used for the workshop. This workshop contains the following exercises: Examining GuardDuty findings IP-based anomaly detection in SageMaker After the setup steps below, there are instructions provided for all of the hands-on exercises, instructions of how to delete the CloudFormation stack, and following that a full walkthrough guide on how to complete the exercises.","title":"Scalable, Automated Anomaly Detection with Amazon GuardDuty and SageMaker"},{"location":"workshops/detection-ml/#whats-in-here","text":"This repository contains the following files that will be used for this workshop: aws_lambda/ cloudtrail_ingest.zip - Lambda zip bundle for workshop CloudTrail log ingest guardduty_ingest.zip - Lambda zip bundle for workshop GuardDuty finding ingest cleanup.sh - Shell script to delete the workshop CloudFormation stack at the end sec405-ipinsights.ipynb - Jupyter notebook for the workshop to load into SageMaker templates/ cloudformation.yaml - The CloudFormation template to deploy the stack of resources for the workshop","title":"What's in here?"},{"location":"workshops/detection-ml/#initial-setup","text":"","title":"Initial setup"},{"location":"workshops/detection-ml/#prerequisites","text":"Before getting started, you will need the following: AWS account Modern, graphical web browser (sorry Lynx users!) IAM user with administrator access to the account","title":"Prerequisites"},{"location":"workshops/detection-ml/#deploying-the-cloudformation-template","text":"The CloudFormation template creates the following: 2 Lambda functions CloudTrail log file ingester GuardDuty finding ingester IAM role used by the Lambda functions S3 bucket used for outputting (principal ID, IP address) tuples First, log in to your AWS account using the IAM user with administrator access. For this workshop, we will be working within the Canada Central (ca-central-1) region. To switch regions, click the region dropdown in the top right of the window and select Canada (Central) . To easily deploy the CloudFormation stack in the Canada (Central) region, please browse to the following stack launch URL: https://console.aws.amazon.com/cloudformation/home?region=ca-central-1#/stacks/new?stackName=SEC405 templateURL=https://s3.ca-central-1.amazonaws.com/aws-reinvent2018-sec405-de42b9ca/cloudformation.yaml The stack launch URL uses a copy of the CloudFormation template from templates/cloudformation.yaml that is contained in an S3 bucket and is the same as the one in this code repository. On the Select Template page, note that the template location where it says \"Specify an Amazon S3 template URL\" is pre-populated with the S3 URL to the template. Click Next . On the Specify Details page, the stack name is pre-populated as \"SEC405\", but you may change it if you wish. Click Next . On the Options screen, click Next . On the Review page, check the box for \u201cI acknowledge that AWS CloudFormation might create IAM resources\u201d since the template creates an IAM role. Click Create to deploy the stack. While the CloudFormation stack is being created, you can view its status in the AWS CloudFormation console. You should see a green Status of CREATE_COMPLETE in just a few minutes. While waiting for the CloudFormation stack to complete, you may proceed to Exercise 1.","title":"Deploying the CloudFormation template"},{"location":"workshops/detection-ml/#exercise-1-examining-guardduty-findings","text":"In this exercise, you will generate and examine sample GuardDuty findings to understand what information they contain, and then also look at several \"real\" GuardDuty findings that were generated in advance from actual AWS account activity. The goal of this exercise is to familiarize with the kinds of information contained in GuardDuty findings, and the structure of the findings themselves..","title":"Exercise 1: Examining GuardDuty findings"},{"location":"workshops/detection-ml/#11-generate-sample-findings","text":"From the Services dropdown in the top left, browse to the GuardDuty console. Double check that you are in the Canada (Central) region via the region dropdown in the top right, and switch to it if you are not. If GuardDuty is not yet enabled, click the button labelled Enable GuardDuty to turn it on with a single click. In the left menu click Settings , scroll down to the section titled \"Sample Findings\", and then click on the button labelled Generate sample findings to generate a sample GuardDuty finding for every finding type. Click on Findings in the left menu and then examine some of the findings shown in the GuardDuty console. What kinds of information do you see? Examine some of the findings with a threat purpose of \"UnauthorizedAccess\".","title":"1.1 Generate sample findings"},{"location":"workshops/detection-ml/#12-examining-real-findings","text":"The \"real\" GuardDuty findings that were generated for this workshop are contained in an S3 bucket. Rather than read them directly, we're going to run the AWS Lambda ingester function for the GuardDuty findings that will read in the findings from the S3 bucket and print them out. Browse to the AWS Lambda console, again ensuring you're in the Canada (Central) region, and then click on the Lambda function whose name starts with \"SEC405-GuardDutyIngestLambda\". Scroll down to view the code for the Lambda function in the inline, browser-based editor. Skim through the code to familiarize with what it does. Click the Test button to run the function. You will need to create a test event to do this, but the event actually does not matter in this case, so just use the \"Hello World\" event template and give it a name \"SEC405\", then click Create . You then need to click the Test button once more. Examine the output, where you'll see the JSON for each GuardDuty finding being printed by the function print_full_finding . Look over the findings to see what information they contain. A function called print_short_finding is also defined to print out a shortened, one-line version of each GuardDuty finding. Replace the call to the function print_full_finding with print_short_finding (hint: Search for \"TODO\" around line 135. You will see multiple TODOs in the file, but only the first one applies here.). Click the Save button at the top of the screen to save your changes to the function, then click Test to run it again. Observe the new output, where you will now see a summarized version of each finding being printed.","title":"1.2 Examining real findings"},{"location":"workshops/detection-ml/#exercise-2-ip-based-anomaly-detection-in-sagemaker","text":"In this exercise, you will use the IP Insights SageMaker machine learning algorithm to learn how unusual GuardDuty findings are for given principals (i.e., IAM users or roles) based on IP address. First, you will use two Lambda functions to prepare the input data for the ML algorithm from the source CloudTrail and GuardDuty log data. You will generate training data consisting of principal ID, IP address tuples from the CloudTrail logs and then you will call the trained model to make inferences to score the GuardDuty findings from Exercise 1 by using a similar set of tuples generated from the findings. The GuardDuty findings are based on the same set of account activity as the CloudTrail logs.","title":"Exercise 2: IP-based anomaly detection in SageMaker"},{"location":"workshops/detection-ml/#21-generate-training-data-using-cloudtrail-logs","text":"In order to use the IP Insights model, we need some training data. We will train the model by passing principal ID, IP address tuples extracted from CloudTrail logs. An AWS Lambda function has been created to do this, but you'll need to make a small change to the function and then run it to generate the tuples. Browse to the AWS Lambda console and click on the Lambda function whose name starts with \"SEC405-CloudTrailIngestLambda\". Scroll down to view the code for the Lambda function in the inline, browser-based editor. Skim through the code to familiarize with what it does. Click the Test button to run the function. You will need to create a test event to do this, but the event actually does not matter in this case, so just use the \"Hello World\" event template and give it a name \"SEC405\", then click Create . You then need to click the Test button once more. Look at the output of the function, where you'll see a short version of each CloudTrail record returned by the function print_short_record being printed. A function get_tuple has been provided to take a CloudTrail record as input and return a principal ID, IP address tuple for each record. A call to this function has already been set up in the handler function, but the lines are commented out (hint: search for the string \"TODO\"). Uncomment both lines. Click the Save button at the top to save your function changes. Click the Test button to run the function again. This time it will write the tuples to the S3 bucket where they can be loaded into the IP Insights algorithm for training the model. In the S3 console, if you find the bucket whose name starts with \"sec405-tuplesbucket\", you should now see a file \"train/cloudtrail_tuples.csv\" inside that contains some principal ID, IP address tuples.","title":"2.1 Generate training data using CloudTrail logs"},{"location":"workshops/detection-ml/#22-generate-scoring-data-using-guardduty-findings","text":"To make use of the trained model, we will pass principal ID, IP address tuples extracted from the GuardDuty findings to it for scoring (i.e., inference). The activity contained in these GuardDuty findings directly corresponds to the activity contained in the CloudTrail logs. An AWS Lambda function has been created to do this, but you'll need to make a small change to the function and then run it to generate the tuples. Browse to the AWS Lambda console and click on the Lambda function whose name starts with \"SEC405-GuardDutyIngestLambda\". A function get_tuples has been provided to take GuardDuty findings as input and return principal ID, IP address tuples for each finding. A call to this function has already been set up in the handler function (search for the string \"TODO\"), but the line is is commented out. Uncomment it. Click the Save button at the top to save your function changes. Click the Test button to run the function again. This time it write the tuples to the S3 bucket where they can be loaded into the IP Insights algorithm for scoring. In the S3 console, if you find the bucket whose name starts with \"sec405-tuplesbucket\", you should now see a file \"infer/guardduty_tuples.csv\" inside that contains some principal ID, IP address tuples.","title":"2.2 Generate scoring data using GuardDuty findings"},{"location":"workshops/detection-ml/#23-set-up-the-sagemaker-notebook","text":"To use the IP Insights algorithm, you will work from a Jupyter notebook, which is an interactive coding environment that lets you mix notes and documentation with code blocks that can be \"run\" in a stepwise fashion throughout the notebook and share the same interpreter. First, go to the S3 console and look for the bucket whose name starts with \"sec405-tuplesbucket\" (e.g., sec405-tuplesbucket-1fnqifqbmsfxy). Copy the name of this bucket; you will need it in a moment. Browse to the Amazon SageMaker console and click on the button called Create notebook instance . On the next screen, give the notebook a name \"SEC405\". For Notebook instance type, we recommend selecting ml.t2.medium. For IAM role, choose \"Create a new role\" in the dropdown. On the next dialog, ensure \"S3 buckets you specify\" is selected, in the text field for \"Specific S3 buckets\" paste the name of the S3 bucket from step 1, and click Create role . All other notebook options can be left at defaults. Click Create notebook instance . Once the notebook is running, click Open Jupyter to open the notebook. Download the sample notebook file for the workshop where we will be working with the IP Insights algorithm: https://s3.ca-central-1.amazonaws.com/aws-reinvent2018-sec405-de42b9ca/sec405-ipinsights.ipynb Once you download the notebook file, click the Upload button on the upper right hand side in Jupyter to upload it to your running notebook instance.","title":"2.3 Set up the SageMaker notebook"},{"location":"workshops/detection-ml/#24-training-and-scoring-with-the-ip-insights-algorithm","text":"Click on the notebook and work through it step by step to learn how to train the model using the tuples from the CloudTrail logs and then make inferences by scoring the tuples from the GuardDuty findings. We recommend using the \"Run\" command to walk through each code block one by one rather than doing \"Run All\". IP Insights is an unsupervised learning algorithm for detecting anomalous behavior and usage patterns of IP addresses, that helps users identifying fraudulent behavior using IP addresses, describe the Amazon SageMaker IP Insights algorithm, demonstrate how you can use it in a real-world application, and share some of our results using it internally. For more information about the IP Insights algorithm, please read the following AWS blog post: https://aws.amazon.com/blogs/machine-learning/detect-suspicious-ip-addresses-with-the-amazon-sagemaker-ip-insights-algorithm/ You can also view the IP Insights documentation here: https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights.html 2.4.1 (BONUS) IP Insights algorithm tutorial If you would like to experiment with the IP Insights algorithm using a much larger dataset, you can choose the SageMaker Examples tab in Jupyter to see a list of all the Amazon SageMaker examples. Expand the Introduction to Amazon Algorithms section, look for a notebook called ipinsights-tutorial.ipynb , then click its Use button and Create copy in the dialog to create a copy of it, then work through it step by step.","title":"2.4 Training and scoring with the IP Insights algorithm"},{"location":"workshops/detection-ml/#cleaning-up","text":"In order to prevent charges to your account from the resources created during this workshop, we recommend cleaning up the infrastructure that was created by deleting the CloudFormation stack. You can leave things running though if you want to do more with the workshop; the following cleanup steps can be performed at any time. We've created a Bash script to delete the CloudFormation stack, which will remove the Lambda functions, IAM role, and S3 bucket. We use a script because the S3 bucket has The script, cleanup.sh , is provided in this repository. Download it and then run as follows: chmod +x cleanup.sh ./cleanup.sh If you are using a different AWS CLI profile than the default, you can specify it with the -p PROFILE parameter to the script, like cleanup.sh -p foo . If you cannot run the Bash script, you can manually clean-up these resources by the following steps: Go to the S3 console and delete the bucket whose name starts with \"sec405-tuplesbucket\". Delete the CloudFormation stack by going to the CloudFormation console, selecting the stack called SEC405 , and from the top menu choosing action Delete Stack . This step will fail if you haven't deleted the S3 bucket first. You will also need to turn off or remove the following resources, unless you wish to keep them running or retain them: GuardDuty ( pricing info ) Go to the GuardDuty console, go to Settings , then scroll down and choose either Suspend GuardDuty or Disable GuardDuty . SageMaker ( pricing info ) Notebook - On the Notebook instances page in the SageMaker console, click the circle to select the \"SEC405\" notebook then under Actions choose Stop . Once the notebook is stopped, under Actions choose Delete . If you'd rather keep the notebook around to work with again, then just Stop is enough. Endpoint - On the Endpoints page in the SageMaker console, click the circle to select the endpoint for the workshop (the endpoint with the name stored in the variable endpoint_name from the notebook), then under Actions choose Delete . CloudWatch ( pricing info ) Logs - CloudWatch log groups will have been created for the \"SEC405-CloudTrailIngestLambda\" and \"SEC405-GuardDutyIngestLambda\" AWS Lambda functions. You can delete a log group by selecting it and then under Actions choosing Delete log group .","title":"Cleaning up"},{"location":"workshops/identity-round-robin/","text":"Identity Round Robin This workshop is composed of a series of rounds covering a range of identity and access management topics. These topics cover identity in general, not just the AWS IAM service. To that end you will find coverage for platform identity, application identity and infrastructure identity on AWS. Some of the services covered (this is not a complete list) include AWS IAM, AWS CloudTrail, Amazon CloudWatch Events, Amazon S3, AWS Lambda, Amazon Macie, Amazon Inspector and Amazon GuardDuty. Published rounds Serverless External security services Permission boundaries Upcoming rounds","title":"Overview"},{"location":"workshops/identity-round-robin/#identity-round-robin","text":"This workshop is composed of a series of rounds covering a range of identity and access management topics. These topics cover identity in general, not just the AWS IAM service. To that end you will find coverage for platform identity, application identity and infrastructure identity on AWS. Some of the services covered (this is not a complete list) include AWS IAM, AWS CloudTrail, Amazon CloudWatch Events, Amazon S3, AWS Lambda, Amazon Macie, Amazon Inspector and Amazon GuardDuty.","title":"Identity Round Robin"},{"location":"workshops/identity-round-robin/#published-rounds","text":"Serverless External security services Permission boundaries","title":"Published rounds"},{"location":"workshops/identity-round-robin/#upcoming-rounds","text":"","title":"Upcoming rounds"},{"location":"workshops/identity-round-robin/ess/","text":"External Security Services Round Welcome to the world of AWS External Security Services! AWS External Services consists of Amazon GuardDuty, Amazon Inspector, and Amazon Macie. In this round, you are going to work through a scenario that could arise in an organization that uses Amazon Web Services for production workloads. You will play the role of an AWS \"superuser\" administrator. You have heard that Amazon GuardDuty, Inspector, and Macie are services that can help you monitor the data, host, and network traffic within your AWS environment and detect anomalous behaviors. In this round of the workshop, you will learn how to use Amazon IAM to control access to these services. AWS Service/Feature Coverage : Amazon GuardDuty Amazon Inspector Amazon Macie AWS Identity and Access Management (IAM) Console role-switching Agenda This round is broken down into Build and Verify Phases. BUILD (45 min): At a high level, in the Build Phase you will do the following: Build the environment using AWS CloudFormation. Perform further customization on the environments to restrict the capabilities of the Security Operator Role. Test your customizations. Pass your credentials to another team to verify the configuration of your environment. VERIFY (30 min): The Verify Phase involves testing the work that another team did in building the environmentensure the requirements were met. You will do the following: Obtain the login credentials from another team that has performed the steps in the Build Phase. Test the environment to determine if the Security Operator role has been properly configured. Document any variances. This workshop can be done as a team exercise or individually. The instructions are written with the assumption that you are working as part of a team but you could just as easily do the steps below individually. If done as part of an AWS sponsored event then you'll be split into teams of around 4-6 people. Each team will do the Build Phase and then hand off their accounts to another team. Then another team will do the Verify Phase. Assumptions and Prerequisites You will need an AWS account for this lab and administrative credentials. These may be provided by an event sponsor. You should be familiar with AWS core services such as AWS CloudFormation and Amazon S3. You should also be comfortable using the AWS console. Architecture Overview The environment in this round consists of an AWS account in which Amazon GuardDuty, Amazon Inspector, Amazon Macie and Amazon CloudTrail will run. The CloudTrail logs will be sent to an Amazon S3 bucket. An Amazon EC2 instance will be launched which will in turn start the Amazon Macie Activity Generator and also launch an Amazon Inspector assessment. The template also creates two AWS IAM roles. The first role is for a Security Administrator which has full access to the External Security Services. The second role is for Security Operators. The Security Operator role initially is very similar to the Security Administrator role but you will modify the permissions of the Security Operator role to provide \"read only\" access to the External Security Services. The use of Security Administrator/Operator roles is very common in organizations that want to delegate the use of security services to different security teams. Here is a picture of what you will build. Preparation You will need an AWS account and the associated administrative login credentials. These may be provided by an event sponsor. SECURITY NOTES If you are providing your own account, make sure the account is used only for educational purposes. The AWS CloudFormation template creates managed roles and policies that allow ANYONE to assume the role that in turn grants access to Amazon S3, AWS CloudTrail, Amazon Macie, Amazon GuardDuty, and Amazon SNS in the account. This is done because the lab needs to work in a variety of environments. Make sure you follow the cleanup instructions at the end of the Verify Phase. Click here to proceed to the Build Phase","title":"Scenario"},{"location":"workshops/identity-round-robin/ess/#external-security-services-round","text":"Welcome to the world of AWS External Security Services! AWS External Services consists of Amazon GuardDuty, Amazon Inspector, and Amazon Macie. In this round, you are going to work through a scenario that could arise in an organization that uses Amazon Web Services for production workloads. You will play the role of an AWS \"superuser\" administrator. You have heard that Amazon GuardDuty, Inspector, and Macie are services that can help you monitor the data, host, and network traffic within your AWS environment and detect anomalous behaviors. In this round of the workshop, you will learn how to use Amazon IAM to control access to these services. AWS Service/Feature Coverage : Amazon GuardDuty Amazon Inspector Amazon Macie AWS Identity and Access Management (IAM) Console role-switching","title":"External Security Services Round"},{"location":"workshops/identity-round-robin/ess/#agenda","text":"This round is broken down into Build and Verify Phases. BUILD (45 min): At a high level, in the Build Phase you will do the following: Build the environment using AWS CloudFormation. Perform further customization on the environments to restrict the capabilities of the Security Operator Role. Test your customizations. Pass your credentials to another team to verify the configuration of your environment. VERIFY (30 min): The Verify Phase involves testing the work that another team did in building the environmentensure the requirements were met. You will do the following: Obtain the login credentials from another team that has performed the steps in the Build Phase. Test the environment to determine if the Security Operator role has been properly configured. Document any variances. This workshop can be done as a team exercise or individually. The instructions are written with the assumption that you are working as part of a team but you could just as easily do the steps below individually. If done as part of an AWS sponsored event then you'll be split into teams of around 4-6 people. Each team will do the Build Phase and then hand off their accounts to another team. Then another team will do the Verify Phase.","title":"Agenda"},{"location":"workshops/identity-round-robin/ess/#assumptions-and-prerequisites","text":"You will need an AWS account for this lab and administrative credentials. These may be provided by an event sponsor. You should be familiar with AWS core services such as AWS CloudFormation and Amazon S3. You should also be comfortable using the AWS console.","title":"Assumptions and Prerequisites"},{"location":"workshops/identity-round-robin/ess/#architecture-overview","text":"The environment in this round consists of an AWS account in which Amazon GuardDuty, Amazon Inspector, Amazon Macie and Amazon CloudTrail will run. The CloudTrail logs will be sent to an Amazon S3 bucket. An Amazon EC2 instance will be launched which will in turn start the Amazon Macie Activity Generator and also launch an Amazon Inspector assessment. The template also creates two AWS IAM roles. The first role is for a Security Administrator which has full access to the External Security Services. The second role is for Security Operators. The Security Operator role initially is very similar to the Security Administrator role but you will modify the permissions of the Security Operator role to provide \"read only\" access to the External Security Services. The use of Security Administrator/Operator roles is very common in organizations that want to delegate the use of security services to different security teams. Here is a picture of what you will build.","title":"Architecture Overview"},{"location":"workshops/identity-round-robin/ess/#preparation","text":"You will need an AWS account and the associated administrative login credentials. These may be provided by an event sponsor. SECURITY NOTES If you are providing your own account, make sure the account is used only for educational purposes. The AWS CloudFormation template creates managed roles and policies that allow ANYONE to assume the role that in turn grants access to Amazon S3, AWS CloudTrail, Amazon Macie, Amazon GuardDuty, and Amazon SNS in the account. This is done because the lab needs to work in a variety of environments. Make sure you follow the cleanup instructions at the end of the Verify Phase.","title":"Preparation"},{"location":"workshops/identity-round-robin/ess/#click-here-to-proceed-to-the-build-phase","text":"","title":"Click here to proceed to the Build Phase"},{"location":"workshops/identity-round-robin/ess/build/","text":"External Security Services Round (Build Phase) IMPORTANT NOTE! Please make sure you have followed the instructions in the instructions in the scenario section before continuing below. Sign in to AWS Depending on how you're doing this workshop, expand one of the following dropdowns to sign into AWS. AWS-sponsored event In a separate tab in your web browser, go to the URL provided to you and login. After you login click the AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for the Management console . Click on that and you will be taken to the AWS console. Individual or an event not sponsored by AWS In a separate tab in your web browser, go to https://aws.amazon.com/console and log into your account. Enable Macie Before we build out our environment, you must make sure Amazon Macie is running. Select Macie from the main console. Macie will open in a new browser tab. Select the us-west-2 (Oregon) region. When the Macie console appears, if a Getting Started button appears, it means that Amazon Macie is disabled. In that case, click Getting Started , confirm that US West (Oregon) is selected as the region, and click Enable Macie . Close the browser tab containing the Macie console. Build out the environment Return to the AWS Console, sigining into the account again if necessary. Open the Deploy to AWS link that follows in a new browser tab to deploy the logging environment in the us-west-2 region: In the new browser tab that you just opened, you will see the Select Template page. Click Next . On the Specify Details/Parameters page, the values have been filled in for you. Click Next . On the Options page, click Next . On the Review page, check both of the I acknowledge boxes and click Create . One acknowledgement is requested because of the creation of resources with custom names. The CloudFormation template does this when it creates certain resources with names that make it easier to identify them. The other acknowledgement is requested because of the nested stack that is created to deploy the Macie Activity Generator. CloudFormation will now begin to create the resources. Refresh the browser window to view the progress. This takes about five minutes. Notice that CloudFormation creates two stacks. In addition to the main stack, CloudFormation also builds a nested stack whose name contains the string MacieSetup. This nested stack is used to run the Macie Activity Generator. Wait until the Status value for the esslab stack shows CREATE_COMPLETE . You can refresh the browser window to update the status. Click on the dropdown below to learn more. Click here to expand We use a nested CloudFormation stack to run the Macie Activity Generator as mentioned earlier. After the nexted stack build is completed, the CloudFormation template launches an Amazon EC2 instance that wil be used as a target for Amazon Inspector and as a means to launch other services. The EC2 instance will then: Create an Amazon GuardDuty detector. Generate GuardDuty sample findings. Associate the Amazon S3 bucket created by the Macie Activity Generator to Amazon Macie so Macie will begin to process it. Initiate an Amazon Inspector assessment run. The assessment takes about 15-20 minutes to complete. Note that there at times may be no findings. This is typically the case when a new AMI is released. Take a look at the outputs for the esslab CloudFormation stack. They will look similar to the picture below. The output value assigned to LoggingBucketName is the name of the bucket into which AWS CloudTrail will deliver its logs. The value assigned to SecAdministratorRoleURL is a URL that you will use later in the lab to temporarily \"switch to\" (meaning take on the access privileges of) a Securty Administrator role. This role has full administrative privileges for AWS CloudTrail, Amazon GuardDuty, Amazon Inspector, and Amazon Macie. The value assigned to SecOperatorRoleURL is a URL that you will use later in the lab to temporarily \"switch to\" a Securty Operator role. You will later modify the policy associated with this role so it only has \"read only\" privileges for AWS CloudTrail, Amazon GuardDuty, Amazon Inspector, and Amazon Macie. Let's take a look at CloudTrail logging. The most important part of collecting AWS CloudTrail information into an Amazon S3 bucket is setting the correct permissions on the Amazon S3 bucket. Go to the S3 console, select the value assigned to LoggingBucketName , click on Permissions , and then Click on Bucket Policy . Note that the policy allows the CloudTrail service to read the ACL of the LoggingBucket and also to create logs with prefixes containing the AWS account ID. you can read more about this policy at this link . Go to the S3 console, select LoggingBucketName . Now click the Overview tab and then click the AWSLogs folder prefix. You should then see the AWS account ID of your account as shown below. This shows that AWS CloudTrail logs for your account have started to make their way to the S3 bucket. It may take up to five minutes for logs to start appearing. Switching to the Security Administrator role You are now going to learn about how to switch to a new role in the AWS console. Switching to a new role allows you to temporarily substitute your AWS console permissions for those contained in another role. In this lab, you will be switching to roles that are in your own AWS account. You can also switch to roles in other AWS accounts to gain access to resources in accounts other than your own. This is known as cross-account access . You will not be doing cross-account access in this lab. The CloudFormation stack you just built created two roles. One role is for a Security Administrator who has full access to CloudTrail, GuardDuty, Inspector, and Macie. The other role is for a Security Operator who, after changes you make later on, will have read-only access to these services. You are going to switch to the Security Administrator role but before doing so, let's look at the privileges associated with that role so you can see what it does. Go to the IAM console, select Roles on the left and search for the string SecAdmininistrator . Click on the role that you retrieve. The policy definition will be similar to the image below. There are five managed policies attached to this role, four of them are provided by AWS for GuardDuty, Inspector, CloudTrail, and SNS. SNS is included because it provides for a better console experience. There is a fifth managed policy that was created for Amazon Macie to illustrate how custom managed poicies can be developed. Feel free to click on each of the managed policies to see the underlying privileges of each. In particular, notice that no other services such as Amazon EC2 are listed. Go to the CloudFormation console and view the outputs tab of the CloudFormation stack named esslab you just built. Click on the URL next to SecAdministratorRoleURL. A new browser tab window will appear showing information similar to the image below. The box contains the account ID (which is the ID of your AWS account), a role name that was created by CloudFormation, and a Display Name. You can also select a color that will be used to display the role you assume in the console. Click Switch Role . You will now see a new role label named SecAdministrator in the top of your console window as shown below. This means that your effective privileges have been temporarily replaced with those of the SecAdministrator role. Go to the Amazon EC2 console. Notice that you are able to go to the console regardless of your permissions. The AWS console is a \"wrapper\" around the underlying EC2 APIs. Not having EC2 permissions doesn't prevent you from going to the console but you will be unable to do anything once you are in that console. Notice the error message below. Now go to the Amazon Inspector Console. Click Assessment Runs and check the box to the left of the instance and click Run . You have just launched an new assessment run which requires administrative access. Now go to the GuardDuty console. Notice that you are in the console and that you can see the GuardDuty Detector ID. You do, however, have an error message at the top as shown below. While your permissions give you full access to the GuardDuty service, the console tries to display information about the service role that GuardDuty uses. This requires IAM permissions that you do not have. To verify that you do have administrative capabilities, scroll down to the field named Updated findings and change the value to Send notification every 1 hour and click Save settings at the bottom of the window (you may need to scroll down further). You will see a message at the top of your window (you may need to scroll up) saying that the settings have been saved. This shows you do have full access to GuardDuty (but not IAM). Go to the Macie console, select the US West (Oregon) region, and click on the Content Type icon. You will see a list of file types appear. Pick a file type such as application/cap , edit it and change the value of the Enabled flag to No - disabled . This shows that you have administrative access to Macie. Close the Macie window. Go back to the console session that you had for GuardDuty and from there go to the CloudTrail console. Select the trail whose name begins with esslab . Toggle the Logging switch to off. You will be asked to confirm. Click Continue . Now toggle Logging back to ON. This shows that you have administrative access to CloudTrail. Now that you have confirmed that you have administrative access to Inspector, Macie, GuardDuty, and CloudTrail, you no longer need your temporary permissions. Click on the SecAdministrator label and select Back to on the bottom right of the menu as shown below. Also note that the console maintains a role history to make it easier for you to switch back to the SecAdministrator role later. After you switch back to your regular role the special role label for SecAdministrator is no longer displayed. Refine the Security Operator role permissions Now that you know how to switch to the Security Administrator role, you are going to make some changes to the permissions for the Security Operator role so that it only has read-only access to Macie, GuardDuty, Inspector, and CloudTrail. Go to the IAM console, select Roles and search for SecOperator . Click on the resulting role that you see. The role will have permissions similar to those shown in the picture below. Notice that there are once again five managed policies, four AWS-managed policies for Inspector, GuardDuty, CloudTrail, and SNS, and a custom managed policy for Macie. The managed policies for Inspector, GuardDuty, and CloudTrail still provide full access to the services. The SNS policy has already been changed to provide read-only access to SNS. The Macie policy (whose name contains SecOperatorMaciePolicy ), despite its name, still provides full access to Macie. Remove the AmazonInspectorFullAccess, AmazonGuardDutyFullAccess, and Amazon InspectorFullAccess policies by click on the removal crosses as shown by the arrows. Add read-only access policies for Inspector, CloudTrail, and GuardDuty. Also modify the SecOperatorMacie policy so that it provides read-only access to Macie. If you need some hints, open the dropdown below. Click here to expand Here are some links that offer information that may be helpful to you. Controlling access to Amazon CloudTrail Controlling access to Amazon GuardDuty Controlling access to Amazon Inspector Controlling access to Amazon Macie Go to the CloudFormation console and view the outputs tab of the CloudFormation stack named esslab you just built. Click on the URL next to SecOperatorRoleURL. A new browser tab window will appear showing information similar to the image below. The box contains the account ID (which is the ID of your AWS account), a role name that was created by CloudFormation, and a Display Name. You can also select a color that will be used to display the role you assume in the console. Click Switch Role . You will now see a new role label named SecAdministrator in the top of your console window as shown below. This means that your effective privileges have been temporarily replaced with those of the SecOperator role. Now go to the Amazon Inspector Console. Click Assessment Runs and check the box to the left of the instance and click Run . After several seconds you will see an error message telling you that you are not authorized to call the StartAssessmentRun action. This is because you have read-only access to Inspector. Now go to the GuardDuty Console and try to modify the Updated findings field. You will see an error message telling you that you are not authorized to perform the UpdateDetector action. This is because you have read-only access to GuardDuty. Go to the Macie console, select the US West (Oregon) region, click on Settings and click on the Content Type icon. You will see a list of file types appear. Pick a file type such as application/cap , edit it and change the value of the Enabled flag and click Save. You will receive an error message because you have read-only access to Macie. Close the Macie window. Go back to the console session that you had for GuardDuty and from there go to the CloudTrail console. Select the trail whose name begins with esslab . Toggle the Logging switch to off. You will be asked to confirm. Click Continue . You will receive an error message because you have read-only access to CloudTrail. Now switch back to your default role. After you to this the SecOperator role label will no longer appear on your console. If you doing this workshop as part of a team, you will pass your account credentials to another team that will verify the configuration of your roles. Click here to proceed to the Verify Phase.","title":"Build Phase"},{"location":"workshops/identity-round-robin/ess/build/#external-security-services-round-build-phase","text":"IMPORTANT NOTE! Please make sure you have followed the instructions in the instructions in the scenario section before continuing below.","title":"External Security Services Round (Build Phase)"},{"location":"workshops/identity-round-robin/ess/build/#sign-in-to-aws","text":"Depending on how you're doing this workshop, expand one of the following dropdowns to sign into AWS. AWS-sponsored event In a separate tab in your web browser, go to the URL provided to you and login. After you login click the AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for the Management console . Click on that and you will be taken to the AWS console. Individual or an event not sponsored by AWS In a separate tab in your web browser, go to https://aws.amazon.com/console and log into your account.","title":"Sign in to AWS"},{"location":"workshops/identity-round-robin/ess/build/#enable-macie","text":"Before we build out our environment, you must make sure Amazon Macie is running. Select Macie from the main console. Macie will open in a new browser tab. Select the us-west-2 (Oregon) region. When the Macie console appears, if a Getting Started button appears, it means that Amazon Macie is disabled. In that case, click Getting Started , confirm that US West (Oregon) is selected as the region, and click Enable Macie . Close the browser tab containing the Macie console.","title":"Enable Macie"},{"location":"workshops/identity-round-robin/ess/build/#build-out-the-environment","text":"Return to the AWS Console, sigining into the account again if necessary. Open the Deploy to AWS link that follows in a new browser tab to deploy the logging environment in the us-west-2 region: In the new browser tab that you just opened, you will see the Select Template page. Click Next . On the Specify Details/Parameters page, the values have been filled in for you. Click Next . On the Options page, click Next . On the Review page, check both of the I acknowledge boxes and click Create . One acknowledgement is requested because of the creation of resources with custom names. The CloudFormation template does this when it creates certain resources with names that make it easier to identify them. The other acknowledgement is requested because of the nested stack that is created to deploy the Macie Activity Generator. CloudFormation will now begin to create the resources. Refresh the browser window to view the progress. This takes about five minutes. Notice that CloudFormation creates two stacks. In addition to the main stack, CloudFormation also builds a nested stack whose name contains the string MacieSetup. This nested stack is used to run the Macie Activity Generator. Wait until the Status value for the esslab stack shows CREATE_COMPLETE . You can refresh the browser window to update the status. Click on the dropdown below to learn more. Click here to expand We use a nested CloudFormation stack to run the Macie Activity Generator as mentioned earlier. After the nexted stack build is completed, the CloudFormation template launches an Amazon EC2 instance that wil be used as a target for Amazon Inspector and as a means to launch other services. The EC2 instance will then: Create an Amazon GuardDuty detector. Generate GuardDuty sample findings. Associate the Amazon S3 bucket created by the Macie Activity Generator to Amazon Macie so Macie will begin to process it. Initiate an Amazon Inspector assessment run. The assessment takes about 15-20 minutes to complete. Note that there at times may be no findings. This is typically the case when a new AMI is released. Take a look at the outputs for the esslab CloudFormation stack. They will look similar to the picture below. The output value assigned to LoggingBucketName is the name of the bucket into which AWS CloudTrail will deliver its logs. The value assigned to SecAdministratorRoleURL is a URL that you will use later in the lab to temporarily \"switch to\" (meaning take on the access privileges of) a Securty Administrator role. This role has full administrative privileges for AWS CloudTrail, Amazon GuardDuty, Amazon Inspector, and Amazon Macie. The value assigned to SecOperatorRoleURL is a URL that you will use later in the lab to temporarily \"switch to\" a Securty Operator role. You will later modify the policy associated with this role so it only has \"read only\" privileges for AWS CloudTrail, Amazon GuardDuty, Amazon Inspector, and Amazon Macie. Let's take a look at CloudTrail logging. The most important part of collecting AWS CloudTrail information into an Amazon S3 bucket is setting the correct permissions on the Amazon S3 bucket. Go to the S3 console, select the value assigned to LoggingBucketName , click on Permissions , and then Click on Bucket Policy . Note that the policy allows the CloudTrail service to read the ACL of the LoggingBucket and also to create logs with prefixes containing the AWS account ID. you can read more about this policy at this link . Go to the S3 console, select LoggingBucketName . Now click the Overview tab and then click the AWSLogs folder prefix. You should then see the AWS account ID of your account as shown below. This shows that AWS CloudTrail logs for your account have started to make their way to the S3 bucket. It may take up to five minutes for logs to start appearing.","title":"Build out the environment"},{"location":"workshops/identity-round-robin/ess/build/#switching-to-the-security-administrator-role","text":"You are now going to learn about how to switch to a new role in the AWS console. Switching to a new role allows you to temporarily substitute your AWS console permissions for those contained in another role. In this lab, you will be switching to roles that are in your own AWS account. You can also switch to roles in other AWS accounts to gain access to resources in accounts other than your own. This is known as cross-account access . You will not be doing cross-account access in this lab. The CloudFormation stack you just built created two roles. One role is for a Security Administrator who has full access to CloudTrail, GuardDuty, Inspector, and Macie. The other role is for a Security Operator who, after changes you make later on, will have read-only access to these services. You are going to switch to the Security Administrator role but before doing so, let's look at the privileges associated with that role so you can see what it does. Go to the IAM console, select Roles on the left and search for the string SecAdmininistrator . Click on the role that you retrieve. The policy definition will be similar to the image below. There are five managed policies attached to this role, four of them are provided by AWS for GuardDuty, Inspector, CloudTrail, and SNS. SNS is included because it provides for a better console experience. There is a fifth managed policy that was created for Amazon Macie to illustrate how custom managed poicies can be developed. Feel free to click on each of the managed policies to see the underlying privileges of each. In particular, notice that no other services such as Amazon EC2 are listed. Go to the CloudFormation console and view the outputs tab of the CloudFormation stack named esslab you just built. Click on the URL next to SecAdministratorRoleURL. A new browser tab window will appear showing information similar to the image below. The box contains the account ID (which is the ID of your AWS account), a role name that was created by CloudFormation, and a Display Name. You can also select a color that will be used to display the role you assume in the console. Click Switch Role . You will now see a new role label named SecAdministrator in the top of your console window as shown below. This means that your effective privileges have been temporarily replaced with those of the SecAdministrator role. Go to the Amazon EC2 console. Notice that you are able to go to the console regardless of your permissions. The AWS console is a \"wrapper\" around the underlying EC2 APIs. Not having EC2 permissions doesn't prevent you from going to the console but you will be unable to do anything once you are in that console. Notice the error message below. Now go to the Amazon Inspector Console. Click Assessment Runs and check the box to the left of the instance and click Run . You have just launched an new assessment run which requires administrative access. Now go to the GuardDuty console. Notice that you are in the console and that you can see the GuardDuty Detector ID. You do, however, have an error message at the top as shown below. While your permissions give you full access to the GuardDuty service, the console tries to display information about the service role that GuardDuty uses. This requires IAM permissions that you do not have. To verify that you do have administrative capabilities, scroll down to the field named Updated findings and change the value to Send notification every 1 hour and click Save settings at the bottom of the window (you may need to scroll down further). You will see a message at the top of your window (you may need to scroll up) saying that the settings have been saved. This shows you do have full access to GuardDuty (but not IAM). Go to the Macie console, select the US West (Oregon) region, and click on the Content Type icon. You will see a list of file types appear. Pick a file type such as application/cap , edit it and change the value of the Enabled flag to No - disabled . This shows that you have administrative access to Macie. Close the Macie window. Go back to the console session that you had for GuardDuty and from there go to the CloudTrail console. Select the trail whose name begins with esslab . Toggle the Logging switch to off. You will be asked to confirm. Click Continue . Now toggle Logging back to ON. This shows that you have administrative access to CloudTrail. Now that you have confirmed that you have administrative access to Inspector, Macie, GuardDuty, and CloudTrail, you no longer need your temporary permissions. Click on the SecAdministrator label and select Back to on the bottom right of the menu as shown below. Also note that the console maintains a role history to make it easier for you to switch back to the SecAdministrator role later. After you switch back to your regular role the special role label for SecAdministrator is no longer displayed.","title":"Switching to the Security Administrator role"},{"location":"workshops/identity-round-robin/ess/build/#refine-the-security-operator-role-permissions","text":"Now that you know how to switch to the Security Administrator role, you are going to make some changes to the permissions for the Security Operator role so that it only has read-only access to Macie, GuardDuty, Inspector, and CloudTrail. Go to the IAM console, select Roles and search for SecOperator . Click on the resulting role that you see. The role will have permissions similar to those shown in the picture below. Notice that there are once again five managed policies, four AWS-managed policies for Inspector, GuardDuty, CloudTrail, and SNS, and a custom managed policy for Macie. The managed policies for Inspector, GuardDuty, and CloudTrail still provide full access to the services. The SNS policy has already been changed to provide read-only access to SNS. The Macie policy (whose name contains SecOperatorMaciePolicy ), despite its name, still provides full access to Macie. Remove the AmazonInspectorFullAccess, AmazonGuardDutyFullAccess, and Amazon InspectorFullAccess policies by click on the removal crosses as shown by the arrows. Add read-only access policies for Inspector, CloudTrail, and GuardDuty. Also modify the SecOperatorMacie policy so that it provides read-only access to Macie. If you need some hints, open the dropdown below. Click here to expand Here are some links that offer information that may be helpful to you. Controlling access to Amazon CloudTrail Controlling access to Amazon GuardDuty Controlling access to Amazon Inspector Controlling access to Amazon Macie Go to the CloudFormation console and view the outputs tab of the CloudFormation stack named esslab you just built. Click on the URL next to SecOperatorRoleURL. A new browser tab window will appear showing information similar to the image below. The box contains the account ID (which is the ID of your AWS account), a role name that was created by CloudFormation, and a Display Name. You can also select a color that will be used to display the role you assume in the console. Click Switch Role . You will now see a new role label named SecAdministrator in the top of your console window as shown below. This means that your effective privileges have been temporarily replaced with those of the SecOperator role. Now go to the Amazon Inspector Console. Click Assessment Runs and check the box to the left of the instance and click Run . After several seconds you will see an error message telling you that you are not authorized to call the StartAssessmentRun action. This is because you have read-only access to Inspector. Now go to the GuardDuty Console and try to modify the Updated findings field. You will see an error message telling you that you are not authorized to perform the UpdateDetector action. This is because you have read-only access to GuardDuty. Go to the Macie console, select the US West (Oregon) region, click on Settings and click on the Content Type icon. You will see a list of file types appear. Pick a file type such as application/cap , edit it and change the value of the Enabled flag and click Save. You will receive an error message because you have read-only access to Macie. Close the Macie window. Go back to the console session that you had for GuardDuty and from there go to the CloudTrail console. Select the trail whose name begins with esslab . Toggle the Logging switch to off. You will be asked to confirm. Click Continue . You will receive an error message because you have read-only access to CloudTrail. Now switch back to your default role. After you to this the SecOperator role label will no longer appear on your console. If you doing this workshop as part of a team, you will pass your account credentials to another team that will verify the configuration of your roles. Click here to proceed to the Verify Phase.","title":"Refine the Security Operator role permissions"},{"location":"workshops/identity-round-robin/ess/verify/","text":"External Security Services Round (Verify Phase) IMPORTANT NOTE! Please make sure you have followed the instructions in the instructions in the scenario section and the build phase before continuing below. The Verification Challenge: Test how the environment was built In the previous phase, you tested the environment that you built. Your goal in this section is to evaluate the security of the environments that were built by another team . Depending on how you're doing this workshop, expand one of the following dropdowns to sign in to AWS. AWS-sponsored event In a separate tab in your web browser, go to the URL provided to you and login. After you login click the AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for the Management console . Click on that and you will be taken to the AWS console. Individual or an event not sponsored by AWS In a separate tab in your web browser, go to https://aws.amazon.com/console and log into your account. Verify the Security Operator role Go to the CloudFormation console and view the outputs tab of the CloudFormation stack named esslab you just built. Click on the URL next to SecOperatorRoleURL. A new browser tab window will appear showing information similar to the image below. The box contains the account ID (which is the ID of your AWS account), a role name that was created by CloudFormation, and a Display Name. You can also select a color that will be used to display the role you assume in the console. Click Switch Role . You will now see a new role label named SecAdministrator in the top of your console window as shown below. This means that your effective privileges have been temporarily replaced with those of the SecOperator role. Now go to the Amazon Inspector Console. Click Assessment Runs and check the box to the left of the instance and click Run . After several seconds you will see an error message telling you that you are not authorized to call the StartAssessmentRun action. This is because you have read-only access to Inspector. Now go to the GuardDuty Console and try to modify the Updated findings field. You will see an error message telling you that you are not authorized to perform the UpdateDetector action. This is because you have read-only access to GuardDuty. Go to the Macie console, select the us-west-2 region, click on Settings and click on the Content Type icon. You will see a list of file types appear. Pick a file type such as application/cap , edit it and change the value of the Enabled flag and click Save. You will receive an error message because you have read-only access to Macie. Close the Macie window. Go back to the console session that you had for GuardDuty and from there go to the CloudTrail console. Select the trail whose name begins with esslab . Toggle the Logging switch to off. You will be asked to confirm. Click Continue . You will receive an error message because you have read-only access to CloudTrail. Now switch back to your default role. After you to this the SecOperator role label will no longer appear on your console. Discuss your findings Discuss any variances you find and share them with the team that built the environment. Clean Up In order to prevent charges to your account we recommend cleaning up the infrastructure that was created, especially if you are doing other Identity rounds. Expand one of the following dropdowns and follow the instructions: AWS Sponsored Event No cleanup required! The responsibility falls to AWS. Individual or an event not sponsored by AWS Follow the steps below to remove the core componenets. Delete the main (not the nested) CloudFormation stack . This will in turn delete the nested stack that represents the Macie Activity Generator. Wait until both the main and nested CloudFormation stacks have been deleted. Disable Amazon Macie . Disable Amazon GuardDuty . Delete the logging bucket . Congratulations on completing the External Security Services round!","title":"Verify Phase"},{"location":"workshops/identity-round-robin/ess/verify/#external-security-services-round-verify-phase","text":"IMPORTANT NOTE! Please make sure you have followed the instructions in the instructions in the scenario section and the build phase before continuing below.","title":"External Security Services Round (Verify Phase)"},{"location":"workshops/identity-round-robin/ess/verify/#the-verification-challenge-test-how-the-environment-was-built","text":"In the previous phase, you tested the environment that you built. Your goal in this section is to evaluate the security of the environments that were built by another team . Depending on how you're doing this workshop, expand one of the following dropdowns to sign in to AWS. AWS-sponsored event In a separate tab in your web browser, go to the URL provided to you and login. After you login click the AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for the Management console . Click on that and you will be taken to the AWS console. Individual or an event not sponsored by AWS In a separate tab in your web browser, go to https://aws.amazon.com/console and log into your account.","title":"The Verification Challenge:  Test how the environment was built"},{"location":"workshops/identity-round-robin/ess/verify/#verify-the-security-operator-role","text":"Go to the CloudFormation console and view the outputs tab of the CloudFormation stack named esslab you just built. Click on the URL next to SecOperatorRoleURL. A new browser tab window will appear showing information similar to the image below. The box contains the account ID (which is the ID of your AWS account), a role name that was created by CloudFormation, and a Display Name. You can also select a color that will be used to display the role you assume in the console. Click Switch Role . You will now see a new role label named SecAdministrator in the top of your console window as shown below. This means that your effective privileges have been temporarily replaced with those of the SecOperator role. Now go to the Amazon Inspector Console. Click Assessment Runs and check the box to the left of the instance and click Run . After several seconds you will see an error message telling you that you are not authorized to call the StartAssessmentRun action. This is because you have read-only access to Inspector. Now go to the GuardDuty Console and try to modify the Updated findings field. You will see an error message telling you that you are not authorized to perform the UpdateDetector action. This is because you have read-only access to GuardDuty. Go to the Macie console, select the us-west-2 region, click on Settings and click on the Content Type icon. You will see a list of file types appear. Pick a file type such as application/cap , edit it and change the value of the Enabled flag and click Save. You will receive an error message because you have read-only access to Macie. Close the Macie window. Go back to the console session that you had for GuardDuty and from there go to the CloudTrail console. Select the trail whose name begins with esslab . Toggle the Logging switch to off. You will be asked to confirm. Click Continue . You will receive an error message because you have read-only access to CloudTrail. Now switch back to your default role. After you to this the SecOperator role label will no longer appear on your console.","title":"Verify the Security Operator role"},{"location":"workshops/identity-round-robin/ess/verify/#discuss-your-findings","text":"Discuss any variances you find and share them with the team that built the environment.","title":"Discuss your findings"},{"location":"workshops/identity-round-robin/ess/verify/#clean-up","text":"In order to prevent charges to your account we recommend cleaning up the infrastructure that was created, especially if you are doing other Identity rounds. Expand one of the following dropdowns and follow the instructions: AWS Sponsored Event No cleanup required! The responsibility falls to AWS. Individual or an event not sponsored by AWS Follow the steps below to remove the core componenets. Delete the main (not the nested) CloudFormation stack . This will in turn delete the nested stack that represents the Macie Activity Generator. Wait until both the main and nested CloudFormation stacks have been deleted. Disable Amazon Macie . Disable Amazon GuardDuty . Delete the logging bucket . Congratulations on completing the External Security Services round!","title":"Clean Up"},{"location":"workshops/identity-round-robin/permission-boundaries/","text":"Permission boundaries round Your customer has deployed a three tier web application in production. Different teams work on different aspects of the architecture but they don't always communicate well. Just recently the team responsible for the web front end set up a Lambda function that inadvertently impacted the application team's resources. The VP of Operations was furious. The VP has tasked you with setting up permissions for the web admins so that they can only impact they own resources while still being able to do their job. AWS Service/Feature Coverage : AWS IAM permission boundaries AWS IAM identifiers or resource restrictions AWS IAM users roles AWS Lambda Agenda The round is broken down into first a BUILD phase followed by a VERIFY phase. BUILD (60 min): First each team will carry out the activities involved in the BUILD phase where they will set up access for the web admins and properly lock down the account. Then each team will hand credentials for an IAM user in their account to another team to act in the VERIFY phase. The VERIFY phase lasts about 30 min. VERIFY (30 min): Each team will carry out the VERIFY activities as if they were part of the web admins team. The VERIFY activities will include validating that the requirements were set up correctly in the BUILD phase and also investigate if the web admins are able to take actions that they shouldn't be allowed to. Team or Individual Exercise This workshop can be done as a team exercise or individually. The instructions are written with assumption that you are working as part of a team but you could just as easily do the steps below on your own. If done as part of an AWS sponsored event then you'll be split into teams of around 4-6 people. Each team will do the BUILD phase and then hand off their accounts to another team. Then each team will do the VERIFY phase. Using this workshop as an example, the three elements of a permission boundary are represented below. When your team does the BUILD tasks you will act as the admin. When your team does the VERIFY tasks you will act as the delegated admin. The delegated admins will create roles that can be considered \"bound\" since they will have permission boundaries attached. Presentation If you are doing this workshop as part of an AWS event then there will usually be a 30 minute presentation before the hands on work. Here is the presentation deck . Setup Instructions To setup your environment please expand one of the following dropdowns (depending on how if you are doing this workshop at an AWS event or individually ) and follow the instructions: AWS Sponsored Event Console Login: if you are attending this workshop at an official AWS event then your team should have the URL and login credentials for your account. This will allow you to login to the account using AWS SSO. Browse to that URL and login. After you login click AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for Management console . Click on that and you will be taken the AWS console. Make sure the region is set to Ohio (us-east-2) CloudFormation: Launch the CloudFormation stack below to setup the environment: Region Deploy US East 2 (Ohio) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. Click Next on the Select Template section. Click Next on the Specify Details section (the stack name will be prefilled - you can change it or leave it as is) Click Next on the Options section. Finally, acknowledge that the template will create IAM roles under Capabilitie and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE . Individual Log in to your account however you would normally CloudFormation: Launch the CloudFormation stack below to setup the environment: Region Deploy US East 2 (Ohio) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. Click Next on the Select Template section. Click Next on the Specify Details section (the stack name will be prefilled - you can change it or leave it as is) Click Next on the Options section. Finally, acknowledge that the template will create IAM roles under Capabilitie and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE . Requirements Click here for the account architecture Account architecture: There are many teams working in this AWS account, including the web admins and the application admins. The ulimate goal of this workshop is to set up the web admins so they can create a Lambda function to read an S3 bucket while making sure they are not able to impact the resources of other teams. The web admins should only have access to the following resources: IAM policies and roles created by the web admins Lambda functions created by the web admins S3 buckets: The web admins are allowed to have read access to the bucket that starts with \"identitywksp-web-admins-applicat-rs3elbaccesslogs-\" and full access to the bucket that starts with \" The web admins should not be able to impact any resources in the account that they do not own including IAM users, groups, roles, S3 buckets, etc. Click here to go to the BUILD phase","title":"Scenario"},{"location":"workshops/identity-round-robin/permission-boundaries/#permission-boundaries-round","text":"Your customer has deployed a three tier web application in production. Different teams work on different aspects of the architecture but they don't always communicate well. Just recently the team responsible for the web front end set up a Lambda function that inadvertently impacted the application team's resources. The VP of Operations was furious. The VP has tasked you with setting up permissions for the web admins so that they can only impact they own resources while still being able to do their job. AWS Service/Feature Coverage : AWS IAM permission boundaries AWS IAM identifiers or resource restrictions AWS IAM users roles AWS Lambda","title":"Permission boundaries round"},{"location":"workshops/identity-round-robin/permission-boundaries/#agenda","text":"The round is broken down into first a BUILD phase followed by a VERIFY phase. BUILD (60 min): First each team will carry out the activities involved in the BUILD phase where they will set up access for the web admins and properly lock down the account. Then each team will hand credentials for an IAM user in their account to another team to act in the VERIFY phase. The VERIFY phase lasts about 30 min. VERIFY (30 min): Each team will carry out the VERIFY activities as if they were part of the web admins team. The VERIFY activities will include validating that the requirements were set up correctly in the BUILD phase and also investigate if the web admins are able to take actions that they shouldn't be allowed to. Team or Individual Exercise This workshop can be done as a team exercise or individually. The instructions are written with assumption that you are working as part of a team but you could just as easily do the steps below on your own. If done as part of an AWS sponsored event then you'll be split into teams of around 4-6 people. Each team will do the BUILD phase and then hand off their accounts to another team. Then each team will do the VERIFY phase. Using this workshop as an example, the three elements of a permission boundary are represented below. When your team does the BUILD tasks you will act as the admin. When your team does the VERIFY tasks you will act as the delegated admin. The delegated admins will create roles that can be considered \"bound\" since they will have permission boundaries attached.","title":"Agenda"},{"location":"workshops/identity-round-robin/permission-boundaries/#presentation","text":"If you are doing this workshop as part of an AWS event then there will usually be a 30 minute presentation before the hands on work. Here is the presentation deck .","title":"Presentation"},{"location":"workshops/identity-round-robin/permission-boundaries/#setup-instructions","text":"To setup your environment please expand one of the following dropdowns (depending on how if you are doing this workshop at an AWS event or individually ) and follow the instructions: AWS Sponsored Event Console Login: if you are attending this workshop at an official AWS event then your team should have the URL and login credentials for your account. This will allow you to login to the account using AWS SSO. Browse to that URL and login. After you login click AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for Management console . Click on that and you will be taken the AWS console. Make sure the region is set to Ohio (us-east-2) CloudFormation: Launch the CloudFormation stack below to setup the environment: Region Deploy US East 2 (Ohio) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. Click Next on the Select Template section. Click Next on the Specify Details section (the stack name will be prefilled - you can change it or leave it as is) Click Next on the Options section. Finally, acknowledge that the template will create IAM roles under Capabilitie and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE . Individual Log in to your account however you would normally CloudFormation: Launch the CloudFormation stack below to setup the environment: Region Deploy US East 2 (Ohio) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. Click Next on the Select Template section. Click Next on the Specify Details section (the stack name will be prefilled - you can change it or leave it as is) Click Next on the Options section. Finally, acknowledge that the template will create IAM roles under Capabilitie and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE .","title":"Setup Instructions"},{"location":"workshops/identity-round-robin/permission-boundaries/#requirements","text":"Click here for the account architecture Account architecture: There are many teams working in this AWS account, including the web admins and the application admins. The ulimate goal of this workshop is to set up the web admins so they can create a Lambda function to read an S3 bucket while making sure they are not able to impact the resources of other teams. The web admins should only have access to the following resources: IAM policies and roles created by the web admins Lambda functions created by the web admins S3 buckets: The web admins are allowed to have read access to the bucket that starts with \"identitywksp-web-admins-applicat-rs3elbaccesslogs-\" and full access to the bucket that starts with \" The web admins should not be able to impact any resources in the account that they do not own including IAM users, groups, roles, S3 buckets, etc.","title":"Requirements"},{"location":"workshops/identity-round-robin/permission-boundaries/#click-here-to-go-to-the-build-phase","text":"","title":"Click here to go to the BUILD phase"},{"location":"workshops/identity-round-robin/permission-boundaries/build/","text":"Permission boundaries round Build Phase Below are a series of tasks to delegate permissions to the web admins. In these tasks you will be creating smaller policies and testing them. In Task 5 you will combine these policies together into one permission policy. You should create each policy and test it before moving on to the next task. It helps to divide the team into people doing the tasks and people testing things out. So some of the members of the team will be logged in using SSO and following the instructions in the tasks while other members will be logged in as the webadmin user (created in Task 1 below) to test out the work done in each task. Task 1 Create an IAM user and an IAM policy with permission to create customer managed policies Build an IAM policy so that web admins can create customer managed policies. They should only be able to edit the policies they create (no other managed policies). We will not be using inline policies for this exercise. \"In most cases, we recommend that you use managed policies instead of inline policies.\" Attention As you use the provided IAM policy hints in each task, keep in mind where you need to add the account ID, correctly use the resource restrictions and change the region specified if needed (although if you are taking this as part of an AWS event, please use the Ohio region or us-east-2.) Missing any of these items can cause issues with your policies Walk Through Begin by navigating to the IAM console . First you will grab the AWS account ID. On the first screen you see in the IAM console (which should be the Dashboard) you will see an IAM users sign-in link . Copy that link because you will need the account ID in the URL for the policies and you will need the entire URL when you hand this account to another team for the VERIFY phase. Click Users on the left menu and create a new IAM user named webadmin . Check AWS Management Console access and then either autogenerate a password or set a custom password. Uncheck Require password reset . Attach the AWS managed policies IAMReadOnlyAccess AWSLambdaReadOnlyAccess to the user. Next click Policies on the left menu. Create a new IAM policy based on the hint below. Attach this policy to the IAM user you created. Hint IAM Identifiers : You will want to use either naming or pathing resource restrictions in the IAM policy. The question marks \" ???? \" in the resource element below should be replaced with something that could act as a resource restriction. Examine the existing resources (roles, Lambda functions) to make sure the policy will give access to existing resources owned by the web admins. Replacing the question marks is really the key to this round. { Version : 2012-10-17 , Statement : [ { Sid : CreateCustomerManagedPolicies , Effect : Allow , Action : [ iam:CreatePolicy , iam:DeletePolicy , iam:CreatePolicyVersion , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : arn:aws:iam::ACCOUNT_ID:policy/???? } ] } You should login with the webadmin IAM user (using a different browser) to verify the user can create a policy (while following the resource restriction.) Use the IAM users sign-in link you gathered earlier to login. The permissions assigned to the policy do not matter for the test. Question Why are we using resource restrictions here? There are two ways of doing resource restrictions: naming and pathing. Which option allows you to create policies using both the AWS Console and CLI? Is there an advantage to using the option that requires you to edit polices via the CLI? Task 2 Create an IAM policy with permission to create IAM roles Build an IAM policy so that the web admins can create IAM roles (which they will use for AWS Lambda functions.) Web admins should be able to attach to these roles existing AWS and customer managed policies. The web admins should only be able to edit the roles they create, not any other roles. Walk Through Create a new IAM policy based on the hint below. Attach this policy to the webadmin user created in Task 1 . Hint IAM Identifiers : The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. Examine the existing resources (roles, Lambda functions) to make sure the policy will give access to existing resources owned by the web admins. It is recommended to use the same resource restriction throughout this phase to simplify the policies. { Version : 2012-10-17 , Statement : [ { Sid : CreateRoles , Effect : Allow , Action : [ iam:CreateRole , iam:UpdateRole , iam:DeleteRole , iam:AttachRolePolicy , iam:DetachRolePolicy ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/???? ] } ] } From the browser where you are logged into the console as the webadmin , verify you can create a role (while following the resource restriction.) This role should use Lambda as the trusted entity (we will use this role to test the next task). The policy attached to the role do not matter at this point. Question Why do resource restriction matter for roles? Task 3 IAM policy to create Lambda functions The web admins can now create IAM policies and roles, so the next step is to give them permissions to create Lambda functions. They should be able to attach only IAM roles they created to the Lambda functions. In addition they should only be able to edit the Lambda functions they create, no other Lambda functions. Walk Through Create a new IAM policy based on the hint below. Attach this policy to the webadmin user. Hint IAM Identifiers : The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : LambdaFullAccesswithResourceRestrictions , Effect : Allow , Action : lambda:* , Resource : arn:aws:lambda:us-east-2:ACCOUNT_ID:function:???? }, { Sid : PassRoletoLambda , Effect : Allow , Action : iam:PassRole , Resource : arn:aws:iam::ACCOUNT_ID:role/???? , Condition : { StringLikeIfExists : { iam:PassedToService : lambda.amazonaws.com } } }, { Sid : AdditionalPermissionsforLambda , Effect : Allow , Action : [ kms:ListAliases , logs:Describe* , logs:ListTagsLogGroup , logs:FilterLogEvents , logs:GetLogEvents ], Resource : * } ] } Again from the browser where you are logged into the console as the webadmin , verify the user can create a lambda function (while following the resource restriction.) Question The scenario where you have admins in an account that need to be able to create IAM polices, roles and Lambda functions is common. The ability to restrict the permissions of the roles attached to the Lambda functions is relatively new though and important to proper least privilege administration. How was this situation handled before permission boundaries came along? Why do we not allow the web admins to attach any role to Lambda functions? Why do we let the admins only pass IAM roles they create to Lambda functions? Are resource restrictions in this case of Lambda function creation really necessary? Task 4 Create a permission boundary We have policies now so that the web admins can create and edit customer managed policies, roles and Lambda functions. We need to limit the permissions of the roles they create though. If not then the web admins could simply create new policies with full admin rights, attach these to the roles, pass these roles to Lambda functions and escalate their permissions (either intentitionally or inadventently). We will use permission boundaries to limits the effective permissions of the roles. The permission boundary should allow the following effective permissions for any role created by the web admins: i. Create log groups (but can not overwrite any other log groups) ii. Create log streams and put logs iii. List the objects from the S3 bucket name that starts with \"identitywksp-web-admins-applicat-rs3elbaccesslogs\" Walk Through: Create a new IAM policy that will act as the permission boundary for the web admins. Name the policy webadminpermissionboundary Hint IAM Identifiers : The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateLogGroup , Effect : Allow , Action : logs:CreateLogGroup , Resource : arn:aws:logs:us-east-2:ACCOUNT_ID:* }, { Sid : CreateLogStreamandEvents , Effect : Allow , Action : [ logs:CreateLogStream , logs:PutLogEvents ], Resource : arn:aws:logs:us-east-2:ACCOUNT_ID:log-group:/aws/lambda/????:* }, { Sid : AllowedS3GetObject , Effect : Allow , Action : [ s3:List* ], Resource : arn:aws:s3:::web-admins-ACCOUNT_ID-* } ] } How could you test the permission boundary at this point? Question From the standpoint of the policy language and how it is presented in the console, how does a permission boundary differ from a standard IAM policy? Task 5 Create one permission policy that incorporate all of the preceding tasks and add a permission boundary condition Walk Through You have two options here: Combine the policies created so far and reference the permission boundary created in the previous step. Use the complete policy below (with the usual changes.) Note that the policy below contains two additional sections (last two sections in the full policy below) that we did not address in the earlier steps. The additions are focused on denying the ability to change or delete the permission policy or the permission boundary. Also the policy below includes the permission boundary conditions and a few other changes because not all actions support the permission boundary condition. Name the new policy webadminpermissionpolicy and attach it to the webadmin user. Remove the earlier policies you added during the testing. When you are done the webadmin user should have only three policies attached: webadminpermissionpolicy, IAMReadOnlyAccess AWSLambdaReadOnlyAccess. Hint Permission boundaries : The question marks ???? in the resource elements below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateCustomerManagedPolicies , Effect : Allow , Action : [ iam:CreatePolicy , iam:DeletePolicy , iam:CreatePolicyVersion , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : arn:aws:iam::ACCOUNT_ID:policy/???? }, { Sid : RoleandPolicyActionswithnoPermissionBoundarySupport , Effect : Allow , Action : [ iam:UpdateRole , iam:DeleteRole ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/???? ] }, { Sid : CreateRoles , Effect : Allow , Action : [ iam:CreateRole , iam:AttachRolePolicy , iam:DetachRolePolicy ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/???? ], Condition : { StringEquals : { iam:PermissionsBoundary : arn:aws:iam::ACCOUNT_ID:policy/webadminpermissionboundary } } }, { Sid : LambdaFullAccesswithResourceRestrictions , Effect : Allow , Action : lambda:* , Resource : arn:aws:lambda:us-east-2:ACCOUNT_ID:function:???? }, { Sid : PassRoletoLambda , Effect : Allow , Action : iam:PassRole , Resource : arn:aws:iam::ACCOUNT_ID:role/???? , Condition : { StringLikeIfExists : { iam:PassedToService : lambda.amazonaws.com } } }, { Sid : AdditionalPermissionsforLambda , Effect : Allow , Action : [ kms:ListAliases , logs:Describe* , logs:ListTagsLogGroup , logs:FilterLogEvents , logs:GetLogEvents ], Resource : * }, { Sid : DenyPermissionBoundaryandPolicyDeleteModify , Effect : Deny , Action : [ iam:CreatePolicyVersion , iam:DeletePolicy , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : [ arn:aws:iam::ACCOUNT_ID:policy/webadminpermissionboundary , arn:aws:iam::ACCOUNT_ID:policy/webadminpermissionpolicy ] }, { Sid : DenyRolePermissionBoundaryDelete , Effect : Deny , Action : iam:DeleteRolePermissionsBoundary , Resource : * } ] } Again from the browser where you are logged into the console as the webadmin , verify the user can create a policy, create a role (attaching both a permssion policy and permission boundary to the role) and finally create a Lambda function into which you will pass that role. All of the preceding steps need to be done will also following the resource restrictions. Question \"Why do we add the Deny for DeletePolicy actions?\" \"What would happen if we didn't deny the ability to delete permission boundaries?\" Task 6 Gather info needed for the VERIFY phase Walk Through Now that you have setup the IAM user for the web admins, it's time to pass this information on to the next team who will work through the VERIFY tasks. You need to gather some details about your setupo and then hand this info to the next team. Here are all of the details you need to pass to another team. If you following the recommended naming conventions than you can use the answers below. If you were given a form to fill out then enter the info into the form. This needs to be given to another team so they can do the VERIFY phase tasks. Your team should collect the VERIFY phase form from another team so you can also work through the VERIFY tasks. IAM users sign-in link: https://Account_ID.signin.aws.amazon.com/console IAM user name: webadmin IAM user password: Resource restriction identifier: Permission boundary name: webadminpermissionboundary Permission policy name: webadminpermissionpolicy Tip Do not hand out this info to the same team that is giving you the info - this way we will end up properly swapping between teams if we have an odd number of teams. Click here to go to the VERIFY phase","title":"Build Phase"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#permission-boundaries-round-build-phase","text":"Below are a series of tasks to delegate permissions to the web admins. In these tasks you will be creating smaller policies and testing them. In Task 5 you will combine these policies together into one permission policy. You should create each policy and test it before moving on to the next task. It helps to divide the team into people doing the tasks and people testing things out. So some of the members of the team will be logged in using SSO and following the instructions in the tasks while other members will be logged in as the webadmin user (created in Task 1 below) to test out the work done in each task.","title":"Permission boundaries round Build Phase"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#task-1-create-an-iam-user-and-an-iam-policy-with-permission-to-create-customer-managed-policies","text":"Build an IAM policy so that web admins can create customer managed policies. They should only be able to edit the policies they create (no other managed policies). We will not be using inline policies for this exercise. \"In most cases, we recommend that you use managed policies instead of inline policies.\" Attention As you use the provided IAM policy hints in each task, keep in mind where you need to add the account ID, correctly use the resource restrictions and change the region specified if needed (although if you are taking this as part of an AWS event, please use the Ohio region or us-east-2.) Missing any of these items can cause issues with your policies","title":"Task 1 Create an IAM user and an IAM policy with permission to create customer managed policies"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#walk-through","text":"Begin by navigating to the IAM console . First you will grab the AWS account ID. On the first screen you see in the IAM console (which should be the Dashboard) you will see an IAM users sign-in link . Copy that link because you will need the account ID in the URL for the policies and you will need the entire URL when you hand this account to another team for the VERIFY phase. Click Users on the left menu and create a new IAM user named webadmin . Check AWS Management Console access and then either autogenerate a password or set a custom password. Uncheck Require password reset . Attach the AWS managed policies IAMReadOnlyAccess AWSLambdaReadOnlyAccess to the user. Next click Policies on the left menu. Create a new IAM policy based on the hint below. Attach this policy to the IAM user you created. Hint IAM Identifiers : You will want to use either naming or pathing resource restrictions in the IAM policy. The question marks \" ???? \" in the resource element below should be replaced with something that could act as a resource restriction. Examine the existing resources (roles, Lambda functions) to make sure the policy will give access to existing resources owned by the web admins. Replacing the question marks is really the key to this round. { Version : 2012-10-17 , Statement : [ { Sid : CreateCustomerManagedPolicies , Effect : Allow , Action : [ iam:CreatePolicy , iam:DeletePolicy , iam:CreatePolicyVersion , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : arn:aws:iam::ACCOUNT_ID:policy/???? } ] } You should login with the webadmin IAM user (using a different browser) to verify the user can create a policy (while following the resource restriction.) Use the IAM users sign-in link you gathered earlier to login. The permissions assigned to the policy do not matter for the test. Question Why are we using resource restrictions here? There are two ways of doing resource restrictions: naming and pathing. Which option allows you to create policies using both the AWS Console and CLI? Is there an advantage to using the option that requires you to edit polices via the CLI?","title":"Walk Through"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#task-2-create-an-iam-policy-with-permission-to-create-iam-roles","text":"Build an IAM policy so that the web admins can create IAM roles (which they will use for AWS Lambda functions.) Web admins should be able to attach to these roles existing AWS and customer managed policies. The web admins should only be able to edit the roles they create, not any other roles.","title":"Task 2 Create an IAM policy with permission to create IAM roles"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#walk-through_1","text":"Create a new IAM policy based on the hint below. Attach this policy to the webadmin user created in Task 1 . Hint IAM Identifiers : The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. Examine the existing resources (roles, Lambda functions) to make sure the policy will give access to existing resources owned by the web admins. It is recommended to use the same resource restriction throughout this phase to simplify the policies. { Version : 2012-10-17 , Statement : [ { Sid : CreateRoles , Effect : Allow , Action : [ iam:CreateRole , iam:UpdateRole , iam:DeleteRole , iam:AttachRolePolicy , iam:DetachRolePolicy ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/???? ] } ] } From the browser where you are logged into the console as the webadmin , verify you can create a role (while following the resource restriction.) This role should use Lambda as the trusted entity (we will use this role to test the next task). The policy attached to the role do not matter at this point. Question Why do resource restriction matter for roles?","title":"Walk Through"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#task-3-iam-policy-to-create-lambda-functions","text":"The web admins can now create IAM policies and roles, so the next step is to give them permissions to create Lambda functions. They should be able to attach only IAM roles they created to the Lambda functions. In addition they should only be able to edit the Lambda functions they create, no other Lambda functions.","title":"Task 3 IAM policy to create Lambda functions"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#walk-through_2","text":"Create a new IAM policy based on the hint below. Attach this policy to the webadmin user. Hint IAM Identifiers : The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : LambdaFullAccesswithResourceRestrictions , Effect : Allow , Action : lambda:* , Resource : arn:aws:lambda:us-east-2:ACCOUNT_ID:function:???? }, { Sid : PassRoletoLambda , Effect : Allow , Action : iam:PassRole , Resource : arn:aws:iam::ACCOUNT_ID:role/???? , Condition : { StringLikeIfExists : { iam:PassedToService : lambda.amazonaws.com } } }, { Sid : AdditionalPermissionsforLambda , Effect : Allow , Action : [ kms:ListAliases , logs:Describe* , logs:ListTagsLogGroup , logs:FilterLogEvents , logs:GetLogEvents ], Resource : * } ] } Again from the browser where you are logged into the console as the webadmin , verify the user can create a lambda function (while following the resource restriction.) Question The scenario where you have admins in an account that need to be able to create IAM polices, roles and Lambda functions is common. The ability to restrict the permissions of the roles attached to the Lambda functions is relatively new though and important to proper least privilege administration. How was this situation handled before permission boundaries came along? Why do we not allow the web admins to attach any role to Lambda functions? Why do we let the admins only pass IAM roles they create to Lambda functions? Are resource restrictions in this case of Lambda function creation really necessary?","title":"Walk Through"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#task-4-create-a-permission-boundary","text":"We have policies now so that the web admins can create and edit customer managed policies, roles and Lambda functions. We need to limit the permissions of the roles they create though. If not then the web admins could simply create new policies with full admin rights, attach these to the roles, pass these roles to Lambda functions and escalate their permissions (either intentitionally or inadventently). We will use permission boundaries to limits the effective permissions of the roles. The permission boundary should allow the following effective permissions for any role created by the web admins: i. Create log groups (but can not overwrite any other log groups) ii. Create log streams and put logs iii. List the objects from the S3 bucket name that starts with \"identitywksp-web-admins-applicat-rs3elbaccesslogs\"","title":"Task 4 Create a permission boundary"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#walk-through_3","text":"Create a new IAM policy that will act as the permission boundary for the web admins. Name the policy webadminpermissionboundary Hint IAM Identifiers : The question marks ???? in the resource element below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateLogGroup , Effect : Allow , Action : logs:CreateLogGroup , Resource : arn:aws:logs:us-east-2:ACCOUNT_ID:* }, { Sid : CreateLogStreamandEvents , Effect : Allow , Action : [ logs:CreateLogStream , logs:PutLogEvents ], Resource : arn:aws:logs:us-east-2:ACCOUNT_ID:log-group:/aws/lambda/????:* }, { Sid : AllowedS3GetObject , Effect : Allow , Action : [ s3:List* ], Resource : arn:aws:s3:::web-admins-ACCOUNT_ID-* } ] } How could you test the permission boundary at this point? Question From the standpoint of the policy language and how it is presented in the console, how does a permission boundary differ from a standard IAM policy?","title":"Walk Through:"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#task-5-create-one-permission-policy-that-incorporate-all-of-the-preceding-tasks-and-add-a-permission-boundary-condition","text":"","title":"Task 5 Create one permission policy that incorporate all of the preceding tasks and add a permission boundary condition"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#walk-through_4","text":"You have two options here: Combine the policies created so far and reference the permission boundary created in the previous step. Use the complete policy below (with the usual changes.) Note that the policy below contains two additional sections (last two sections in the full policy below) that we did not address in the earlier steps. The additions are focused on denying the ability to change or delete the permission policy or the permission boundary. Also the policy below includes the permission boundary conditions and a few other changes because not all actions support the permission boundary condition. Name the new policy webadminpermissionpolicy and attach it to the webadmin user. Remove the earlier policies you added during the testing. When you are done the webadmin user should have only three policies attached: webadminpermissionpolicy, IAMReadOnlyAccess AWSLambdaReadOnlyAccess. Hint Permission boundaries : The question marks ???? in the resource elements below should be replaced with something that could act as a resource restriction. { Version : 2012-10-17 , Statement : [ { Sid : CreateCustomerManagedPolicies , Effect : Allow , Action : [ iam:CreatePolicy , iam:DeletePolicy , iam:CreatePolicyVersion , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : arn:aws:iam::ACCOUNT_ID:policy/???? }, { Sid : RoleandPolicyActionswithnoPermissionBoundarySupport , Effect : Allow , Action : [ iam:UpdateRole , iam:DeleteRole ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/???? ] }, { Sid : CreateRoles , Effect : Allow , Action : [ iam:CreateRole , iam:AttachRolePolicy , iam:DetachRolePolicy ], Resource : [ arn:aws:iam::ACCOUNT_ID:role/???? ], Condition : { StringEquals : { iam:PermissionsBoundary : arn:aws:iam::ACCOUNT_ID:policy/webadminpermissionboundary } } }, { Sid : LambdaFullAccesswithResourceRestrictions , Effect : Allow , Action : lambda:* , Resource : arn:aws:lambda:us-east-2:ACCOUNT_ID:function:???? }, { Sid : PassRoletoLambda , Effect : Allow , Action : iam:PassRole , Resource : arn:aws:iam::ACCOUNT_ID:role/???? , Condition : { StringLikeIfExists : { iam:PassedToService : lambda.amazonaws.com } } }, { Sid : AdditionalPermissionsforLambda , Effect : Allow , Action : [ kms:ListAliases , logs:Describe* , logs:ListTagsLogGroup , logs:FilterLogEvents , logs:GetLogEvents ], Resource : * }, { Sid : DenyPermissionBoundaryandPolicyDeleteModify , Effect : Deny , Action : [ iam:CreatePolicyVersion , iam:DeletePolicy , iam:DeletePolicyVersion , iam:SetDefaultPolicyVersion ], Resource : [ arn:aws:iam::ACCOUNT_ID:policy/webadminpermissionboundary , arn:aws:iam::ACCOUNT_ID:policy/webadminpermissionpolicy ] }, { Sid : DenyRolePermissionBoundaryDelete , Effect : Deny , Action : iam:DeleteRolePermissionsBoundary , Resource : * } ] } Again from the browser where you are logged into the console as the webadmin , verify the user can create a policy, create a role (attaching both a permssion policy and permission boundary to the role) and finally create a Lambda function into which you will pass that role. All of the preceding steps need to be done will also following the resource restrictions. Question \"Why do we add the Deny for DeletePolicy actions?\" \"What would happen if we didn't deny the ability to delete permission boundaries?\"","title":"Walk Through"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#task-6-gather-info-needed-for-the-verify-phase","text":"","title":"Task 6 Gather info needed for the VERIFY phase"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#walk-through_5","text":"Now that you have setup the IAM user for the web admins, it's time to pass this information on to the next team who will work through the VERIFY tasks. You need to gather some details about your setupo and then hand this info to the next team. Here are all of the details you need to pass to another team. If you following the recommended naming conventions than you can use the answers below. If you were given a form to fill out then enter the info into the form. This needs to be given to another team so they can do the VERIFY phase tasks. Your team should collect the VERIFY phase form from another team so you can also work through the VERIFY tasks. IAM users sign-in link: https://Account_ID.signin.aws.amazon.com/console IAM user name: webadmin IAM user password: Resource restriction identifier: Permission boundary name: webadminpermissionboundary Permission policy name: webadminpermissionpolicy Tip Do not hand out this info to the same team that is giving you the info - this way we will end up properly swapping between teams if we have an odd number of teams.","title":"Walk Through"},{"location":"workshops/identity-round-robin/permission-boundaries/build/#click-here-to-go-to-the-verify-phase","text":"","title":"Click here to go to the VERIFY phase"},{"location":"workshops/identity-round-robin/permission-boundaries/verify/","text":"Permission boundaries round VERIFY phase You are now in the VERIFY phase. It is time to put on the hat of the web admins and test out their access. First you verify that you are able to do what you should be allowed to do. With any remaining time, check if there are other resources in the account that you can access. You should have receieved from another team the following information: IAM users sign-in link: https://Account_ID.signin.aws.amazon.com/console IAM user name: webadmin IAM user password: Resource restriction identifier: Permission boundary name: webadminpermissionboundary Permission policy name: webadminpermissionpolicy The web admins (you) should only have access to the following resources: IAM policies and roles created by the web admins Lambda functions created by the web admins The web admins should not be able to impact any resources in the account that they do not own including IAM users, roles, S3 buckets, Lambda functions, etc. You will be setting up an IAM policy, an IAM role and a Lambda function. The Lambda function should be able to list files in an S3 bucket. This is how you will verify you are able to do what the web admins are allowed to do. Application architecture: Task 1 Create a customer managed IAM policy The first step is to create a customer managed IAM policy. This will set the permissions of the role that you will pass to a Lambda function. Since the function will be working with S3 and since the point of this is to show how permission boundaries work, use the following policy which grants basic Lambda logging permissions and S3 full access. Keep in mind the resource restrictions put in place which will require you to use a certain name for the policy. { Version : 2012-10-17 , Statement : [ { Effect : Allow , Action : [ logs:CreateLogGroup , logs:CreateLogStream , logs:PutLogEvents , s3:* ], Resource : * } ] } Task 2 Create an IAM role Next you will create an IAM Role. Choose Lambda as the service for this role. Attach the policy you just created and the permission boundary (which will most likely be named: webadminpermissionboundary ) Keep in mind the resource restrictions put in place which will require you to use a certain name for the role. Task 3 Create a Lambda function Finally you will create a Node.js 8.10 Lambda function using the code below and attach the IAM role you just created to it. You will need to replace \"WEB_ADMIN_BUCKET_NAME\" with the bucket from the account that begins with \"web-admins-\" . and ends in \"-data\" const AWS = require ( aws-sdk ); const s3 = new AWS . S3 (); exports . handler = async ( event ) = { console.log( Loading function ) ; const allKeys = [] ; await getKeys({ Bucket : WEB_ADMIN_BUCKET_NAME } , allKeys ); return allKeys ; } ; async function getKeys ( params , keys ) { const response = await s3.listObjectsV2(params).promise() ; response.Contents.forEach(obj = keys.push(obj.Key)) ; if (response.IsTruncated) { const newParams = Object.assign({ } , params ); newParams . ContinuationToken = response . NextContinuationToken ; await getKeys ( newParams , keys ); } } Test the Lambda function and make sure it is generating logs in CloudWatch logs and that it is able to list the objects in the bucket. In order to test you will need to create a test event. The parameters of the test do not matter. Task 4 Investigate if you are able to do anything else The final step is to determine if you can do anything else in the account. Can you impact any resources not owned by the web admins?","title":"Verify Phase"},{"location":"workshops/identity-round-robin/permission-boundaries/verify/#permission-boundaries-round-verify-phase","text":"You are now in the VERIFY phase. It is time to put on the hat of the web admins and test out their access. First you verify that you are able to do what you should be allowed to do. With any remaining time, check if there are other resources in the account that you can access. You should have receieved from another team the following information: IAM users sign-in link: https://Account_ID.signin.aws.amazon.com/console IAM user name: webadmin IAM user password: Resource restriction identifier: Permission boundary name: webadminpermissionboundary Permission policy name: webadminpermissionpolicy The web admins (you) should only have access to the following resources: IAM policies and roles created by the web admins Lambda functions created by the web admins The web admins should not be able to impact any resources in the account that they do not own including IAM users, roles, S3 buckets, Lambda functions, etc. You will be setting up an IAM policy, an IAM role and a Lambda function. The Lambda function should be able to list files in an S3 bucket. This is how you will verify you are able to do what the web admins are allowed to do. Application architecture:","title":"Permission boundaries round VERIFY phase"},{"location":"workshops/identity-round-robin/permission-boundaries/verify/#task-1-create-a-customer-managed-iam-policy","text":"The first step is to create a customer managed IAM policy. This will set the permissions of the role that you will pass to a Lambda function. Since the function will be working with S3 and since the point of this is to show how permission boundaries work, use the following policy which grants basic Lambda logging permissions and S3 full access. Keep in mind the resource restrictions put in place which will require you to use a certain name for the policy. { Version : 2012-10-17 , Statement : [ { Effect : Allow , Action : [ logs:CreateLogGroup , logs:CreateLogStream , logs:PutLogEvents , s3:* ], Resource : * } ] }","title":"Task 1 Create a customer managed IAM policy"},{"location":"workshops/identity-round-robin/permission-boundaries/verify/#task-2-create-an-iam-role","text":"Next you will create an IAM Role. Choose Lambda as the service for this role. Attach the policy you just created and the permission boundary (which will most likely be named: webadminpermissionboundary ) Keep in mind the resource restrictions put in place which will require you to use a certain name for the role.","title":"Task 2 Create an IAM role"},{"location":"workshops/identity-round-robin/permission-boundaries/verify/#task-3-create-a-lambda-function","text":"Finally you will create a Node.js 8.10 Lambda function using the code below and attach the IAM role you just created to it. You will need to replace \"WEB_ADMIN_BUCKET_NAME\" with the bucket from the account that begins with \"web-admins-\" . and ends in \"-data\" const AWS = require ( aws-sdk ); const s3 = new AWS . S3 (); exports . handler = async ( event ) = { console.log( Loading function ) ; const allKeys = [] ; await getKeys({ Bucket : WEB_ADMIN_BUCKET_NAME } , allKeys ); return allKeys ; } ; async function getKeys ( params , keys ) { const response = await s3.listObjectsV2(params).promise() ; response.Contents.forEach(obj = keys.push(obj.Key)) ; if (response.IsTruncated) { const newParams = Object.assign({ } , params ); newParams . ContinuationToken = response . NextContinuationToken ; await getKeys ( newParams , keys ); } } Test the Lambda function and make sure it is generating logs in CloudWatch logs and that it is able to list the objects in the bucket. In order to test you will need to create a test event. The parameters of the test do not matter.","title":"Task 3 Create a Lambda function"},{"location":"workshops/identity-round-robin/permission-boundaries/verify/#task-4-investigate-if-you-are-able-to-do-anything-else","text":"The final step is to determine if you can do anything else in the account. Can you impact any resources not owned by the web admins?","title":"Task 4 Investigate if you are able to do anything else"},{"location":"workshops/identity-round-robin/serverless/","text":"Serverless Round Welcome to the world of serverless! Now you may be asking yourself, What is serverless ? Well, it is an architecture paradigm that allows you to create your applications without provisioning or managing any servers. Sounds great, right? Organizations look at building serverless applications as a way of improving their scalability and reducing their operational overhead. The responsibility of the underlying infrastructure is shifted off your plate so you can spend more time focusing on building your applications. So with less infrastructure to manage you are no longer responsible for patching your operating systems and the attack surface you need to worry about has been significantly reduced. But with the use of serverless technologies comes other responsibility. When you hear the word serverless you may think specifically of AWS Lambda but it is important to remember that there are other services used within a serverless application and securing an application involves more than just securing your Lambda functions. In this round you will be focused on improving the identity controls of the WildRydes serverless application (which is borrowed from aws-serverless-workshops and retrofitted for the purposes of this round). You will get exposed to different identity concepts through the use of a variety of services such as AWS IAM , Amazon S3 , Amazon CloudFront , and Amazon Cognito . Upon completion you should have a better idea of how to use native AWS identity controls to improve the security posture of a serverless application. AWS Service/Feature Coverage : S3 Bucket Policies S3 ACLs CloudFront Origin Access Identities Cognito User Pools Cognito Hosted UI Agenda This round is broken down into a BUILD VERIFY phase. BUILD (60 min): The Build phase involves evaluating, implementing, and enhancing the identity controls of the WildRydes application based on a set of business level functional and non-functional requirements. VERIFY (15 min): The Verify phase involves putting on the hat of an end user and testing the controls you put in place to ensure the requirements were met. In addition you will also ensure that a systems administrator is still able to manage the resources. Team or Individual Exercise This workshop can be done as a team exercise or individually. The instructions are written with the assumption that you are working as part of a team but you could just as easily do the steps below individually. If done as part of an AWS sponsored event then you'll be split into teams of around 4-6 people. Each team will do the BUILD phase and then hand off their accounts to another team. Then each team will do the VERIFY phase. Presentation Workshop Presentation Powerpoint Environment setup To setup your environment please expand one of the following dropdown sections (depending on how you're doing this workshop) and follow the instructions: AWS Sponsored Event Browse to the URL provided to you and login. After you login click the AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for the Management console . Click on that and you will be taken to the AWS console. Individual Launch the CloudFormation stack below to setup the WildRydes application: Region Deploy US East 1 (N. Virginia) Click the Deploy to AWS button above (right click and open in a new tab). This will automatically take you to the console to run the template. Click Next on the Specify Template section. On the Specify Details step, add a Team Number and a validation AWS Account and then click Next . The Team Name is only relevant when running this as a team so that the Verify team can reach out to the Build team with any questions. The account will be the one the Verify team uses to validate the controls put in place during the BUILD phase. If you are doing both phases in a single AWS account and as an individual put whatever you want for the team name and the AWS account number for the account you are currently using. Click Next on the Options section. Finally, acknowledge that the template will create IAM roles under Capabilities and click Create**. This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE . WildRydes identity overhaul You just joined a new DevOps team who manages a suite of animal-based ride sharing applications. Given your security background you've been embedded on the team to take the lead on security related tasks, evangelize security best practices, and represent your team when interacting with your security organization. Recently, your team inherited a new application; WildRydes. View your application Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and click on WebsiteCloudFrontURL . As part of the hand off to your team, the product team shared their vision for the application and stated that future iterations will include more dynamic features. After doing an evaluation of the architecture you determined that the WildRydes application is a static website hosted in an S3 bucket. There is a CloudFront Distribution setup to be used as a content delivery network and a Cognito User Pool for user management. Current application architecture After thoroughly evaluating the architecture and doing a threat modeling exercise your team has identified a number of broken features and misconfigurations. It looks as though someone started putting in place certain security controls but were not able to fully implement them. These reviews resulted in the creation of a couple tasks that were added to the backlog for your team and given a high priority. Click Next to move on to the Build Phase !","title":"Scenario"},{"location":"workshops/identity-round-robin/serverless/#serverless-round","text":"Welcome to the world of serverless! Now you may be asking yourself, What is serverless ? Well, it is an architecture paradigm that allows you to create your applications without provisioning or managing any servers. Sounds great, right? Organizations look at building serverless applications as a way of improving their scalability and reducing their operational overhead. The responsibility of the underlying infrastructure is shifted off your plate so you can spend more time focusing on building your applications. So with less infrastructure to manage you are no longer responsible for patching your operating systems and the attack surface you need to worry about has been significantly reduced. But with the use of serverless technologies comes other responsibility. When you hear the word serverless you may think specifically of AWS Lambda but it is important to remember that there are other services used within a serverless application and securing an application involves more than just securing your Lambda functions. In this round you will be focused on improving the identity controls of the WildRydes serverless application (which is borrowed from aws-serverless-workshops and retrofitted for the purposes of this round). You will get exposed to different identity concepts through the use of a variety of services such as AWS IAM , Amazon S3 , Amazon CloudFront , and Amazon Cognito . Upon completion you should have a better idea of how to use native AWS identity controls to improve the security posture of a serverless application. AWS Service/Feature Coverage : S3 Bucket Policies S3 ACLs CloudFront Origin Access Identities Cognito User Pools Cognito Hosted UI","title":"Serverless Round"},{"location":"workshops/identity-round-robin/serverless/#agenda","text":"This round is broken down into a BUILD VERIFY phase. BUILD (60 min): The Build phase involves evaluating, implementing, and enhancing the identity controls of the WildRydes application based on a set of business level functional and non-functional requirements. VERIFY (15 min): The Verify phase involves putting on the hat of an end user and testing the controls you put in place to ensure the requirements were met. In addition you will also ensure that a systems administrator is still able to manage the resources. Team or Individual Exercise This workshop can be done as a team exercise or individually. The instructions are written with the assumption that you are working as part of a team but you could just as easily do the steps below individually. If done as part of an AWS sponsored event then you'll be split into teams of around 4-6 people. Each team will do the BUILD phase and then hand off their accounts to another team. Then each team will do the VERIFY phase.","title":"Agenda"},{"location":"workshops/identity-round-robin/serverless/#presentation","text":"Workshop Presentation Powerpoint","title":"Presentation"},{"location":"workshops/identity-round-robin/serverless/#environment-setup","text":"To setup your environment please expand one of the following dropdown sections (depending on how you're doing this workshop) and follow the instructions: AWS Sponsored Event Browse to the URL provided to you and login. After you login click the AWS Account box, then click on the Account ID displayed below that (the red box in the image.) You should see a link below that for the Management console . Click on that and you will be taken to the AWS console. Individual Launch the CloudFormation stack below to setup the WildRydes application: Region Deploy US East 1 (N. Virginia) Click the Deploy to AWS button above (right click and open in a new tab). This will automatically take you to the console to run the template. Click Next on the Specify Template section. On the Specify Details step, add a Team Number and a validation AWS Account and then click Next . The Team Name is only relevant when running this as a team so that the Verify team can reach out to the Build team with any questions. The account will be the one the Verify team uses to validate the controls put in place during the BUILD phase. If you are doing both phases in a single AWS account and as an individual put whatever you want for the team name and the AWS account number for the account you are currently using. Click Next on the Options section. Finally, acknowledge that the template will create IAM roles under Capabilities and click Create**. This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE .","title":"Environment setup"},{"location":"workshops/identity-round-robin/serverless/#wildrydes-identity-overhaul","text":"You just joined a new DevOps team who manages a suite of animal-based ride sharing applications. Given your security background you've been embedded on the team to take the lead on security related tasks, evangelize security best practices, and represent your team when interacting with your security organization. Recently, your team inherited a new application; WildRydes.","title":"WildRydes identity overhaul"},{"location":"workshops/identity-round-robin/serverless/#view-your-application","text":"Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and click on WebsiteCloudFrontURL . As part of the hand off to your team, the product team shared their vision for the application and stated that future iterations will include more dynamic features. After doing an evaluation of the architecture you determined that the WildRydes application is a static website hosted in an S3 bucket. There is a CloudFront Distribution setup to be used as a content delivery network and a Cognito User Pool for user management.","title":"View your application"},{"location":"workshops/identity-round-robin/serverless/#current-application-architecture","text":"After thoroughly evaluating the architecture and doing a threat modeling exercise your team has identified a number of broken features and misconfigurations. It looks as though someone started putting in place certain security controls but were not able to fully implement them. These reviews resulted in the creation of a couple tasks that were added to the backlog for your team and given a high priority. Click Next to move on to the Build Phase !","title":"Current application architecture"},{"location":"workshops/identity-round-robin/serverless/build/","text":"Serverless Round Build Phase Since you are championing the security tasks for your team, you pick up the two tasks for the WildRydes application. Please read through and complete the following tasks. Good Luck! Task 1 Reduce the attack surface of the origin Ensure the application serves content out through the CloudFront Distribution and that your end users can only access the application through CloudFront URLs and not Amazon S3 URLs. As part of this configuration your end users should not be able to affect the availability or integrity of the application. Key Security Benefits Obfuscates the S3 origin Forces traffic over HTTPS with custom certificates Adds DDoS protection to your application and enables the future use of AWS WAF and AWS Shield View the Existing Policy First, view the existing S3 bucket policy to see what permissions the previous engineers created. Go to the Amazon S3 console Click on the identity-wksp-serverless- ACCOUNT# >-us-east-1-wildrydes bucket. Click on the Permissions tab and then click on Bucket Policy . What's wrong with this policy? What does \"Principal\": \"*\" mean? Both \"Principal\": \"*\" and \"Principal\":{\"AWS\":\"*\"} grant permission to everyone (also referred to as anonymous access). Use caution when granting anonymous access to your S3 bucket. When you grant anonymous access, anyone in the world can access your bucket. We highly recommend that you never grant any kind of anonymous write access to your S3 bucket. Modify Principal Since the current bucket allows for anonymous access, you need to change this to only allow access from the CloudFront Distribution. Go to the Amazon CloudFront console. You should see a Web Distribution for the WildRydes web application. Click on Origin Access Identities in the left navigation. You should see an identity named Unicorn OAI . CloudFront Origin Access Identity An Origin Access Identity (OAI) is a special CloudFront identity that you can associate with a Distribution in order restrict access using AWS IAM. You can also find the OAI by viewing your Web Distribution Copy down the ID. Go back to the Amazon S3 console and open up the bucket policy. Replace the principal with the following and click save : Principal : { AWS : arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity OAI ID } , Info You could also use the canonical user id as the principal: \"CanonicalUser\": \" OAI S3CanonicalUserId \" Modify Actions Now that the principal is restricted to the identity associated with the CloudFront distribution you can take a closer look at the permissions. Go back to the Amazon S3 console and open up the bucket policy. Does CloudFront really need access to Delete Objects? The distribution is acting as a CDN for the static site so it only needs read access to the S3 bucket. Change the actions to ensure an end user can not affect the integrity of the site. Test the new bucket policy Now that the bucket policy has been updated, go validate that you can not access the website using an S3 URL. Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and click on WebsiteS3URL . Are you still able to access the site using the S3 URL? Solve the Mystery So you've modified the bucket policy to restrict access to read only actions from the CloudFront Distribution but for some reason you are still able to access the site using S3 URLs. Do some investigation into why this is the case and put in the additional control necessary to restrict the traffic. Tip What other access controls exist within S3? Look into the following resources: S3 Block Public Access (easiest) AWS IAM Policy Elements: NotPrincipal (hardest) Be sure to clear your cache when testing! Task 2 Set up application user management Set up user management for the application using Cognito User pools. To reduce the operational overhead of creating and maintaining forms and custom logic for authentication, the decision has been made to use the Cognito hosted-UI to integrate the application with the User Pool. As part of the user experience users should be able to sign themselves up, they should have to validate their email address, and be required to create a password that meets the password complexity requirements for applications set in your security standards. Password Complexity Requirements for Applications Minimum length of 10 characters Must include symbols Must include numbers Must include uppercase characters Must include lowercase characters Application Integration Requirements Implicit grant OAuth flow Scopes: email openid Upon successful authentication the user should be redirected to ride.html Configure User Pool Go to the Amazon Cognito console (us-east-1) Click on Manage User Pools and then click on the WildRydes pool. Click on Policies in the left navigation and modify the password policy, enable users to sign themselves up, and save your changes. Click on MFA and Verifications in the left navigation, enable email verification, and save your changes. Configure App Integration Click on App Client Settings in the left navigation and enter the following and click Save changes : Enabled Identity Providers: Cognito User Pool Callback URL: WebsiteCloudFrontURL>/ride.html Sign Out URL: WebsiteCloudFrontURL>/index.html Allowed OAuth Flows: Implicit Grant Allowed OAuth Scope: email openid Click on Domain Name in the left navigation, enter a unique domain name, and save your changes. Construct the Hosted-UI URL Now that your User Pool and App Integration have been configured you can construct the URL to allow users to sign-in via the Cognito Hosted Wed UI (built-in webpages for signing up and signing in your users). your_domain /login?response_type= code or token client_id= your_app_client_id redirect_uri= your_callback_url Tip Replace the values in (including the carrots) to the correct values. All can be found in your Cognito configuration. The response type is based on the OAuth flow. Reference Documentation Go to the S3 console and click on the bucket named: identity-wksp-serverless- ACCOUNT#>-us-east-1-wildrydes . Open index.html and add the hosted UI URL to the Giddy Up button. Upload index.html back to the S3 bucket. After you have completed these tasks you can move on to the Verify Phase. Warning If you are doing this as part of an AWS sponsored event STOP here and wait for further instructions on the hand off to the next team.","title":"Build Phase"},{"location":"workshops/identity-round-robin/serverless/build/#serverless-round-build-phase","text":"Since you are championing the security tasks for your team, you pick up the two tasks for the WildRydes application. Please read through and complete the following tasks. Good Luck!","title":"Serverless Round Build Phase"},{"location":"workshops/identity-round-robin/serverless/build/#task-1-reduce-the-attack-surface-of-the-origin","text":"Ensure the application serves content out through the CloudFront Distribution and that your end users can only access the application through CloudFront URLs and not Amazon S3 URLs. As part of this configuration your end users should not be able to affect the availability or integrity of the application. Key Security Benefits Obfuscates the S3 origin Forces traffic over HTTPS with custom certificates Adds DDoS protection to your application and enables the future use of AWS WAF and AWS Shield","title":"Task 1 Reduce the attack surface of the origin"},{"location":"workshops/identity-round-robin/serverless/build/#view-the-existing-policy","text":"First, view the existing S3 bucket policy to see what permissions the previous engineers created. Go to the Amazon S3 console Click on the identity-wksp-serverless- ACCOUNT# >-us-east-1-wildrydes bucket. Click on the Permissions tab and then click on Bucket Policy . What's wrong with this policy? What does \"Principal\": \"*\" mean? Both \"Principal\": \"*\" and \"Principal\":{\"AWS\":\"*\"} grant permission to everyone (also referred to as anonymous access). Use caution when granting anonymous access to your S3 bucket. When you grant anonymous access, anyone in the world can access your bucket. We highly recommend that you never grant any kind of anonymous write access to your S3 bucket.","title":"View the Existing Policy"},{"location":"workshops/identity-round-robin/serverless/build/#modify-principal","text":"Since the current bucket allows for anonymous access, you need to change this to only allow access from the CloudFront Distribution. Go to the Amazon CloudFront console. You should see a Web Distribution for the WildRydes web application. Click on Origin Access Identities in the left navigation. You should see an identity named Unicorn OAI . CloudFront Origin Access Identity An Origin Access Identity (OAI) is a special CloudFront identity that you can associate with a Distribution in order restrict access using AWS IAM. You can also find the OAI by viewing your Web Distribution Copy down the ID. Go back to the Amazon S3 console and open up the bucket policy. Replace the principal with the following and click save : Principal : { AWS : arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity OAI ID } , Info You could also use the canonical user id as the principal: \"CanonicalUser\": \" OAI S3CanonicalUserId \"","title":"Modify Principal"},{"location":"workshops/identity-round-robin/serverless/build/#modify-actions","text":"Now that the principal is restricted to the identity associated with the CloudFront distribution you can take a closer look at the permissions. Go back to the Amazon S3 console and open up the bucket policy. Does CloudFront really need access to Delete Objects? The distribution is acting as a CDN for the static site so it only needs read access to the S3 bucket. Change the actions to ensure an end user can not affect the integrity of the site.","title":"Modify Actions"},{"location":"workshops/identity-round-robin/serverless/build/#test-the-new-bucket-policy","text":"Now that the bucket policy has been updated, go validate that you can not access the website using an S3 URL. Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and click on WebsiteS3URL . Are you still able to access the site using the S3 URL?","title":"Test the new bucket policy"},{"location":"workshops/identity-round-robin/serverless/build/#solve-the-mystery","text":"So you've modified the bucket policy to restrict access to read only actions from the CloudFront Distribution but for some reason you are still able to access the site using S3 URLs. Do some investigation into why this is the case and put in the additional control necessary to restrict the traffic. Tip What other access controls exist within S3? Look into the following resources: S3 Block Public Access (easiest) AWS IAM Policy Elements: NotPrincipal (hardest) Be sure to clear your cache when testing!","title":"Solve the Mystery"},{"location":"workshops/identity-round-robin/serverless/build/#task-2-set-up-application-user-management","text":"Set up user management for the application using Cognito User pools. To reduce the operational overhead of creating and maintaining forms and custom logic for authentication, the decision has been made to use the Cognito hosted-UI to integrate the application with the User Pool. As part of the user experience users should be able to sign themselves up, they should have to validate their email address, and be required to create a password that meets the password complexity requirements for applications set in your security standards. Password Complexity Requirements for Applications Minimum length of 10 characters Must include symbols Must include numbers Must include uppercase characters Must include lowercase characters Application Integration Requirements Implicit grant OAuth flow Scopes: email openid Upon successful authentication the user should be redirected to ride.html","title":"Task 2 Set up application user management"},{"location":"workshops/identity-round-robin/serverless/build/#configure-user-pool","text":"Go to the Amazon Cognito console (us-east-1) Click on Manage User Pools and then click on the WildRydes pool. Click on Policies in the left navigation and modify the password policy, enable users to sign themselves up, and save your changes. Click on MFA and Verifications in the left navigation, enable email verification, and save your changes.","title":"Configure User Pool"},{"location":"workshops/identity-round-robin/serverless/build/#configure-app-integration","text":"Click on App Client Settings in the left navigation and enter the following and click Save changes : Enabled Identity Providers: Cognito User Pool Callback URL: WebsiteCloudFrontURL>/ride.html Sign Out URL: WebsiteCloudFrontURL>/index.html Allowed OAuth Flows: Implicit Grant Allowed OAuth Scope: email openid Click on Domain Name in the left navigation, enter a unique domain name, and save your changes.","title":"Configure App Integration"},{"location":"workshops/identity-round-robin/serverless/build/#construct-the-hosted-ui-url","text":"Now that your User Pool and App Integration have been configured you can construct the URL to allow users to sign-in via the Cognito Hosted Wed UI (built-in webpages for signing up and signing in your users). your_domain /login?response_type= code or token client_id= your_app_client_id redirect_uri= your_callback_url Tip Replace the values in (including the carrots) to the correct values. All can be found in your Cognito configuration. The response type is based on the OAuth flow. Reference Documentation Go to the S3 console and click on the bucket named: identity-wksp-serverless- ACCOUNT#>-us-east-1-wildrydes . Open index.html and add the hosted UI URL to the Giddy Up button. Upload index.html back to the S3 bucket. After you have completed these tasks you can move on to the Verify Phase. Warning If you are doing this as part of an AWS sponsored event STOP here and wait for further instructions on the hand off to the next team.","title":"Construct the Hosted-UI URL"},{"location":"workshops/identity-round-robin/serverless/verify/","text":"Serverless Round Verify Phase Now that the additional identity controls have been added to the application, you have been tasked with acting as an end user and manually testing to verify that the controls have been put in place correctly and that the requirements have been met. Login Instructions The Build team created a cross-account AWS IAM Role to allow you complete your testing and verification tasks. To complete your tasks switch roles in the AWS Management Console to this role. Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and copy down VerifyAWSAccount . Click your account drop down in the top right corner of the Management Console next to the bell (third from the right). Click on Switch Roles Enter the following information Account : VerifyAWSAccount # Role : identity-wksp-serverless-verify Display Name : Build Color : your choice Now that you are logged into the Build AWS account you can access find their application URLs in the CloudFormation stack Outputs. Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and use WebsiteCloudFrontURL and WebsiteS3URL . Verify Task 1 Ensure the application serves content out through the CloudFront Distribution and that your end users can only access the application through CloudFront URLs and not Amazon S3 URLs. As part of this configuration your end users should not be able to affect the availability or integrity of the application. Verification Checklist You can access the site through the CloudFront Distribution URL ( WebsiteCloudFrontURL>). You are restricted from accessing any of the application resources through S3 URLs ( WebsiteS3URL>). Try some deep links (e.g. WebsiteS3URL>/js/vendor/unicorn-icon) You can not delete or modify any of the application resources through the CloudFront Distribution. Try using something like curl or Postman to make requests with different HTTP verbs (e.g. Delete). Below is an example using curl: curl -i -X DELETE WebsiteCloudFrontURL /index.html Verify Task 2 Set up user management for the application using Cognito User pools. To reduce the operational overhead of creating and maintaining forms and custom logic for authentication, the decision has been made to use the Cognito hosted-UI to integrate the application with the User Pool. As part of the user experience users should be able to sign themselves up, they should have to validate their email address, and be required to create a password that meets the password complexity requirements for applications set in your security standards. Verification Checklist You are taken to the hosted UI when clicking on Giddy Up . You are able to sign your self up for the site. You are required to create a password with the following complexity: Minimum length of 10 characters Must include symbols Must include numbers Must include uppercase characters You are required to verify your email address. After authentication, you are redirected to ride.html and are presented with your JWT IdToken. Final Architecture Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created, especially if you are doing other Identity rounds. Expand one of the following dropdown sections and follow the instructions: AWS Sponsored Event No cleanup required! The responsibility falls to AWS. Individual You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete the Amazon Cognito Domain for the hosted-UI. Go to the Amazon Cognito console. Click on the WildRydes pool. On the left navigation under App Integration , click on Domain Name . Click Delete Click the acknowledgement checkbox and click Delete Delete the CloudFormation stack ( Identity-RR-Wksp-Serverless-Round ). Go to the AWS CloudFormation console. Select the appropriate stack. Select Action . Click Delete Stack . Congratulations on completing the Serverless Round!","title":"Verify Phase"},{"location":"workshops/identity-round-robin/serverless/verify/#serverless-round-verify-phase","text":"Now that the additional identity controls have been added to the application, you have been tasked with acting as an end user and manually testing to verify that the controls have been put in place correctly and that the requirements have been met.","title":"Serverless Round Verify Phase"},{"location":"workshops/identity-round-robin/serverless/verify/#login-instructions","text":"The Build team created a cross-account AWS IAM Role to allow you complete your testing and verification tasks. To complete your tasks switch roles in the AWS Management Console to this role. Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and copy down VerifyAWSAccount . Click your account drop down in the top right corner of the Management Console next to the bell (third from the right). Click on Switch Roles Enter the following information Account : VerifyAWSAccount # Role : identity-wksp-serverless-verify Display Name : Build Color : your choice Now that you are logged into the Build AWS account you can access find their application URLs in the CloudFormation stack Outputs. Open the Amazon CloudFormation console (us-east-1) Click on the Identity-RR-Wksp-Serverless-Round stack. Click on Outputs and use WebsiteCloudFrontURL and WebsiteS3URL .","title":"Login Instructions"},{"location":"workshops/identity-round-robin/serverless/verify/#verify-task-1","text":"Ensure the application serves content out through the CloudFront Distribution and that your end users can only access the application through CloudFront URLs and not Amazon S3 URLs. As part of this configuration your end users should not be able to affect the availability or integrity of the application. Verification Checklist You can access the site through the CloudFront Distribution URL ( WebsiteCloudFrontURL>). You are restricted from accessing any of the application resources through S3 URLs ( WebsiteS3URL>). Try some deep links (e.g. WebsiteS3URL>/js/vendor/unicorn-icon) You can not delete or modify any of the application resources through the CloudFront Distribution. Try using something like curl or Postman to make requests with different HTTP verbs (e.g. Delete). Below is an example using curl: curl -i -X DELETE WebsiteCloudFrontURL /index.html","title":"Verify Task 1"},{"location":"workshops/identity-round-robin/serverless/verify/#verify-task-2","text":"Set up user management for the application using Cognito User pools. To reduce the operational overhead of creating and maintaining forms and custom logic for authentication, the decision has been made to use the Cognito hosted-UI to integrate the application with the User Pool. As part of the user experience users should be able to sign themselves up, they should have to validate their email address, and be required to create a password that meets the password complexity requirements for applications set in your security standards. Verification Checklist You are taken to the hosted UI when clicking on Giddy Up . You are able to sign your self up for the site. You are required to create a password with the following complexity: Minimum length of 10 characters Must include symbols Must include numbers Must include uppercase characters You are required to verify your email address. After authentication, you are redirected to ride.html and are presented with your JWT IdToken.","title":"Verify Task 2"},{"location":"workshops/identity-round-robin/serverless/verify/#final-architecture","text":"","title":"Final Architecture"},{"location":"workshops/identity-round-robin/serverless/verify/#cleanup","text":"In order to prevent charges to your account we recommend cleaning up the infrastructure that was created, especially if you are doing other Identity rounds. Expand one of the following dropdown sections and follow the instructions: AWS Sponsored Event No cleanup required! The responsibility falls to AWS. Individual You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete the Amazon Cognito Domain for the hosted-UI. Go to the Amazon Cognito console. Click on the WildRydes pool. On the left navigation under App Integration , click on Domain Name . Click Delete Click the acknowledgement checkbox and click Delete Delete the CloudFormation stack ( Identity-RR-Wksp-Serverless-Round ). Go to the AWS CloudFormation console. Select the appropriate stack. Select Action . Click Delete Stack . Congratulations on completing the Serverless Round!","title":"Cleanup"},{"location":"workshops/threat-detection-remediation/","text":"Find All the Threats: AWS Threat Detection and Remediation This workshop is designed to help you get familiar with AWS Security services and learn how to use them to identify and remediate threats in your environment. You'll be working with services such as Amazon GuardDuty, Amazon Macie, Amazon Inspector, Amazon CloudWatch, AWS Lambda, AWS Systems Manager, AWS Config, and AWS CloudTrail. You will learn how to use these services to investigate threats during and after an attack, set up a notification and remediation pipeline, and add additional protections to improve the security posture of your environment. Scenario Your company is new to the cloud and has recently performed a lift-and-shift of your infrastructure for piloting purposes. You are a systems administrator and have been tasked with security monitoring within your AWS environment. As part of that maintenance you are also responsible for responding to any security event in your environment. Architecture overview For this Workshop you will have a single instance setup in the us-west-2 region. As this was a \u201clift-and-shift\u201d migration for piloting, you have yet to build redundancy into your application, so you have a single public-facing web server. The web server has access to the Internet Gateway through an Elastic Network Interface. Customers access your web server through a DNS entry pointing to the Elastic Network Interface. You store static content in an S3 bucket and use the VPC S3 Endpoint Gateway for access from the web server. Presentation deck Workshop Presentation Deck Region Please use the us-west-2 (Oregon) region for this workshop. Modules Environment Build and Configuration Attack Simulation Detection and Remediation Review and Discussion Total time: 2 hours","title":"Overview"},{"location":"workshops/threat-detection-remediation/#find-all-the-threats-aws-threat-detection-and-remediation","text":"This workshop is designed to help you get familiar with AWS Security services and learn how to use them to identify and remediate threats in your environment. You'll be working with services such as Amazon GuardDuty, Amazon Macie, Amazon Inspector, Amazon CloudWatch, AWS Lambda, AWS Systems Manager, AWS Config, and AWS CloudTrail. You will learn how to use these services to investigate threats during and after an attack, set up a notification and remediation pipeline, and add additional protections to improve the security posture of your environment.","title":"Find All the Threats: AWS Threat Detection and Remediation"},{"location":"workshops/threat-detection-remediation/#scenario","text":"Your company is new to the cloud and has recently performed a lift-and-shift of your infrastructure for piloting purposes. You are a systems administrator and have been tasked with security monitoring within your AWS environment. As part of that maintenance you are also responsible for responding to any security event in your environment.","title":"Scenario"},{"location":"workshops/threat-detection-remediation/#architecture-overview","text":"For this Workshop you will have a single instance setup in the us-west-2 region. As this was a \u201clift-and-shift\u201d migration for piloting, you have yet to build redundancy into your application, so you have a single public-facing web server. The web server has access to the Internet Gateway through an Elastic Network Interface. Customers access your web server through a DNS entry pointing to the Elastic Network Interface. You store static content in an S3 bucket and use the VPC S3 Endpoint Gateway for access from the web server.","title":"Architecture overview"},{"location":"workshops/threat-detection-remediation/#presentation-deck","text":"Workshop Presentation Deck","title":"Presentation deck"},{"location":"workshops/threat-detection-remediation/#region","text":"Please use the us-west-2 (Oregon) region for this workshop.","title":"Region"},{"location":"workshops/threat-detection-remediation/#modules","text":"Environment Build and Configuration Attack Simulation Detection and Remediation Review and Discussion Total time: 2 hours","title":"Modules"},{"location":"workshops/threat-detection-remediation/01-environment-setup/","text":"Module 1: Environment build and configuration In the first module you will be configuring detective and responsive controls for your environment. You'll be running the first of two CloudFormation templates which will automate the creation of some of these controls and then you will manually configure the rest. Deploy the AWS CloudFormation template To initiate the scenario and configure your environment you will need to run the module 1 CloudFormation template: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. On the Specify Details section enter the necessary parameters as shown below. Parameter Value Stack name ThreatDetectionWksp-Env-Setup Email Address A valid email address Once you have entered your parameters click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status as shown below. You will get an email from SNS asking you to confirm the Subscription. Confirm the subscription so you can receive email alerts from AWS services during the Workshop. Setup Amazon CloudWatch event rules and automatic response The CloudFormation template you just ran created three CloudWatch Event Rules for alerting and response purposes. The steps below will walk you through creating the final rule. After this you'll have rules in place to receive email notifications and trigger AWS Lambda functions to respond to threats. Below are steps to create this rule through the console but you can also find out more about doing it programmatically by reviewing the Amazon GuardDuty Documentation . Open the CloudWatch console (us-west-2) In the navigation pane on the left, under Events , click Rules What are the current Rules in place setup to do? Click Create Rule Under Event Pattern click Build event pattern to match events by service and select Custom event pattern in the drop down. Copy and paste in the custom event pattern below: { source : [ aws.guardduty ], detail : { type : [ UnauthorizedAccess:EC2/MaliciousIPCaller.Custom ] } } For Targets , click Add Target , select Lambda Function , and then select threat-detection-wksp-remediation-nacl . Click Configure details . On the Configure rule details screen fill out the Name and Description (suggestions below). Name: threat-detection-wksp-guardduty-finding-ec2-maliciousip Description: GuardDuty Finding: UnauthorizedAccess:EC2/MaliciousIPCaller.Custom Click Create rule . Optional: Consider examining the Lambda function to see what it does. Open the Lambda console . Click on the function named threat-detection-wksp-remediation-nacl What will the function do when invoked? What will the threat-detection-wksp-remediation-inspector functions do? Enable Amazon GuardDuty The next step is to enable Amazon GuardDuty, which will continuously monitor your environment for malicious or unauthorized behavior. Go to the Amazon GuardDuty console (us-west-2). Click the Get Started button. On the next screen click the Enable GuardDuty button. GuardDuty is now enabled and continuously monitoring your CloudTrail logs, VPC flow logs, and DNS Query logs for threats in your environment. Enable Amazon Macie Since you plan on storing sensitive data in S3, let\u2019s quickly enable Amazon Macie. Macie is a security service that will continuously monitor data access activity for anomalies and generate alerts when it detects risk of unauthorized access or inadvertent data leaks. Go to the Amazon Macie console (us-west-2). Click Get Started . Macie will create a service-linked role when you enable it. If you would like to see the permissions that the role will have you can click the View service role permissions . Click Enable Macie . Setup Amazon Macie for data discovery classification Macie is also used for automatically discovering and classifying sensitive data. Now that Macie is enabled, setup an integration to classify data in your S3 bucket. In the Amazon Macie console click on Integrations on the left navigation. Find your AWS account ID (there should be only one) and click Select Click Add then on the next screen click the check box next to the S3 bucket that ends with \u201c-data\u201d . Click Add Leave the options here at the default, click Review . On the next screen click Start Classification . Finally click Done . Macie is now enabled and has begun to discover, classify and protect your data. Enable AWS Security Hub Now that all of your detective controls have been configured you need to enable AWS Security Hub , which will provide you with a comprehensive view of the security and compliance of your AWS environment. Go to the AWS Security Hub console. Click the Enable Security Hub button. On the next screen click the Enable AWS Security Hub button. AWS Security Hub is now enabled and will begin collecting and aggregating findings from the security services we have enabled so far. Architecture overview Your environment is now configured and ready for operations. Below is a diagram to depict the detective controls you now have in place. After you have successfully setup your environment, you can proceed to the next module.","title":"Module 1: Environment Build"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#module-1-environment-build-and-configuration","text":"In the first module you will be configuring detective and responsive controls for your environment. You'll be running the first of two CloudFormation templates which will automate the creation of some of these controls and then you will manually configure the rest.","title":"Module 1: Environment build and configuration"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#deploy-the-aws-cloudformation-template","text":"To initiate the scenario and configure your environment you will need to run the module 1 CloudFormation template: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. On the Specify Details section enter the necessary parameters as shown below. Parameter Value Stack name ThreatDetectionWksp-Env-Setup Email Address A valid email address Once you have entered your parameters click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status as shown below. You will get an email from SNS asking you to confirm the Subscription. Confirm the subscription so you can receive email alerts from AWS services during the Workshop.","title":"Deploy the AWS CloudFormation template"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#setup-amazon-cloudwatch-event-rules-and-automatic-response","text":"The CloudFormation template you just ran created three CloudWatch Event Rules for alerting and response purposes. The steps below will walk you through creating the final rule. After this you'll have rules in place to receive email notifications and trigger AWS Lambda functions to respond to threats. Below are steps to create this rule through the console but you can also find out more about doing it programmatically by reviewing the Amazon GuardDuty Documentation . Open the CloudWatch console (us-west-2) In the navigation pane on the left, under Events , click Rules What are the current Rules in place setup to do? Click Create Rule Under Event Pattern click Build event pattern to match events by service and select Custom event pattern in the drop down. Copy and paste in the custom event pattern below: { source : [ aws.guardduty ], detail : { type : [ UnauthorizedAccess:EC2/MaliciousIPCaller.Custom ] } } For Targets , click Add Target , select Lambda Function , and then select threat-detection-wksp-remediation-nacl . Click Configure details . On the Configure rule details screen fill out the Name and Description (suggestions below). Name: threat-detection-wksp-guardduty-finding-ec2-maliciousip Description: GuardDuty Finding: UnauthorizedAccess:EC2/MaliciousIPCaller.Custom Click Create rule . Optional: Consider examining the Lambda function to see what it does. Open the Lambda console . Click on the function named threat-detection-wksp-remediation-nacl What will the function do when invoked? What will the threat-detection-wksp-remediation-inspector functions do?","title":"Setup Amazon CloudWatch event rules and automatic response"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#enable-amazon-guardduty","text":"The next step is to enable Amazon GuardDuty, which will continuously monitor your environment for malicious or unauthorized behavior. Go to the Amazon GuardDuty console (us-west-2). Click the Get Started button. On the next screen click the Enable GuardDuty button. GuardDuty is now enabled and continuously monitoring your CloudTrail logs, VPC flow logs, and DNS Query logs for threats in your environment.","title":"Enable Amazon GuardDuty"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#enable-amazon-macie","text":"Since you plan on storing sensitive data in S3, let\u2019s quickly enable Amazon Macie. Macie is a security service that will continuously monitor data access activity for anomalies and generate alerts when it detects risk of unauthorized access or inadvertent data leaks. Go to the Amazon Macie console (us-west-2). Click Get Started . Macie will create a service-linked role when you enable it. If you would like to see the permissions that the role will have you can click the View service role permissions . Click Enable Macie .","title":"Enable Amazon Macie"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#setup-amazon-macie-for-data-discovery-classification","text":"Macie is also used for automatically discovering and classifying sensitive data. Now that Macie is enabled, setup an integration to classify data in your S3 bucket. In the Amazon Macie console click on Integrations on the left navigation. Find your AWS account ID (there should be only one) and click Select Click Add then on the next screen click the check box next to the S3 bucket that ends with \u201c-data\u201d . Click Add Leave the options here at the default, click Review . On the next screen click Start Classification . Finally click Done . Macie is now enabled and has begun to discover, classify and protect your data.","title":"Setup Amazon Macie for data discovery &amp; classification"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#enable-aws-security-hub","text":"Now that all of your detective controls have been configured you need to enable AWS Security Hub , which will provide you with a comprehensive view of the security and compliance of your AWS environment. Go to the AWS Security Hub console. Click the Enable Security Hub button. On the next screen click the Enable AWS Security Hub button. AWS Security Hub is now enabled and will begin collecting and aggregating findings from the security services we have enabled so far.","title":"Enable AWS Security Hub"},{"location":"workshops/threat-detection-remediation/01-environment-setup/#architecture-overview","text":"Your environment is now configured and ready for operations. Below is a diagram to depict the detective controls you now have in place. After you have successfully setup your environment, you can proceed to the next module.","title":"Architecture overview"},{"location":"workshops/threat-detection-remediation/02-attack-simulation/","text":"Module 2: Attack Simulation Now that you have detective and responsive controls setup, you'll be running another CloudFormation template which will simulate the actual attack you will be investigating. Agenda Run the second CloudFormation template \u2013 5 min Threat detection and response presentation \u2013 25 min Deploy the CloudFormation template To initiate the attack simulation you will need to run the module 2 CloudFormation template: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. The name of the stack will be automatically populated but you are free to change it, after which click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and click Create This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status as shown below. Threat detection and response presentation Below is a diagram of the setup after the module 2 CloudFormation stack is created. If you are going through this workshop in a classroom setting then wait till the presentation is over before starting module 3 (the presentation will allow enough time to pass for the attack scenario to complete.) If you are going through this workshop outside of a classroom setting you can proceed to Module 3. Please note it will take at least 20 minutes after the 2nd CloudFormation template has completed before you will start seeing findings.","title":"Module 2: Attack Simulation"},{"location":"workshops/threat-detection-remediation/02-attack-simulation/#module-2-attack-simulation","text":"Now that you have detective and responsive controls setup, you'll be running another CloudFormation template which will simulate the actual attack you will be investigating. Agenda Run the second CloudFormation template \u2013 5 min Threat detection and response presentation \u2013 25 min","title":"Module 2: Attack Simulation"},{"location":"workshops/threat-detection-remediation/02-attack-simulation/#deploy-the-cloudformation-template","text":"To initiate the attack simulation you will need to run the module 2 CloudFormation template: Region Deploy US West 2 (Oregon) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. The name of the stack will be automatically populated but you are free to change it, after which click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and click Create This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status as shown below.","title":"Deploy the CloudFormation template"},{"location":"workshops/threat-detection-remediation/02-attack-simulation/#threat-detection-and-response-presentation","text":"Below is a diagram of the setup after the module 2 CloudFormation stack is created. If you are going through this workshop in a classroom setting then wait till the presentation is over before starting module 3 (the presentation will allow enough time to pass for the attack scenario to complete.) If you are going through this workshop outside of a classroom setting you can proceed to Module 3. Please note it will take at least 20 minutes after the 2nd CloudFormation template has completed before you will start seeing findings.","title":"Threat detection and response presentation"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/","text":"Module 3: Detect, Investigate Respond Unfortunately, due to a misconfiguration in your environment, an attacker may have been able to gain access to the web server. You are getting alerts from the security services you\u2019ve put in place indicating malicious activity. These alerts include communication with known malicious IP addresses, account reconnaissance, changes to an Amazon S3 bucket configuration, and disabling security configurations. You must identify what activity the intruder may have performed and how they did it so you can block the intruder\u2019s access, remediate the vulnerabilities, and restore the configuration to its proper state. Part 1 - Compromised AWS IAM credentials Detect and investigate By now you\u2019ve received email alerts from the security services you enabled. Now what? As part of your risk driven detection strategy your organization has decided to prioritize AWS IAM related findings. Sort through your email alerts and identity an alert related to an AWS IAM principals (e.g. Amazon GuardDuty Finding: UnauthorizedAccess:IAMUser/MaliciousIPCaller.Custom ). Copy the Access Key ID from the e-mail alert. Explore findings related to the access key (Amazon GuardDuty) Now that you have a resource identifier to go off of you can use Amazon GuardDuty to start doing some investigation into the findings. Go to the Amazon GuardDuty console (us-west-2). Click in the Add filter criteria box: Select Access Key ID . and then paste in the Access Key ID you copied from the e-mail. What findings do you see related to this access key ID? Click on one of the findings to see the details. Where did these credentials come from? Examining User type under Resource affected you can see that the access key referenced in this finding is from an IAM assumed role. Examining Principal ID under Resource affected you will find two strings separated by a colon. The first is the unique ID for the IAM role and the second is the EC2 instance ID. The Principal ID contains a unique ID for the entity making the API request, and when the request is made using temporary security credentials (which is what happens for an assume role call) it also includes a session name. In this case the session name is the EC2 instance ID since the assume role call was done using an IAM role for EC2. Copy the full Principal Id which contains both the unique ID of the role and the session name: \"principalId\": \" unique ID : session name \" Examine the User name under Resource affected . This corresponds to the name of the IAM role involved since the temp creds used to make the API call came from EC2 instance with an IAM role attached. How could you have found the IAM role name just using the unique ID found earlier? Respond Now that you have identified that a temporary security credential from an IAM role for EC2 is being used by an attacker, the decision has been made to rotate the credential immediately to prevent any further misuse or potential escalation of privilege. Revoke the IAM role sessions (IAM) Browse to the AWS IAM console. Click Roles and find the role you identified in the previous section (this is the role attached to the compromised instance). Click on the Revoke sessions tab. Click on Revoke active sessions . Click the acknowledgement check box and then click Revoke active sessions . What is the mechanism that is put in place by this step to actually prevent the use of the temporary security credentials issued by this role? Restart the EC2 instance to rotate the access keys (EC2) All active credentials for the compromised IAM role have been invalidated. This means the attacker can no longer use those access keys, but it also means that any applications that use this role can't as well. You knew this going in but decided it was necessary due to the high risk of a compromised IAM access key. In order to ensure the availability of your application you need to refresh the access keys on the instance by stopping and starting the instance. A simple reboot will not change the keys. If you waited the temporary security credential on the instance would be refreshed but this procedure will speed things up. Since you are using AWS Systems Manager for doing administration on your EC2 Instances you can use it to query the metadata to validate that the access keys were rotated after the rotation. In the EC2 console Stop the Instance named threat-detection-wksp: Compromised Instance . Wait for the Instance State to say stopped under Instance State (you may need to refresh the EC2 console) and then Start the instance. Verify the access keys have been rotated (Systems Manager) Go to AWS Systems Manager console and click on Session Manager on the left navigation and then click Start Session . You should see an instance named threat-detection-wksp: Compromised Instance with a Instance state of running . To see the credentials currently active on the instance, click on the radio button next to threat-detection-wksp: Compromised Instance and click Start Session . Run the following command in the shell: curl http://169.254.169.254/latest/meta-data/iam/security-credentials/threat-detection-wksp-compromised-ec2 Compare the access key ID to the one found in the email alerts to ensure it has changed. Why would this scenario be a good use case for auto-scaling groups and golden-image AMI\u2019s? At this point you've successfully revoked all the active sessions from AWS IAM role and rotated the temporary security credentials on the EC2 instance. Part 2 - Compromised EC2 instance Detect and investigate Now that you've addressed the compromised IAM credential you need focus in on how the attacker was able to compromise the EC2 instance. It's this compromise which allowed them to query the instance metadata and steal the credentials. Explore findings related to the instance ID (AWS Security Hub) When investigating the compromised IAM credential you discovered that it was from an IAM role for EC2 and identified the EC2 instance ID from the principal ID of the finding. Using the instance ID you can use AWS Security Hub to start investigating the findings. To start, you are going to research the GuardDuty findings related to the EC2 instance. Go to the AWS Security Hub console. The link should take you to the Findings section but if not, click on Findings in the navigation on the left. Click in the Add filter box: Scroll down to Resource ID , change the operator to CONTAINS and paste in the Instance ID you copied earlier (from the principal ID you gathered in the GuardDuty finding). Add another filter by again clicking in the Add filter box and scrolling down to Product Name , and paste in the word GuardDuty . What findings do you see related to this instance ID? One of the findings should indicate that the EC2 instance is communicating with an IP address on a threat list ( disallowed IP ) which adds further evidence to the conclusion that the instance has been compromised. The other finding should indicate that a system at a particular IP address is performing an SSH brute force attack against your instance. You now need to investigate if the SSH brute force attack was successful and if that is what allowed the attacker to gain access to the instance. Determine if ssh password authentication is enabled on the EC2 instance (AWS Security Hub) Automated responses to threats can do many things. For example, you could have an trigger that helps gather information about the threat that could then be used in the investigation by the security team. With that option in mind, we have a CloudWatch event rule in place that will trigger an Amazon Inspector scan of an EC2 instance when GuardDuty detects a particular attack. We will use AWS Security Hub to view the findings from Inspector. We want to determine if the SSH configuration adheres to best practices. Go to the AWS Security Hub console. The link should take you to the Findings section but if not, click on Findings in the navigation on the left. Click in the Add filter box: Scroll down to Title , change the operator to CONTAINS and paste in password authentication over SSH . In the results do you see a finding regarding SSH and password authentication for the instance that experienced the SSH brute force attack? If you do not see any findings after awhile, there may have been an issue with your Inspector agent. Go to the Inspector console, click on Assessment Templates , check the template that starts with threat-detection-wksp , and click Run . Please allow 15 minutes for the scan to complete. You can also look in Assessment runs and check the status . Feel free to continue through this module and check the results later on. Based on the findings you should see that password authentication over SSH is configured on the instance. In addition if you examine some of the other Inspector findings you will see that there are no password complexity restrictions. This means the instance is more susceptible to an SSH brute force attack. Determine if the attacker was able to login to the EC2 instance (CloudWatch logs) Now that we know that the instance was more susceptible to an SSH brute force attack, let\u2019s look at the CloudWatch logs and create a metric to see if there were any successful SSH logins (to finally answer the question of whether the SSH brute force attack was successful.) Your corporate policy is to send security certain logs from EC2 instances to CloudWatch. Go to CloudWatch logs . Click on the log group /threat-detection-wksp/var/log/secure If you have multiple log streams, filter using the Instance ID you copied earlier and click on the stream. Within the Filter Events text-box put the following Filter Pattern: [Mon, day, timestamp, ip, id, msg1= Invalid, msg2 = user, ...] Do you see any failed (invalid user) attempts to log into the instance? Would that be consistent with an SSH brute force attack? Now replace the Filter with one for successful attempts: [Mon, day, timestamp, ip, id, msg1= Accepted, msg2 = password, ...] Do you see any successful attempts to log into the instance? Which linux user was compromised? Respond Modify the EC2 security group (EC2) The active session from the attacker was automatically stopped by an update to the NACL on the subnet where the instance resides. This was done by a CloudWatch event rule trigger that is invoked based on certain GuardDuty findings. A good next step would be to modify the security group associated with the EC2 instance to prevent the attacker or anyone else from connecting from a different source IP. Go to the Amazon EC2 Console. Find the running instances with the name threat-detection-wksp: Compromised Instance . Under the Description tab, click on the Security Group for the compromised instance. View the rules under the Inbound tab. Click Edit and delete the inbound SSH rule. You've decided that all administration on EC2 Instances will be done through AWS Systems Manager so you no longer need this port open. In your initial setup you already installed the SSM Agent on your EC2 Instance. Click Save Part 3 - Compromised S3 bucket Detect and investigate Now that we know the SSH brute force attack was successful and we disabled the IAM credentials that were stolen, we need to determine if anything else occurred. One step we could take here is to examine the IAM policy attached the IAM role that generated the temp credentials. We notice in the policy that there are permissions relating to the Amazon S3 service so that is something to keep in mind as you continue the investigation. Truncated policy from the IAM role attached to the compromised EC2 instance: { Version : 2012-10-17 , Statement : [ { Action : s3:PutObject , Resource : arn:aws:s3:::threat-detection-wksp-ACCOUNT_ID-us-west-2-gd-threatlist/* , Effect : Allow }, { Action : [ s3:* ], Resource : arn:aws:s3:::threat-detection-wksp-ACCOUNT_ID-us-west-2-data/* , Effect : Allow }, { Action : [ s3:* ], Resource : arn:aws:s3:::threat-detection-wksp-ACCOUNT_ID-us-west-2-data , Effect : Allow } ] } Investigate any S3 related findings (AWS Security Hub) There are many ways to approach this next step. We are going to start with a Security Hub insight that may be helpful in situations like this. This is not the only way you could approach this but it can definitely save time initially as you investigate the full repercussions of an attack. Go to AWS Security Hub in the AWS Management Console. The link should take you to the Insights section but if not, click on Insights in the navigation on the left. Click in the Filter insights box and type Top S3 which will display the built in Insight \"Top S3 buckets by counts of findings.\" Click on that Insight. Which buckets are displayed? There should be one that with threat-detection-wksp- and ends in -data . Click on that. What do the findings show? This Security Hub Insight is one way of determining what an attacker may have done. It is not going to help in every situation though. What additional steps would you take to investigate what an attacker had done? Check if sensitive data was involved (Macie) At this point you know how the attacker was able to get into your systems and a general idea of what they did. In the previous step you determined that the S3 bucket that starts with threat-detection-wksp- and ends in -data has an ACL that grants global read rights. We will now check if there is any sensitive and business-critical data in any of the buckets (but especially that data bucket) and take a closer at the Macie Alerts. Go to the Amazon Macie in the AWS Management console. Look through the latest alerts. Do you see any critical alerts? Does this match what you found in Security Hub? Next lets verify what sort of sensitive data exists in that bucket. Click Dashboard on the left navigation. You should see the following data classifications: You can slide the risk slider to filter data classifications based on risk levels. Above the risk slider, click the icon for S3 public objects and buckets . The icon will be in the shape of a globe but you can also hover over the icons to find the right one. Click the magnifying glass to the left of the bucket name listed. Check if any of the data in the bucket is considered a high risk Look for the Object PII priority field and Object risk level field Verify if any of the data is unencrypted Look for the Object encryption field. (Does a portion of the blue bar indicate that encryption is set to none?) Respond Fix the permissions and encryption on the bucket (S3) In the previous step we determined that the S3 bucket that starts with threat-detection-wksp- and ends in -data has sensitive data and some of that data is unencrypted. We also know that the bucket grants global read rights. We need to manually fix these issues. Go to Amazon S3 in the AWS Management Console. First we will fix the permissions: Find the bucket that starts with threat-detection-wksp- and ends in -data Click on the Permissions tab then click on ACL Control List Under Public access click on the radio button next to Everyone . Uncheck List objects then click Save Now we need to fix the encryption: In the same bucket, click on the Properties tab then click on Default encryption Set the encryption to AWS-KMS. Select the aws/s3 key. Finally click Save . Do you know what impact you had on existing objects in the bucket by enabling Default encryption ? Congratulations! You have successfully remediated the incident and further hardened your environment. This is obviously a simulation and we can not cover every aspect of the response function in the short time allotted but hopefully this gave you an idea of the capabilities available on AWS to detect, investigate and respond to threats and attacks. Here is a diagram of the attack you just investigated. Numbers 1 2 show the SSH brute force attack and successful SSH login. Number 3 shows the S3 bucket changes the attacker made. Number 4 shows the API calls the attacker made with the IAM temporary credentials stolen from the compromised EC2 instance. If you are going through this workshop in a classroom setting then the instructor should start the module 4 presentation soon.","title":"Module 3: Detect & Respond"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#module-3-detect-investigate-respond","text":"Unfortunately, due to a misconfiguration in your environment, an attacker may have been able to gain access to the web server. You are getting alerts from the security services you\u2019ve put in place indicating malicious activity. These alerts include communication with known malicious IP addresses, account reconnaissance, changes to an Amazon S3 bucket configuration, and disabling security configurations. You must identify what activity the intruder may have performed and how they did it so you can block the intruder\u2019s access, remediate the vulnerabilities, and restore the configuration to its proper state.","title":"Module 3: Detect, Investigate &amp; Respond"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#part-1-compromised-aws-iam-credentials","text":"","title":"Part 1 - Compromised AWS IAM credentials"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#detect-and-investigate","text":"By now you\u2019ve received email alerts from the security services you enabled. Now what? As part of your risk driven detection strategy your organization has decided to prioritize AWS IAM related findings. Sort through your email alerts and identity an alert related to an AWS IAM principals (e.g. Amazon GuardDuty Finding: UnauthorizedAccess:IAMUser/MaliciousIPCaller.Custom ). Copy the Access Key ID from the e-mail alert. Explore findings related to the access key (Amazon GuardDuty) Now that you have a resource identifier to go off of you can use Amazon GuardDuty to start doing some investigation into the findings. Go to the Amazon GuardDuty console (us-west-2). Click in the Add filter criteria box: Select Access Key ID . and then paste in the Access Key ID you copied from the e-mail. What findings do you see related to this access key ID? Click on one of the findings to see the details. Where did these credentials come from? Examining User type under Resource affected you can see that the access key referenced in this finding is from an IAM assumed role. Examining Principal ID under Resource affected you will find two strings separated by a colon. The first is the unique ID for the IAM role and the second is the EC2 instance ID. The Principal ID contains a unique ID for the entity making the API request, and when the request is made using temporary security credentials (which is what happens for an assume role call) it also includes a session name. In this case the session name is the EC2 instance ID since the assume role call was done using an IAM role for EC2. Copy the full Principal Id which contains both the unique ID of the role and the session name: \"principalId\": \" unique ID : session name \" Examine the User name under Resource affected . This corresponds to the name of the IAM role involved since the temp creds used to make the API call came from EC2 instance with an IAM role attached. How could you have found the IAM role name just using the unique ID found earlier?","title":"Detect and investigate"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#respond","text":"Now that you have identified that a temporary security credential from an IAM role for EC2 is being used by an attacker, the decision has been made to rotate the credential immediately to prevent any further misuse or potential escalation of privilege. Revoke the IAM role sessions (IAM) Browse to the AWS IAM console. Click Roles and find the role you identified in the previous section (this is the role attached to the compromised instance). Click on the Revoke sessions tab. Click on Revoke active sessions . Click the acknowledgement check box and then click Revoke active sessions . What is the mechanism that is put in place by this step to actually prevent the use of the temporary security credentials issued by this role? Restart the EC2 instance to rotate the access keys (EC2) All active credentials for the compromised IAM role have been invalidated. This means the attacker can no longer use those access keys, but it also means that any applications that use this role can't as well. You knew this going in but decided it was necessary due to the high risk of a compromised IAM access key. In order to ensure the availability of your application you need to refresh the access keys on the instance by stopping and starting the instance. A simple reboot will not change the keys. If you waited the temporary security credential on the instance would be refreshed but this procedure will speed things up. Since you are using AWS Systems Manager for doing administration on your EC2 Instances you can use it to query the metadata to validate that the access keys were rotated after the rotation. In the EC2 console Stop the Instance named threat-detection-wksp: Compromised Instance . Wait for the Instance State to say stopped under Instance State (you may need to refresh the EC2 console) and then Start the instance. Verify the access keys have been rotated (Systems Manager) Go to AWS Systems Manager console and click on Session Manager on the left navigation and then click Start Session . You should see an instance named threat-detection-wksp: Compromised Instance with a Instance state of running . To see the credentials currently active on the instance, click on the radio button next to threat-detection-wksp: Compromised Instance and click Start Session . Run the following command in the shell: curl http://169.254.169.254/latest/meta-data/iam/security-credentials/threat-detection-wksp-compromised-ec2 Compare the access key ID to the one found in the email alerts to ensure it has changed. Why would this scenario be a good use case for auto-scaling groups and golden-image AMI\u2019s? At this point you've successfully revoked all the active sessions from AWS IAM role and rotated the temporary security credentials on the EC2 instance.","title":"Respond"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#part-2-compromised-ec2-instance","text":"","title":"Part 2 - Compromised EC2 instance"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#detect-and-investigate_1","text":"Now that you've addressed the compromised IAM credential you need focus in on how the attacker was able to compromise the EC2 instance. It's this compromise which allowed them to query the instance metadata and steal the credentials. Explore findings related to the instance ID (AWS Security Hub) When investigating the compromised IAM credential you discovered that it was from an IAM role for EC2 and identified the EC2 instance ID from the principal ID of the finding. Using the instance ID you can use AWS Security Hub to start investigating the findings. To start, you are going to research the GuardDuty findings related to the EC2 instance. Go to the AWS Security Hub console. The link should take you to the Findings section but if not, click on Findings in the navigation on the left. Click in the Add filter box: Scroll down to Resource ID , change the operator to CONTAINS and paste in the Instance ID you copied earlier (from the principal ID you gathered in the GuardDuty finding). Add another filter by again clicking in the Add filter box and scrolling down to Product Name , and paste in the word GuardDuty . What findings do you see related to this instance ID? One of the findings should indicate that the EC2 instance is communicating with an IP address on a threat list ( disallowed IP ) which adds further evidence to the conclusion that the instance has been compromised. The other finding should indicate that a system at a particular IP address is performing an SSH brute force attack against your instance. You now need to investigate if the SSH brute force attack was successful and if that is what allowed the attacker to gain access to the instance. Determine if ssh password authentication is enabled on the EC2 instance (AWS Security Hub) Automated responses to threats can do many things. For example, you could have an trigger that helps gather information about the threat that could then be used in the investigation by the security team. With that option in mind, we have a CloudWatch event rule in place that will trigger an Amazon Inspector scan of an EC2 instance when GuardDuty detects a particular attack. We will use AWS Security Hub to view the findings from Inspector. We want to determine if the SSH configuration adheres to best practices. Go to the AWS Security Hub console. The link should take you to the Findings section but if not, click on Findings in the navigation on the left. Click in the Add filter box: Scroll down to Title , change the operator to CONTAINS and paste in password authentication over SSH . In the results do you see a finding regarding SSH and password authentication for the instance that experienced the SSH brute force attack? If you do not see any findings after awhile, there may have been an issue with your Inspector agent. Go to the Inspector console, click on Assessment Templates , check the template that starts with threat-detection-wksp , and click Run . Please allow 15 minutes for the scan to complete. You can also look in Assessment runs and check the status . Feel free to continue through this module and check the results later on. Based on the findings you should see that password authentication over SSH is configured on the instance. In addition if you examine some of the other Inspector findings you will see that there are no password complexity restrictions. This means the instance is more susceptible to an SSH brute force attack. Determine if the attacker was able to login to the EC2 instance (CloudWatch logs) Now that we know that the instance was more susceptible to an SSH brute force attack, let\u2019s look at the CloudWatch logs and create a metric to see if there were any successful SSH logins (to finally answer the question of whether the SSH brute force attack was successful.) Your corporate policy is to send security certain logs from EC2 instances to CloudWatch. Go to CloudWatch logs . Click on the log group /threat-detection-wksp/var/log/secure If you have multiple log streams, filter using the Instance ID you copied earlier and click on the stream. Within the Filter Events text-box put the following Filter Pattern: [Mon, day, timestamp, ip, id, msg1= Invalid, msg2 = user, ...] Do you see any failed (invalid user) attempts to log into the instance? Would that be consistent with an SSH brute force attack? Now replace the Filter with one for successful attempts: [Mon, day, timestamp, ip, id, msg1= Accepted, msg2 = password, ...] Do you see any successful attempts to log into the instance? Which linux user was compromised?","title":"Detect and investigate"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#respond_1","text":"Modify the EC2 security group (EC2) The active session from the attacker was automatically stopped by an update to the NACL on the subnet where the instance resides. This was done by a CloudWatch event rule trigger that is invoked based on certain GuardDuty findings. A good next step would be to modify the security group associated with the EC2 instance to prevent the attacker or anyone else from connecting from a different source IP. Go to the Amazon EC2 Console. Find the running instances with the name threat-detection-wksp: Compromised Instance . Under the Description tab, click on the Security Group for the compromised instance. View the rules under the Inbound tab. Click Edit and delete the inbound SSH rule. You've decided that all administration on EC2 Instances will be done through AWS Systems Manager so you no longer need this port open. In your initial setup you already installed the SSM Agent on your EC2 Instance. Click Save","title":"Respond"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#part-3-compromised-s3-bucket","text":"","title":"Part 3 - Compromised S3 bucket"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#detect-and-investigate_2","text":"Now that we know the SSH brute force attack was successful and we disabled the IAM credentials that were stolen, we need to determine if anything else occurred. One step we could take here is to examine the IAM policy attached the IAM role that generated the temp credentials. We notice in the policy that there are permissions relating to the Amazon S3 service so that is something to keep in mind as you continue the investigation. Truncated policy from the IAM role attached to the compromised EC2 instance: { Version : 2012-10-17 , Statement : [ { Action : s3:PutObject , Resource : arn:aws:s3:::threat-detection-wksp-ACCOUNT_ID-us-west-2-gd-threatlist/* , Effect : Allow }, { Action : [ s3:* ], Resource : arn:aws:s3:::threat-detection-wksp-ACCOUNT_ID-us-west-2-data/* , Effect : Allow }, { Action : [ s3:* ], Resource : arn:aws:s3:::threat-detection-wksp-ACCOUNT_ID-us-west-2-data , Effect : Allow } ] } Investigate any S3 related findings (AWS Security Hub) There are many ways to approach this next step. We are going to start with a Security Hub insight that may be helpful in situations like this. This is not the only way you could approach this but it can definitely save time initially as you investigate the full repercussions of an attack. Go to AWS Security Hub in the AWS Management Console. The link should take you to the Insights section but if not, click on Insights in the navigation on the left. Click in the Filter insights box and type Top S3 which will display the built in Insight \"Top S3 buckets by counts of findings.\" Click on that Insight. Which buckets are displayed? There should be one that with threat-detection-wksp- and ends in -data . Click on that. What do the findings show? This Security Hub Insight is one way of determining what an attacker may have done. It is not going to help in every situation though. What additional steps would you take to investigate what an attacker had done? Check if sensitive data was involved (Macie) At this point you know how the attacker was able to get into your systems and a general idea of what they did. In the previous step you determined that the S3 bucket that starts with threat-detection-wksp- and ends in -data has an ACL that grants global read rights. We will now check if there is any sensitive and business-critical data in any of the buckets (but especially that data bucket) and take a closer at the Macie Alerts. Go to the Amazon Macie in the AWS Management console. Look through the latest alerts. Do you see any critical alerts? Does this match what you found in Security Hub? Next lets verify what sort of sensitive data exists in that bucket. Click Dashboard on the left navigation. You should see the following data classifications: You can slide the risk slider to filter data classifications based on risk levels. Above the risk slider, click the icon for S3 public objects and buckets . The icon will be in the shape of a globe but you can also hover over the icons to find the right one. Click the magnifying glass to the left of the bucket name listed. Check if any of the data in the bucket is considered a high risk Look for the Object PII priority field and Object risk level field Verify if any of the data is unencrypted Look for the Object encryption field. (Does a portion of the blue bar indicate that encryption is set to none?)","title":"Detect and investigate"},{"location":"workshops/threat-detection-remediation/03-detection-and-remediation/#respond_2","text":"Fix the permissions and encryption on the bucket (S3) In the previous step we determined that the S3 bucket that starts with threat-detection-wksp- and ends in -data has sensitive data and some of that data is unencrypted. We also know that the bucket grants global read rights. We need to manually fix these issues. Go to Amazon S3 in the AWS Management Console. First we will fix the permissions: Find the bucket that starts with threat-detection-wksp- and ends in -data Click on the Permissions tab then click on ACL Control List Under Public access click on the radio button next to Everyone . Uncheck List objects then click Save Now we need to fix the encryption: In the same bucket, click on the Properties tab then click on Default encryption Set the encryption to AWS-KMS. Select the aws/s3 key. Finally click Save . Do you know what impact you had on existing objects in the bucket by enabling Default encryption ? Congratulations! You have successfully remediated the incident and further hardened your environment. This is obviously a simulation and we can not cover every aspect of the response function in the short time allotted but hopefully this gave you an idea of the capabilities available on AWS to detect, investigate and respond to threats and attacks. Here is a diagram of the attack you just investigated. Numbers 1 2 show the SSH brute force attack and successful SSH login. Number 3 shows the S3 bucket changes the attacker made. Number 4 shows the API calls the attacker made with the IAM temporary credentials stolen from the compromised EC2 instance. If you are going through this workshop in a classroom setting then the instructor should start the module 4 presentation soon.","title":"Respond"},{"location":"workshops/threat-detection-remediation/04-review-and-discussion/","text":"Module 4: Review and Discussion In the last module we will have a short discussion of the workshop (and discuss exactly what occurred.) We will also go over a number of questions and then provide instructions on how to clean up the workshop environment (to prevent future charges in your AWS account.) Agenda Review Discussion \u2013 10 min Questions \u2013 10 min Cleanup \u2013 5 min Architecture Overview Diagram of the overall workshop setup: What is Really Going On? In Module 1 of the workshop you setup the initial components of your infrastructure including GuardDuty, Macie and a simple notification and remediation pipeline. Some of the steps required manual configuration but you also ran a CloudFormation template which setup some of the components. In Module 2 you launched a second CloudFormation template that initiated the attack simulated by this workshop. The CloudFormation template created two EC2 instances. One instance (named Malicious Host ) had an EIP attached to it that was added to your GuardDuty custom threat list. Although the Malicious Host is in the same VPC as the other instance, for the sake of the scenario (and to prevent the need to submit a penetration testing request) we acted as if it is on the Internet and represented the attack's computer. The other instance (named Compromised Instance ) was your web server and it was taken over by the Malicious Host . In Module 3 you investigated the attack, remediated the damage, and setup some automated remediations for future attacks. Here is what occurred in the attack: There are two instances created by the Module 2 CloudFormation template. They are in the same VPC but different subnets. The Malicious Host represents the attacker which we pretend is on the Internet. The Elastic IP on the Malicious Host is in a custom threat list in GuardDuty. The other instance named Compromised Instance represents the web server that was lifted and shifted into AWS. Although company policy is that only key-based authentication should be enabled for SSH, at some point password authentication for SSH was enabled on the Compromised Instance . This misconfiguration is identified in the Inspector scan that is triggered from the GuardDuty finding. The Malicious Host performed a brute force SSH password attack against the Compromised Instance . The brute force attack is designed to be successful. GuardDuty Finding : UnauthorizedAccess:EC2/SSHBruteForce The SSH brute force attack was successful and the attacker was able to log in to the Compromised Instance . Successful login is confirmed in CloudWatch Logs (/threat-detection-wksp/var/log/secure). The EC2 Instance that is created in the Module 2 CloudFormation template disabled default encryption on the Data bucket. In addition the CloudFormation template made the Data bucket public. This is used for the Macie part of the investigation in Module 3. We pretend that the attacker made the bucket public and removed the default encryption from the bucket. Macie Alert : S3 Bucket IAM policy grants global read rights The Compromised Instance also has a cron job that continuously pings the Malicious Host to generate a GuardDuty finding based off the custom threat list. GuardDuty Finding : UnauthorizedAccess:EC2/MaliciousIPCaller.Custom The API Calls that generated the API findings come from the Malicious Host . The calls use the temp creds from the IAM role for EC2 running on the Malicious Host . The GuardDuty findings are generated because the EIP attached to the Malicious Host is in a custom threat list. GuardDuty Finding : Recon:IAMUser/MaliciousIPCaller.Custom GuardDuty Finding : UnauthorizedAccess:IAMUser/MaliciousIPCaller.Custom A number of CloudWatch Events Rules are evoked by the GuardDuty findings and then these trigger various services. CloudWatch Event Rule : The generic GuardDuty finding invokes a CloudWatch Event rule which triggers SNS to send an email. CloudWatch Event Rule : The generic Macie alert invokes a CloudWatch Event rule which triggers SNS to send an email. CloudWatch Event Rule : The SSH brute force attack finding invokes a CloudWatch Event rule which triggers a Lambda function to block the attacker IP address of the attacker via a NACL as well as a Lambda function that runs an Inspector scan on the EC2 instance. CloudWatch Event Rule : The Unauthorized Access Custom MaliciousIP finding invokes a CloudWatch Event rule which triggers a Lambda function to block the IP address of the attacker via a NACL. Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forgot about it, and then accrue charges. You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete the Inspector objects created for the workshop. Go to the Amazon Inspector console. Click on Assessment targets in the navigation pane on the left. Delete all that start with threat-detection-wksp . Delete the IAM Role for the compromised EC2 instance and the Service-Linked Role for Inspector (if you didn't already have this Role created). Go to AWS IAM console. Click on Roles Search for the role named threat-detection-wksp-compromised-ec2 . Click the check box next to it and click Delete . Repeat the steps above for the role named AWSServiceRoleForAmazonInspector . Delete all three S3 buckets created by the Module 1 CloudFormation template (the buckets that start with threat-detection-wksp and end with -data , -threatlist and -logs ) Go to Amazon S3 console. Click on the appropiate bucket. Click Delete Bucket . Copy and paste the name of the bucket (this is an extra verification that you actually want to delete the bucket). Repeat the steps above for all three buckets. Delete Module 1 and 2 CloudFormation stacks ( ThreatDetectionWksp-Env-Setup and ThreatDetectionWksp-Attacks ). Go to the AWS CloudFormation console. Select the appropiate stack. Select Action . Click Delete Stack . Repeat the steps above for each stack. You do not need to wait for the first stack to delete before you delete the second one. Delete the GuardDuty custom threat list and disable GuardDuty (if you didn't already have it configured before the workshop) Go to the Amazon GuardDuty console. Click on Lists on the left navigation. Click the X next to the threat list that starts with Custom-Threat-List . Click Settings in the navigation pane on the left navigation. Click the check box next to Disable . Click Save settings and then click Disable in the pop-up box. Disable AWS Security Hub Go to the AWS Security Hub console. Click on Settings on the left navigation. Click the General on the top navigation. Click Disable AWS Security Hub . Delete the manual CloudWatch Event Rule you created and the CloudWatch Logs that were generated. Go to the AWS CloudWatch console. Click on Rules in the navigation pane on the left. Click the radio button next threat-detection-wksp-guardduty-finding-maliciousip . Select Action and click Delete . Click on Logs in the navigation pane on the left. Click the radio button next to /aws/lambda/threat-detection-wksp-inspector-role-creation . Select Action and click Delete log group and then click Yes, Delete in the pop-up box. Repeat for: /aws/lambda/threat-detection-wksp-remediation-inspector /aws/lambda/threat-detection-wksp-remediation-nacl /threat-detection-wksp/var/log/secure Delete the SNS subscription that was created when you subscribed to SNS Topic. Go to the AWS SNS console. Click on Subscriptions on the left navigation. Select the check box next to the subscription that shows your e-mail as the Endpoint and has threat-detection-wksp in the Subscription ARN . Select Action and then click Delete subscriptions Disable Macie (if you didn't already have Macie enabled before the workshop). Go the Amazon Macie console. In the upper right-hand corner select the down arrow to the left of the Region and select Macie General Settings . Check the two boxes and click Disable Amazon Macie Disabling Macie will actually log you out of the AWS Console so you will need to log back to do any other tasks. Finished! Congratulations on completing this workshop! This is the workshop's permanent home, so feel free to revisit as often as you'd like.","title":"Module 4: Discussion"},{"location":"workshops/threat-detection-remediation/04-review-and-discussion/#module-4-review-and-discussion","text":"In the last module we will have a short discussion of the workshop (and discuss exactly what occurred.) We will also go over a number of questions and then provide instructions on how to clean up the workshop environment (to prevent future charges in your AWS account.) Agenda Review Discussion \u2013 10 min Questions \u2013 10 min Cleanup \u2013 5 min","title":"Module 4: Review and Discussion"},{"location":"workshops/threat-detection-remediation/04-review-and-discussion/#architecture-overview","text":"Diagram of the overall workshop setup:","title":"Architecture Overview"},{"location":"workshops/threat-detection-remediation/04-review-and-discussion/#what-is-really-going-on","text":"In Module 1 of the workshop you setup the initial components of your infrastructure including GuardDuty, Macie and a simple notification and remediation pipeline. Some of the steps required manual configuration but you also ran a CloudFormation template which setup some of the components. In Module 2 you launched a second CloudFormation template that initiated the attack simulated by this workshop. The CloudFormation template created two EC2 instances. One instance (named Malicious Host ) had an EIP attached to it that was added to your GuardDuty custom threat list. Although the Malicious Host is in the same VPC as the other instance, for the sake of the scenario (and to prevent the need to submit a penetration testing request) we acted as if it is on the Internet and represented the attack's computer. The other instance (named Compromised Instance ) was your web server and it was taken over by the Malicious Host . In Module 3 you investigated the attack, remediated the damage, and setup some automated remediations for future attacks. Here is what occurred in the attack: There are two instances created by the Module 2 CloudFormation template. They are in the same VPC but different subnets. The Malicious Host represents the attacker which we pretend is on the Internet. The Elastic IP on the Malicious Host is in a custom threat list in GuardDuty. The other instance named Compromised Instance represents the web server that was lifted and shifted into AWS. Although company policy is that only key-based authentication should be enabled for SSH, at some point password authentication for SSH was enabled on the Compromised Instance . This misconfiguration is identified in the Inspector scan that is triggered from the GuardDuty finding. The Malicious Host performed a brute force SSH password attack against the Compromised Instance . The brute force attack is designed to be successful. GuardDuty Finding : UnauthorizedAccess:EC2/SSHBruteForce The SSH brute force attack was successful and the attacker was able to log in to the Compromised Instance . Successful login is confirmed in CloudWatch Logs (/threat-detection-wksp/var/log/secure). The EC2 Instance that is created in the Module 2 CloudFormation template disabled default encryption on the Data bucket. In addition the CloudFormation template made the Data bucket public. This is used for the Macie part of the investigation in Module 3. We pretend that the attacker made the bucket public and removed the default encryption from the bucket. Macie Alert : S3 Bucket IAM policy grants global read rights The Compromised Instance also has a cron job that continuously pings the Malicious Host to generate a GuardDuty finding based off the custom threat list. GuardDuty Finding : UnauthorizedAccess:EC2/MaliciousIPCaller.Custom The API Calls that generated the API findings come from the Malicious Host . The calls use the temp creds from the IAM role for EC2 running on the Malicious Host . The GuardDuty findings are generated because the EIP attached to the Malicious Host is in a custom threat list. GuardDuty Finding : Recon:IAMUser/MaliciousIPCaller.Custom GuardDuty Finding : UnauthorizedAccess:IAMUser/MaliciousIPCaller.Custom A number of CloudWatch Events Rules are evoked by the GuardDuty findings and then these trigger various services. CloudWatch Event Rule : The generic GuardDuty finding invokes a CloudWatch Event rule which triggers SNS to send an email. CloudWatch Event Rule : The generic Macie alert invokes a CloudWatch Event rule which triggers SNS to send an email. CloudWatch Event Rule : The SSH brute force attack finding invokes a CloudWatch Event rule which triggers a Lambda function to block the attacker IP address of the attacker via a NACL as well as a Lambda function that runs an Inspector scan on the EC2 instance. CloudWatch Event Rule : The Unauthorized Access Custom MaliciousIP finding invokes a CloudWatch Event rule which triggers a Lambda function to block the IP address of the attacker via a NACL.","title":"What is Really Going On?"},{"location":"workshops/threat-detection-remediation/04-review-and-discussion/#cleanup","text":"In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forgot about it, and then accrue charges. You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete the Inspector objects created for the workshop. Go to the Amazon Inspector console. Click on Assessment targets in the navigation pane on the left. Delete all that start with threat-detection-wksp . Delete the IAM Role for the compromised EC2 instance and the Service-Linked Role for Inspector (if you didn't already have this Role created). Go to AWS IAM console. Click on Roles Search for the role named threat-detection-wksp-compromised-ec2 . Click the check box next to it and click Delete . Repeat the steps above for the role named AWSServiceRoleForAmazonInspector . Delete all three S3 buckets created by the Module 1 CloudFormation template (the buckets that start with threat-detection-wksp and end with -data , -threatlist and -logs ) Go to Amazon S3 console. Click on the appropiate bucket. Click Delete Bucket . Copy and paste the name of the bucket (this is an extra verification that you actually want to delete the bucket). Repeat the steps above for all three buckets. Delete Module 1 and 2 CloudFormation stacks ( ThreatDetectionWksp-Env-Setup and ThreatDetectionWksp-Attacks ). Go to the AWS CloudFormation console. Select the appropiate stack. Select Action . Click Delete Stack . Repeat the steps above for each stack. You do not need to wait for the first stack to delete before you delete the second one. Delete the GuardDuty custom threat list and disable GuardDuty (if you didn't already have it configured before the workshop) Go to the Amazon GuardDuty console. Click on Lists on the left navigation. Click the X next to the threat list that starts with Custom-Threat-List . Click Settings in the navigation pane on the left navigation. Click the check box next to Disable . Click Save settings and then click Disable in the pop-up box. Disable AWS Security Hub Go to the AWS Security Hub console. Click on Settings on the left navigation. Click the General on the top navigation. Click Disable AWS Security Hub . Delete the manual CloudWatch Event Rule you created and the CloudWatch Logs that were generated. Go to the AWS CloudWatch console. Click on Rules in the navigation pane on the left. Click the radio button next threat-detection-wksp-guardduty-finding-maliciousip . Select Action and click Delete . Click on Logs in the navigation pane on the left. Click the radio button next to /aws/lambda/threat-detection-wksp-inspector-role-creation . Select Action and click Delete log group and then click Yes, Delete in the pop-up box. Repeat for: /aws/lambda/threat-detection-wksp-remediation-inspector /aws/lambda/threat-detection-wksp-remediation-nacl /threat-detection-wksp/var/log/secure Delete the SNS subscription that was created when you subscribed to SNS Topic. Go to the AWS SNS console. Click on Subscriptions on the left navigation. Select the check box next to the subscription that shows your e-mail as the Endpoint and has threat-detection-wksp in the Subscription ARN . Select Action and then click Delete subscriptions Disable Macie (if you didn't already have Macie enabled before the workshop). Go the Amazon Macie console. In the upper right-hand corner select the down arrow to the left of the Region and select Macie General Settings . Check the two boxes and click Disable Amazon Macie Disabling Macie will actually log you out of the AWS Console so you will need to log back to do any other tasks.","title":"Cleanup"},{"location":"workshops/threat-detection-remediation/04-review-and-discussion/#finished","text":"Congratulations on completing this workshop! This is the workshop's permanent home, so feel free to revisit as often as you'd like.","title":"Finished!"}]}